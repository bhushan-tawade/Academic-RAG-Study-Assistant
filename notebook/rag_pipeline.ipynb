{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5aaf9a",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fdcd8b",
   "metadata": {},
   "source": [
    "## üìö Dataset Description\n",
    "\n",
    "### üìå Dataset Overview\n",
    "\n",
    "The dataset used in this RAG-based Academic Study Assistant consists of structured Machine Learning course material organized into chapter-wise PDF documents.\n",
    "\n",
    "The dataset contains the following files:\n",
    "\n",
    "1. **Chapter 1 ‚Äì Introduction to Machine Learning**\n",
    "2. **Chapter 2 ‚Äì Simple Linear Regression**\n",
    "3. **Chapter 3 ‚Äì Logistic Regression**\n",
    "4. **Chapter 4 ‚Äì Decision Trees**\n",
    "5. **Chapter 5 ‚Äì Neural Networks**\n",
    "6. **Chapter 6 ‚Äì Overfitting & Regularization**\n",
    "7. **Chapter 7 ‚Äì Bias-Variance Tradeoff**\n",
    "8. **Chapter 8 ‚Äì Gradient Descent**\n",
    "9. **Chapter 9 ‚Äì Evaluation Metrics**\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Dataset Characteristics\n",
    "\n",
    "- **Format:** PDF  \n",
    "- **Type:** Academic lecture notes / textbook chapters  \n",
    "- **Domain:** Machine Learning  \n",
    "- **Content Includes:**\n",
    "  - Theoretical explanations\n",
    "  - Mathematical derivations\n",
    "  - Regression equations\n",
    "  - Optimization formulas\n",
    "  - Algorithm descriptions\n",
    "  - Conceptual diagrams (if present)\n",
    "- **Complexity Level:** Undergraduate / Early Postgraduate ML coursework  \n",
    "\n",
    "---\n",
    "\n",
    "### üß† Nature of the Content\n",
    "\n",
    "The dataset includes:\n",
    "\n",
    "- Mathematical equations (e.g., least squares, gradient descent updates)\n",
    "- Statistical notations\n",
    "- Model definitions\n",
    "- Algorithm steps\n",
    "- Conceptual explanations\n",
    "- Performance metrics and evaluation formulas\n",
    "\n",
    "Some chapters (e.g., Regression, Neural Networks, Gradient Descent) contain heavy mathematical notation and symbolic expressions.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö† Challenges Identified in the Dataset\n",
    "\n",
    "1. Mathematical equations may appear in symbolic or multi-line format.\n",
    "2. PDF formatting can break equations during text extraction.\n",
    "3. Technical terms and formula-heavy sections require careful chunking.\n",
    "4. Certain chapters are concept-heavy, while others are equation-heavy.\n",
    "\n",
    "These challenges are addressed using preprocessing, structured chunking strategies, and equation normalization techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Purpose of Using This Dataset\n",
    "\n",
    "This dataset is used to build and evaluate a Retrieval-Augmented Generation (RAG) based academic assistant capable of:\n",
    "\n",
    "- Answering conceptual ML questions\n",
    "- Explaining mathematical formulas\n",
    "- Retrieving relevant theory sections\n",
    "- Providing context-aware explanations\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Why This Dataset Is Suitable for RAG Evaluation\n",
    "\n",
    "This dataset is ideal for evaluating RAG performance because:\n",
    "\n",
    "- It contains both conceptual and mathematical content.\n",
    "- It spans multiple interconnected ML topics.\n",
    "- It allows evaluation of retrieval performance across:\n",
    "  - Definition-based questions\n",
    "  - Derivation-based questions\n",
    "  - Algorithm explanation queries\n",
    "  - Formula-based queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4d941",
   "metadata": {},
   "source": [
    "### document datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da157552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4ab5ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example', 'page': 1, 'author': 'Bhushan', 'date_created': '2025-04-05'}, page_content='this is the main text contain I am Using to create RAG')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"this is the main text contain I am Using to create RAG\",\n",
    "    metadata={\n",
    "        \"source\": \"example\",\n",
    "        \"page\": 1,\n",
    "        \"author\": \"Bhushan\",\n",
    "        \"date_created\": \"2025-04-05\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1443b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a simple text file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b2da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_text = {\n",
    "    \"../data/text_files/python_intro.txt\" : \"\"\"Python Programming Introduction\n",
    "     \n",
    "    Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "    Created by Guido van Rossum and first released in 1991, Pyhton has become one of the most popular \n",
    "    programming languages in the world.\n",
    "\n",
    "    Key Features:\n",
    "    - Easy to learn and use\n",
    "    - Extensive standard library\n",
    "    - Cross-platform campatibility\n",
    "    - Strong community support\n",
    "\n",
    "    Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "\n",
    "    \"../data/text_files/machine_learning.txt\" : \"\"\" Machine Learning Basics\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables syste,s to learn and improve \n",
    "    from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "    that can access data and use it to learn for themselves.\n",
    "\n",
    "    Types of Machine Learning:\n",
    "    1. Supervised Learning: Learning with labeled data\n",
    "    2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "    3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "    Applications include image recognition, speech processing, and recommendation systems\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for filepath,content in sample_text.items():\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"‚úÖ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58cc58",
   "metadata": {},
   "source": [
    "### Text loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6795a65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\n    Python is a high-level, interpreted programming language known for its simplicity and readability.\\n    Created by Guido van Rossum and first released in 1991, Pyhton has become one of the most popular \\n    programming languages in the world.\\n\\n    Key Features:\\n    - Easy to learn and use\\n    - Extensive standard library\\n    - Cross-platform campatibility\\n    - Strong community support\\n\\n    Python is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56365cbe",
   "metadata": {},
   "source": [
    "### Direactory Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01cf09fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content=' Machine Learning Basics\\n\\n    Machine learning is a subset of artificial intelligence that enables syste,s to learn and improve \\n    from experience without being explicitly programmed. It focuses on developing computer programs\\n    that can access data and use it to learn for themselves.\\n\\n    Types of Machine Learning:\\n    1. Supervised Learning: Learning with labeled data\\n    2. Unsupervised Learning: Finding patterns in unlabeled data\\n    3. Reinforcement Learning: Learning through rewards and penalties\\n\\n    Applications include image recognition, speech processing, and recommendation systems\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\n    Python is a high-level, interpreted programming language known for its simplicity and readability.\\n    Created by Guido van Rossum and first released in 1991, Pyhton has become one of the most popular \\n    programming languages in the world.\\n\\n    Key Features:\\n    - Easy to learn and use\\n    - Extensive standard library\\n    - Cross-platform campatibility\\n    - Strong community support\\n\\n    Python is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls= TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False \n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecabe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Sankey\\RAG-Based Study Assistant\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, PyMuPDFLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls= PyMuPDFLoader,\n",
    "    show_progress=False \n",
    ")\n",
    "\n",
    "pdf_documents = dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8b42a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='MACHINE LEARNING  \\n[R17A0534] \\nLECTURE NOTES \\n \\nB.TECH IV YEAR ‚Äì I SEM(R17) \\n(2020-21) \\n \\n \\n \\n \\n \\n \\nDEPARTMENT OF \\nCOMPUTER SCIENCE AND ENGINEERING \\nMALLA REDDY COLLEGE OF ENGINEERING & \\nTECHNOLOGY \\n(Autonomous Institution ‚Äì UGC, Govt. of India) \\nRecognized under 2(f) and 12 (B) of UGC ACT 1956 \\n(Affiliated to JNTUH, Hyderabad, Approved by AICTE - Accredited by NBA & NAAC ‚Äì ‚ÄòA‚Äô Grade - ISO 9001:2015 Certified) \\nMaisammaguda, Dhulapally (Post Via. Hakimpet), Secunderabad ‚Äì 500100, Telangana State, India'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='IV Year B. Tech. CSE ‚ÄìII Sem   \\n \\n \\n \\n \\n \\n                L   T/P/D   C  \\n  4   1/- / -   3  \\n(R17A0534) Machine Learning \\nObjectives:  \\n\\uf0b7 Acquire theoretical Knowledge on setting hypothesis for pattern recognition. \\n\\uf0b7 Apply suitable machine learning techniques for data handling and to gain knowledge from it. \\n\\uf0b7 Evaluate the performance of algorithms and to provide solution for various real world \\napplications. \\n \\nUNIT I:  \\nIntroduction to Machine Learning \\nIntroduction ,Components of Learning , Learning Models , Geometric Models, Probabilistic \\nModels, Logic Models, Grouping and Grading, Designing a Learning System, Types of \\nLearning, Supervised, Unsupervised, Reinforcement, Perspectives and Issues, Version Spaces, \\nPAC Learning, VC Dimension.  \\n \\nUNIT II:  \\nSupervised and Unsupervised Learning \\nDecision Trees: ID3, Classification and Regression Trees, Regression: Linear Regression, Multiple Linear \\nRegression, Logistic Regression, Neural Networks: Introduction, Perception, Multilayer Perception, \\nSupport Vector Machines: Linear and Non-Linear, Kernel Functions, K Nearest Neighbors.  \\nIntroduction to clustering, K-means clustering, K-Mode Clustering. \\n \\nUNIT III:  \\nEnsemble and Probabilistic Learning \\nModel Combination Schemes, Voting, Error-Correcting Output Codes, Bagging: Random Forest Trees, \\nBoosting: Adaboost, Stacking. \\nGaussian mixture models - The Expectation-Maximization (EM) Algorithm, Information Criteria, Nearest \\nneighbour methods - Nearest Neighbour Smoothing, Efficient Distance Computations: the KD-Tree, \\nDistance Measures. \\n \\n \\nUNIT IV:  \\nReinforcement Learning and Evaluating Hypotheses \\nIntroduction, Learning Task, Q Learning, Non deterministic Rewards and actions, temporal-difference \\nlearning, Relationship to Dynamic Programming, Active reinforcement learning, Generalization in \\nreinforcement learning. \\nMotivation, Basics of Sampling Theory: Error Estimation and Estimating Binomial Proportions, The \\nBinomial Distribution, Estimators, Bias, and Variance   \\n \\n \\nUNIT V:  \\nGenetic Algorithms: Motivation, Genetic Algorithms: Representing Hypotheses, Genetic Operator, \\nFitness Function and Selection, An Illustrative Example, Hypothesis Space Search, Genetic \\nProgramming, Models of Evolution and Learning: Lamarkian Evolution, Baldwin Effect, Parallelizing \\nGenetic Algorithms.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2}, page_content='TEXT BOOKS:  \\n \\n1. Ethem  Alpaydin, ‚ÄùIntroduction to Machine Learning‚Äù, MIT Press, Prentice Hall of India, 3rd \\nEdition2014. \\n2. Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar ‚Äù Foundations of Machine Learning‚Äù, MIT \\nPress,2012. \\n3. Tom Mitchell, ‚ÄúMachine Learning‚Äù, McGraw Hill, 3rdEdition, 1997. \\n4. MACHINE LEARNING - An Algorithmic Perspective, Second Edition, Stephen Marsland, 2015. \\n \\nREFERENCE BOOKS:  \\n1. \\nCharuC.Aggarwal,‚ÄúDataClassificationAlgorithmsandApplications‚Äù,CRCPress,2014. \\n2. \\nCharu C. Aggarwal, ‚ÄúDATA CLUSTERING Algorithms and Applications‚Äù, CRC Press,  \\n       2014. \\n3. \\nKevin P. Murphy ‚ÄùMachine Learning: A Probabilistic Perspective‚Äù, The MIT Press, 2012 \\n4. \\nJiawei Han and Micheline Kambers and JianPei, ‚ÄúData Mining Concepts  \\n      andTechniques‚Äù,3rd edition, Morgan Kaufman Publications, 2012. \\n \\n \\nOUTCOMES:  \\n1. Recognize the characteristics of Machine Learning techniques that enable to solve real world \\nproblems \\n2. Recognize the characteristics of machine learning strategies \\n3. Apply various supervised learning methods to appropriate problems \\n4. Identify and integrate more than one techniques to enhance the performance of learning \\n5. Create probabilistic and unsupervised learning models for handling unknown pattern \\n6. Analyze the co-occurrence of data to find interesting frequent patterns'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3}, page_content='INDEX \\nUNIT NO \\nTOPIC \\nPAGE NO \\nI \\nIntroduction \\n1 \\nLearning Models \\n3 \\nDesigning a Learning System \\n7 \\nTypes of Learning \\n12 \\nPerspectives and Issues \\n13 \\nVersion Spaces \\n14 \\nPAC Learning \\n19 \\nVC Dimension \\n21 \\nII \\nDecision Trees \\n23 \\nClassification and Regression Trees \\n27 \\nNeural Networks \\n37 \\nSupport Vector Machines \\n45 \\nIntroduction to clustering \\n49 \\nK-means clustering \\n52 \\nIII \\nModel Combination Schemes \\n55 \\nVoting, Error-Correcting Output Codes \\n57 \\nBagging, Random Forest Trees \\n61 \\nBoosting, Adaboost \\n65 \\nGaussian mixture models \\n68 \\nEM Algorithms \\n69 \\nEfficient Distance Computations \\n73'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4}, page_content='IV \\nReinforcement Learning \\n78 \\nLearning Task \\n79 \\nQ Learning \\n82 \\nEvaluating Hypotheses \\n86 \\nBasics of Sampling Theory \\n88 \\nV \\nGenetic Algorithms \\n92 \\nAn Illustrative Example \\n96 \\nHypothesis Space Search \\n98 \\nGenetic Programming \\n101 \\nModels of Evolution and Learning \\n104 \\nParallelizing Genetic Algorithms. \\n105'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5}, page_content='1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a computer program to optimize the parameters of the model using the training data or \\npast experience. The model may be predictive to make predictions in the future, or descriptive to gain \\nknowledge from data, or both. \\nArthur Samuel, an early American leader in the field of computer gaming and artificial intelligence, \\ncoined the term ‚ÄúMachine Learning‚Äù in 1959 while at IBM. He defined machine learning as ‚Äúthe field of \\nstudy that gives computers the ability to learn without being explicitly programmed.‚Äù However, there is \\nno universally accepted definition for machine learning. Different authors define the term differently. \\n \\nDefinition of learning \\nDefinition \\nA computer program is said to learn from experience E with respect to some class of tasks T and \\nperformance measure P, if its performance at tasks T, as measured by P, improves with experience E. \\n \\nExamples \\ni) Handwriting recognition learning problem \\n‚Ä¢ Task T: Recognising and classifying handwritten words within images \\n‚Ä¢ Performance P: Percent of words correctly classified \\n‚Ä¢ Training experience E: A dataset of handwritten words with given classifications \\nii) A robot driving learning problem \\n‚Ä¢ Task T: Driving on highways using vision sensors \\n‚Ä¢ Performance measure P: Average distance traveled before an error \\n‚Ä¢ training experience: A sequence of images and steering commands recorded while  \\n  observing a human driver \\niii) A chess learning problem \\n‚Ä¢ Task T: Playing chess \\n‚Ä¢ Performance measure P: Percent of games won against opponents \\n‚Ä¢ Training experience E: Playing practice games against itself \\nDefinition \\nA computer program which learns from experience is called a machine learning program or \\nsimply a learning program. Such a program is sometimes also referred to as a learner. \\n \\n1.2 Components of Learning \\n Basic components of learning process \\nThe learning process, whether by a human or a machine, can be divided into four components, \\nnamely, data storage, abstraction, generalization and evaluation. Figure 1.1 illustrates the \\nvariouscomponents and the steps involved in the learning process.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6}, page_content='2 \\n \\n \\n1. Data storage \\nFacilities for storing and retrieving huge amounts of data are an important component of the \\nlearning process. Humans and computers alike utilize data storage as a foundation for advanced \\nreasoning. \\n‚Ä¢ In a human being, the data is stored in the brain and data is retrieved using electrochemical    signals. \\n‚Ä¢ Computers use hard disk drives, flash memory, random access memory and similar devices    to store \\ndata and use cables and other technology to retrieve data. \\n \\n2. Abstraction \\nThe second component of the learning process is known as abstraction. \\nAbstraction is the process of extracting knowledge about stored data. This involves creating general \\nconcepts about the data as a whole. The creation of knowledge involves application of known models \\nand creation of new models. \\nThe process of fitting a model to a dataset is known as training. When the model has been trained, the \\ndata is transformed into an abstract form that summarizes the original information. \\n \\n3. Generalization \\nThe third component of the learning process is known as generalisation. \\nThe term generalization describes the process of turning the knowledge about stored data into a form \\nthat can be utilized for future action. These actions are to be carried out on tasks that are similar, but \\nnot identical, to those what have been seen before. In generalization, the goal is to discover those \\nproperties of the data that will be most relevant to future tasks. \\n \\n4. Evaluation \\nEvaluation is the last component of the learning process. \\nIt is the process of giving feedback to the user to measure the utility of the learned knowledge. This \\nfeedback is then utilised to effect improvements in the whole learning process \\n \\nApplications of machine learning \\nApplication of machine learning methods to large databases is called data mining. In data \\nmining, a large volume of data is processed to construct a simple model with valuable use, for example, \\nhaving \\nhigh predictive accuracy. \\n \\nThe following is a list of some of the typical applications of machine learning. \\n1. In retail business, machine learning is used to study consumer behaviour. \\n2. In finance, banks analyze their past data to build models to use in credit applications, fraud \\ndetection, and the stock market. \\n3. In manufacturing, learning models are used for optimization, control, and troubleshooting.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7}, page_content='3 \\n \\n4. In medicine, learning programs are used for medical diagnosis. \\n5. In telecommunications, call patterns are analyzed for network optimization and maximizing the \\nquality of service. \\n6. In science, large amounts of data in physics, astronomy, and biology can only be analyzed fast \\nenough by computers. The World Wide Web is huge; it is constantly growing and searching for \\nrelevant information cannot be done manually. \\n7. In artificial intelligence, it is used to teach a system to learn and adapt to changes so that the \\nsystem designer need not foresee and provide solutions for all possible situations.  \\n8. It is used to find solutions to many problems in vision, speech recognition, and robotics.  \\n9. Machine learning methods are applied in the design of computer-controlled vehicles to steer \\ncorrectly when driving on a variety of roads. \\n10. Machine learning methods have been used to develop programmes for playing games such as \\nchess, backgammon and Go. \\n \\n1.3 Learning Models \\nMachine learning is concerned with using the right features to build the right models that \\nachieve the right tasks.  The basic idea of Learning models has divided into three categories. \\nFor a given problem, the collection of all possible outcomes represents the sample space or instance \\nspace. \\n \\n\\uf0b7 \\nUsing a Logical expression. (Logical models) \\n\\uf0b7 \\nUsing the Geometry of the instance space. (Geometric models)  \\n\\uf0b7 \\nUsing Probability to classify the instance space. (Probabilistic models) \\n\\uf0b7 \\nGrouping and Grading \\n \\n1.3.1  Logical models \\nLogical models use a logical expression to divide the instance space into segments and hence \\nconstruct grouping models. A logical expression is an expression that returns a Boolean value, i.e., a \\nTrue or False outcome. Once the data is grouped using a logical expression, the data is divided into \\nhomogeneous groupings for the problem we are trying to solve.  For example, for a classiÔ¨Åcation \\nproblem, all the instances in the group belong to one class. \\n \\nThere are mainly two kinds of logical models: Tree models and Rule models. \\n \\nRule models consist of a collection of implications or IF-THEN rules. For tree-based models, the ‚Äòif-part‚Äô \\ndeÔ¨Ånes a segment and the ‚Äòthen-part‚Äô deÔ¨Ånes the behaviour of the model for this segment. Rule models \\nfollow the same reasoning. \\n \\nLogical models and Concept learning \\nTo understand logical models further, we need to understand the idea of Concept Learning. \\nConcept Learning involves learning logical expressions or concepts from examples. The idea of Concept \\nLearning fits in well with the idea of Machine learning, i.e., inferring a general function from specific \\ntraining examples. Concept learning forms the basis of both tree-based and rule-based models.  More \\nformally, Concept Learning involves acquiring the definition of a general category from a given set of \\npositive and negative training examples of the category. A Formal Definition for Concept Learning is \\n‚ÄúThe inferring of a Boolean-valued function from training examples of its input and output.‚Äù In \\nconcept learning, we only learn a description for the positive class and label everything that doesn‚Äôt \\nsatisfy that description as negative.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8}, page_content='4 \\n \\n \\n \\n \\n \\n \\n \\n \\nThe following example explains this idea in more detail. \\n \\n \\n \\nA Concept Learning Task called ‚ÄúEnjoy Sport‚Äù as shown above is defined by a set of data from \\nsome example days. Each data is described by six attributes. The task is to learn to predict the value of \\nEnjoy Sport for an arbitrary day based on the values of its attribute values. The problem can be \\nrepresented by a series of hypotheses. Each hypothesis is described by a conjunction of constraints on \\nthe attributes. The training data represents a set of positive and negative examples of the target \\nfunction. In the example above, each hypothesis is a vector of six constraints, specifying the values of \\nthe six attributes ‚Äì  Sky, AirTemp, Humidity, Wind, Water, and Forecast. The training phase involves \\nlearning the set of days (as a conjunction of attributes) for which Enjoy Sport = yes. \\n \\nThus, the problem can be formulated as: \\n \\n\\uf0b7 \\nGiven instances X  which represent a set of all possible days, each described by the attributes: \\no \\nSky ‚Äì (values: Sunny, Cloudy, Rainy), \\no \\nAirTemp ‚Äì (values: Warm, Cold), \\no \\nHumidity ‚Äì (values: Normal, High), \\no \\nWind ‚Äì (values: Strong, Weak), \\no \\nWater ‚Äì (values: Warm, Cold), \\no \\nForecast ‚Äì (values: Same, Change). \\n \\nTry to identify a function that can predict the target variable Enjoy Sport as yes/no, i.e., 1 or 0. \\n \\n1.3.2 Geometric models \\nIn the previous section, we have seen that with logical models, such as decision trees, a logical \\nexpression is used to partition the instance space. Two instances are similar when they end up in the \\nsame logical segment. In this section, we consider models that define similarity by considering the \\ngeometry of the instance space.  In Geometric models, features could be described as points in two \\ndimensions (x- and y-axis) or a three-dimensional space (x, y, and z). Even when features are not'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9}, page_content='5 \\n \\nintrinsically geometric, they could be modelled in a geometric manner (for example, temperature as a \\nfunction of time can be modelled in two axes). In geometric models, there are two ways we could \\nimpose similarity. \\n\\uf0b7 \\nWe could use geometric concepts like lines or planes to segment (classify) the instance space. \\nThese are called Linear models. \\n\\uf0b7 \\nAlternatively, we can use the geometric notion of distance to represent similarity. In this case, if \\ntwo points are close together, they have similar values for features and thus can be classed as \\nsimilar. We call such models as Distance-based models. \\n \\n \\nLinear models \\nLinear models are relatively simple. In this case, the function is represented as a linear \\ncombination of its inputs. Thus, if x1 and x2 are two scalars or vectors of the same dimension \\nand a and b are arbitrary scalars, then ax1 + bx2 represents a linear combination of x1 and x2. In the \\nsimplest case where f(x) represents a straight line, we have an equation of the form f (x) \\n= mx + c where c represents the intercept and m represents the slope. \\n \\n \\nLinear models are parametric, which means that they have a Ô¨Åxed form with a small number of numeric \\nparameters that need to be learned from data. For example, in f (x) = mx + c, m and c are the \\nparameters that we are trying to learn from the data. This technique is different from tree or rule \\nmodels, where the structure of the model (e.g., which features to use in the tree, and where) is not \\nÔ¨Åxed in advance. \\n \\nLinear models are stable, i.e., small variations in the training data have only a limited impact on the \\nlearned model. In contrast, tree models tend to vary more with the training data, as the choice of a \\ndifferent split at the root of the tree typically means that the rest of the tree is different as well.  As a \\nresult of having relatively few parameters, Linear models have low variance and high bias. This implies \\nthat Linear models are less likely to overfit the training data than some other models. However, they \\nare more likely to underfit. For example, if we want to learn the boundaries between countries based \\non labelled data, then linear models are not likely to give a good approximation. \\n \\nDistance-based models \\nDistance-based models are the second class of Geometric models. Like Linear models, distance-\\nbased models are based on the geometry of data. As the name implies, distance-based models work on \\nthe concept of distance.  In the context of Machine learning, the concept of distance is not based on \\nmerely the physical distance between two points. Instead, we could think of the distance between two \\npoints considering the mode of transport between two points. Travelling between two cities by plane'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10}, page_content='6 \\n \\ncovers less distance physically than by train because a plane is unrestricted. Similarly, in chess, the \\nconcept of distance depends on the piece used ‚Äì for example, a Bishop can move diagonally.   Thus, \\ndepending on the entity and the mode of travel, the concept of distance can be experienced differently. \\nThe distance metrics commonly used are Euclidean, Minkowski, Manhattan, and Mahalanobis. \\n \\n \\nDistance is applied through the concept of neighbours and exemplars. Neighbours are points in \\nproximity with respect to the distance measure expressed through exemplars. Exemplars are \\neither centroids that Ô¨Ånd a centre of mass according to a chosen distance metric or medoids that Ô¨Ånd \\nthe most centrally located data point. The most commonly used centroid is the arithmetic mean, which \\nminimises squared Euclidean distance to all other points. \\n \\nNotes: \\n\\uf0b7 \\nThe centroid represents the geometric centre of a plane figure, i.e., the arithmetic mean \\nposition of all the points in the figure from the centroid point. This definition extends to any \\nobject in n-dimensional space: its centroid is the mean position of all the points. \\n\\uf0b7 \\nMedoids are similar in concept to means or centroids. Medoids are most commonly used on \\ndata when a mean or centroid cannot be defined. They are used in contexts where the centroid \\nis not representative of the dataset, such as in image data. \\n \\nExamples of distance-based models include the nearest-neighbour models, which use the training data \\nas exemplars ‚Äì for example, in classification. The K-means clustering algorithm also uses exemplars to \\ncreate clusters of similar data points. \\n \\n1.3.3 Probabilistic models \\nThe third family of machine learning algorithms is the probabilistic models. We have seen \\nbefore that the k-nearest neighbour algorithm uses the idea of distance (e.g., Euclidian distance) to \\nclassify entities, and logical models use a logical expression to partition the instance space. In this \\nsection, we see how the probabilistic models use the idea of probability to classify new entities. \\n \\nProbabilistic models see features and target variables as random variables. The process of modelling \\nrepresents and manipulates the level of uncertainty with respect to these variables. There are two \\ntypes of probabilistic models: Predictive and Generative. Predictive probability models use the idea of \\na conditional probability distribution P (Y |X) from which Y can be predicted from X.  Generative models \\nestimate the joint distribution P (Y, X).  Once we know the joint distribution for the generative models, \\nwe can derive any conditional or marginal distribution involving the same variables. Thus, the \\ngenerative model is capable of creating new data points and their labels, knowing the joint probability \\ndistribution. The joint distribution looks for a relationship between two variables. Once this relationship \\nis inferred, it is possible to infer new data points. \\nNa√Øve Bayes is an example of a probabilistic classifier. \\n \\nWe can do this using the Bayes rule defined as'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11}, page_content='7 \\n \\n \\n \\n \\nThe Na√Øve Bayes algorithm is based on the idea of Conditional Probability.  Conditional probability is \\nbased on finding the probability that something will happen, given that something else has already \\nhappened. The task of the algorithm then is to look at the evidence and to determine the likelihood of a \\nspecific class and assign a label accordingly to each entity. \\n \\nSome broad categories of models: \\nGeometric models \\nProbabilistic models \\nLogical models \\nE.g. K-nearest neighbors, linear \\nregression, \\nsupport \\nvector \\nmachine, logistic regression, ‚Ä¶ \\nNa√Øve Bayes, Gaussian process \\nregression, conditional random \\nfield, ‚Ä¶ \\nDecision tree, random forest, ‚Ä¶ \\n \\n1.3.4 Grouping and Grading \\nGrading vs grouping is an orthogonal categorization to geometric-probabilistic-logical-compositional.  \\n\\uf0b7 \\nGrouping models break the instance space up into groups or segments and in each segment \\napply a very simple method (such as majority class). \\no E.g. decision tree, KNN. \\n\\uf0b7 \\nGrading models form one global model over the instance space. \\no E.g. Linear classifiers ‚Äì Neural networks \\n1.4 Designing a Learning System \\nFor any learning system, we must be knowing the three elements ‚Äî T (Task), P (Performance \\nMeasure), and E (Training Experience). At a high level, the process of learning system looks as below. \\n \\nThe learning process starts with task T, performance measure P and training experience E and objective \\nare to find an unknown target function. The target function is an exact knowledge to be learned from the \\ntraining experience and its unknown. For example, in a case of credit approval, the learning system will \\nhave customer application records as experience and task would be to classify whether the given \\ncustomer application is eligible for a loan. So in this case, the training examples can be represented as'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12}, page_content=\"8 \\n \\n(x1,y1)(x2,y2)..(xn,yn) where X represents customer application details and y represents the status of \\ncredit approval. \\nWith these details, what is that exact knowledge to be learned from the training experience? \\nSo the target function to be learned in the credit approval learning system is a mapping function f:X ‚Üíy. \\nThis function represents the exact knowledge defining the relationship between input variable X and \\noutput variable y.  \\nDesign of a learning system \\nJust now we looked into the learning process and also understood the goal of the learning. When we \\nwant to design a learning system that follows the learning process, we need to consider a few design \\nchoices. The design choices will be to decide the following key components: \\n1. Type of training experience \\n2. Choosing the Target Function \\n3. Choosing a representation for the Target Function \\n4. Choosing an approximation algorithm for the Target Function \\n5. The final Design \\n \\nWe will look into the game - checkers learning problem and apply the above design choices. For a \\ncheckers learning problem, the three elements will be, \\n \\n1. Task T: To play checkers \\n2. Performance measure P: Total percent of the game won in the tournament. \\n3. Training experience E: A set of games played against itself \\n \\n1.4.1 Type of training experience \\nDuring the design of the checker's learning system, the type of training experience available for a \\nlearning system will have a significant effect on the success or failure of the learning. \\n \\n1. Direct or Indirect training experience ‚Äî In the case of direct training experience, an individual board \\nstates \\nand \\ncorrect \\nmove \\nfor \\neach \\nboard \\nstate \\nare \\ngiven. \\nIn case of indirect training experience, the move sequences for a game and the final result (win, loss \\nor draw) are given for a number of games. How to assign credit or blame to individual moves is the \\ncredit assignment problem. \\n2. Teacher or Not ‚Äî Supervised ‚Äî The training experience will be labeled, which means, all the board \\nstates will be labeled with the correct move. So the learning takes place in the presence of a \\nsupervisor \\nor \\na \\nteacher. \\nUnsupervised ‚Äî The training experience will be unlabeled, which means, all the board states will not \\nhave the moves. So the learner generates random games and plays against itself with no supervision \\nor \\nteacher \\ninvolvement.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13}, page_content='9 \\n \\nSemi-supervised ‚Äî Learner generates game states and asks the teacher for help in finding the \\ncorrect move if the board state is confusing. \\n3. Is the training experience good ‚Äî Do the training examples represent the distribution of examples \\nover which the final system performance will be measured? Performance is best when training \\nexamples and test examples are from the same/a similar distribution. \\n \\nThe checker player learns by playing against oneself. Its experience is indirect. It may not encounter \\nmoves that are common in human expert play. Once the proper training experience is available, the next \\ndesign step will be choosing the Target Function. \\n \\n1.4.2 Choosing the Target Function \\nWhen you are playing the checkers game, at any moment of time, you make a decision on \\nchoosing the best move from different possibilities. You think and apply the learning that you have \\ngained from the experience. Here the learning is, for a specific board, you move a checker such that your \\nboard state tends towards the winning situation. Now the same learning has to be defined in terms of \\nthe target function. \\n \\nHere there are 2 considerations ‚Äî direct and indirect experience. \\n \\n\\uf0b7 \\nDuring the direct experience, the checkers learning system, it needs only to learn how to choose \\nthe best move among some large search space. We need to find a target function that will help \\nus choose the best move among alternatives. Let us call this function ChooseMove and use the \\nnotation ChooseMove : B ‚ÜíM to indicate that this function accepts as input any board from the \\nset of legal board states B and produces as output some move from the set of legal moves M. \\n\\uf0b7 \\nWhen there is an indirect experience, it becomes difficult to learn such function. How about \\nassigning a real score to the board state.  \\n \\nSo the function be V : B ‚ÜíR indicating that this accepts as input any board from the set of legal board \\nstates B and produces an output a real score. This function assigns the higher scores to better board \\nstates. \\n \\n \\nIf the system can successfully learn such a target function V, then it can easily use it to select the best \\nmove from any board position.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14}, page_content='10 \\n \\nLet us therefore define the target value V(b) for an arbitrary board state b in B, as follows: \\n1. if b is a final board state that is won, then V(b) = 100 \\n2. if b is a final board state that is lost, then V(b) = -100 \\n3. if b is a final board state that is drawn, then V(b) = 0 \\n4. if b is a not a final state in the game, then V (b) = V (b‚Äô), where b‚Äô is the best final board state that can \\nbe achieved starting from b and playing optimally until the end of the game. \\n \\nThe (4) is a recursive definition and to determine the value of V(b) for a particular board state, it \\nperforms the search ahead for the optimal line of play, all the way to the end of the game. So this \\ndefinition is not efficiently computable by our checkers playing program, we say that it is a \\nnonoperational definition. \\n \\nThe goal of learning, in this case, is to discover an operational description of V ; that is, a description \\nthat can be used by the checkers-playing program to evaluate states and select moves within realistic \\ntime bounds. \\nIt may be very difficult in general to learn such an operational form of V perfectly. We expect learning \\nalgorithms to acquire only some approximation to the target function ^V. \\n \\n1.4.3 Choosing a representation for the Target Function \\nNow that we have specified the ideal target function V, we must choose a representation that \\nthe learning program will use to describe the function ^V that it will learn. As with earlier design \\nchoices, we again have many options. We could, for example, allow the program to represent using a \\nlarge table with a distinct entry specifying the value for each distinct board state. Or we could allow it to \\nrepresent using a collection of rules that match against features of the board state, or a quadratic \\npolynomial function of predefined board features, or an artificial \\nneural network. In general, this choice of representation involves a crucial tradeoff. On one hand, we \\nwish to pick a very expressive representation to allow representing as close an approximation as \\npossible to the ideal target function V.  \\n \\nOn the other hand, the more expressive the representation, the more training data the program \\nwill require in order to choose among the alternative hypotheses it can represent. To keep the \\ndiscussion brief, let us choose a simple representation:  \\nfor any given board state, the function ^V will be calculated as a linear combination of the following \\nboard features: \\n\\uf0b7 \\nx1(b) ‚Äî number of black pieces on board b \\n\\uf0b7 \\nx2(b) ‚Äî number of red pieces on b \\n\\uf0b7 \\nx3(b) ‚Äî number of black kings on b \\n\\uf0b7 \\nx4(b) ‚Äî number of red kings on b \\n\\uf0b7 \\nx5(b) ‚Äî number of red pieces threatened by black (i.e., which can be taken on black‚Äôs next turn) \\n\\uf0b7 \\nx6(b) ‚Äî number of black pieces threatened by red \\n \\n^V = w0 + w1 ¬∑ x1(b) + w2 ¬∑ x2(b) + w3 ¬∑ x3(b) + w4 ¬∑ x4(b) +w5 ¬∑ x5(b) + w6 ¬∑ x6(b) \\n \\nWhere w0 through w6 are numerical coefficients or weights to be obtained by a learning algorithm.  \\nWeights w1 to w6 will determine the relative importance of different board features.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 15}, page_content='11 \\n \\nSpecification of the Machine Learning Problem at this time ‚Äî Till now we worked on choosing the type \\nof training experience, choosing the target function and its representation. The checkers learning task \\ncan be summarized as below. \\n\\uf0b7 \\nTask T : Play Checkers \\n\\uf0b7 \\nPerformance Measure : % of games won in world tournament \\n\\uf0b7 \\nTraining Experience E : opportunity to play against itself \\n\\uf0b7 \\nTarget Function : V : Board ‚Üí R \\n\\uf0b7 \\nTarget Function Representation : ^V = w0 + w1 ¬∑ x1(b) + w2 ¬∑ x2(b) + w3 ¬∑ x3(b) + w4 ¬∑ x4(b) +w5 ¬∑ \\nx5(b) + w6 ¬∑ x6(b) \\nThe first three items above correspond to the specification of the learning task,whereas the final two \\nitems constitute design choices for the implementation of the learning program. \\n \\n1.4.4 Choosing an approximation algorithm for the Target Function \\nGenerating training data ‚Äî \\nTo train our learning program, we need a set of training data, each describing a specific board state b and \\nthe training value V_train (b) for b. Each training example is an ordered pair <b,V_train(b)> \\nFor example, a training example may be <(x1 = 3, x2 = 0, x3 = 1, x4 = 0, x5 = 0, x6 = 0), +100\">. This is an \\nexample where black has won the game since x2 = 0 or red has no remaining pieces. However, such clean \\nvalues of V_train (b) can be obtained only for board value b that are clear win, loss or draw. \\nIn above case, assigning a training value V_train(b) for the specific boards b that are clean win, loss or \\ndraw is direct as they are direct training experience. But in the case of indirect training experience, \\nassigning a training value V_train(b) for the intermediate boards is difficult. In such case, the training \\nvalues are updated using temporal difference learning. Temporal difference (TD) learning is a concept \\ncentral to reinforcement learning, in which learning happens through the iterative correction of your \\nestimated returns towards a more accurate target return. \\nLet Successor(b) denotes the next board state following b for which it is again the program‚Äôs turn to \\nmove. ^V is the learner‚Äôs current approximation to V. Using these information, assign the training value \\nof V_train(b) for any intermediate board state b as below :  \\nV_train(b) ‚Üê ^V(Successor(b)) \\n \\nAdjusting the weights \\nNow its time to define the learning algorithm for choosing the weights and best fit the set of \\ntraining examples. One common approach is to define the best hypothesis as that which minimizes the \\nsquared error E between the training values and the values predicted by the hypothesis ^V. \\n \\n \\nThe learning algorithm should incrementally refine weights as more training examples become available \\nand it needs to be robust to errors in training data Least Mean Square (LMS) training rule is the one \\ntraining algorithm that will adjust weights a small amount in the direction that reduces the error. \\n \\nThe LMS algorithm is defined as follows:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 16}, page_content='12 \\n \\n \\n \\n1.4.5 Final Design for Checkers Learning system \\nThe final design of our checkers learning system can be naturally described by four distinct \\nprogram modules that represent the central components in many learning systems. \\n1. The performance System ‚Äî Takes a new board as input and outputs a trace of the game it played \\nagainst itself. \\n2. The Critic ‚Äî Takes the trace of a game as an input and outputs a set of training examples of the \\ntarget function. \\n3. The Generalizer ‚Äî Takes training examples as input and outputs a hypothesis that estimates the \\ntarget function. Good generalization to new cases is crucial. \\n4. The Experiment Generator ‚Äî Takes the current hypothesis (currently learned function) as input and \\noutputs a new problem (an initial board state) for the performance system to explore. \\n \\n \\nFinal design of the checkers learning program. \\n \\n1.5 Types of Learning \\nIn general, machine learning algorithms can be classified into three types. \\n\\uf0b7 \\nSupervised learning \\n\\uf0b7 \\nUnsupervised learning \\n\\uf0b7 \\nReinforcement learning \\n \\n1.5.1 Supervised learning \\nA training set of examples with the correct responses (targets) is provided and, based on this \\ntraining set, the algorithm generalises to respond correctly to all possible inputs. This is also called \\nlearning from exemplars. Supervised learning is the machine learning task of learning a function that \\nmaps an input to an output based on example input-output pairs. \\n \\nIn supervised learning, each example in the training set is a pair consisting of an input object \\n(typically a vector) and an output value. A supervised learning algorithm analyzes the training data and \\nproduces a function, which can be used for mapping new examples. In the optimal case, the function \\nwill correctly determine the class labels for unseen instances. Both classification and regression'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 17}, page_content='13 \\n \\nproblems are supervised learning problems. A wide range of supervised learning algorithms are \\navailable, each with its strengths and weaknesses. There is no single learning algorithm that works best \\non all supervised learning problems. \\n \\n \\nFigure 1.4: Supervised learning \\n \\n \\n \\nRemarks \\nA ‚Äúsupervised learning‚Äù is so called because the process of an algorithm learning from the \\ntraining dataset can be thought of as a teacher supervising the learning process. We know the correct \\nanswers (that is, the correct outputs), the algorithm iteratively makes predictions on the training data \\nand is corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of \\nperformance. \\n \\nExample \\nConsider the following data regarding patients entering a clinic. The data consists of the gender \\nand age of the patients and each patient is labeled as ‚Äúhealthy‚Äù or ‚Äúsick‚Äù. \\n \\n \\n \\n1.5.2 Unsupervised learning \\nCorrect responses are not provided, but instead the algorithm tries to identify similarities \\nbetween the inputs so that inputs that have something in common are categorised together. The \\nstatistical approach to unsupervised learning is \\nknown as density estimation. \\n \\nUnsupervised learning is a type of machine learning algorithm used to draw inferences from \\ndatasets consisting of input data without labeled responses. In unsupervised learning algorithms, a \\nclassification or categorization is not included in the observations. There are no output values and so \\nthere is no estimation of functions. Since the examples given to the learner are unlabeled, the accuracy \\nof the structure that is output by the algorithm cannot be evaluated. The most common unsupervised \\nlearning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 18}, page_content=\"14 \\n \\nor grouping in data. \\n \\nExample \\nConsider the following data regarding patients entering a clinic. The data consists of the gender \\nand age of the patients. \\n \\nBased on this data, can we infer anything regarding the patients entering the clinic? \\n \\n1.5.3 Reinforcement learning \\nThis is somewhere between supervised and unsupervised learning. The algorithm gets told \\nwhen the answer is wrong, but does not get told how to correct it. It has to explore and try out different \\npossibilities until it works out how to get the answer right. Reinforcement learning is sometime called \\nlearning with a critic because of this monitor that scores the answer, but does not suggest \\nimprovements. \\n \\nReinforcement learning is the problem of getting an agent to act in the world so as to maximize \\nits rewards. A learner (the program) is not told what actions to take as in most forms of machine \\nlearning, but instead must discover which actions yield the most reward by trying them. In the most \\ninteresting and challenging cases, actions may affect not only the immediate reward but also the next \\nsituations and, through that, all subsequent rewards. \\n \\nExample \\nConsider teaching a dog a new trick: we cannot tell it what to do, but we can reward/punish it if \\nit does the right/wrong thing. It has to find out what it did that made it get the reward/punishment. We \\ncan use a similar method to train computers to do many tasks, such as playing backgammon or chess, \\nscheduling jobs, and controlling robot limbs. Reinforcement learning is different from supervised \\nlearning. Supervised learning is learning from examples provided by a knowledgeable expert. \\n \\n1.6 PERSPECTIVES AND ISSUES IN MACHINE LEARNING \\n \\nPerspectives in Machine Learning \\nOne useful perspective on machine learning is that it involves searching a very large space of \\npossible hypotheses to determine one that best fits the observed data and any prior knowledge held by \\nthe learner. \\nFor example, consider the space of hypotheses that could in principle be output by the above checkers \\nlearner. This hypothesis space consists of all evaluation functions that can be represented by some \\nchoice of values for the weights wo through w6. The learner's task is thus to search through this vast \\nspace to locate the hypothesis that is most consistent with the available training examples. The LMS \\nalgorithm for fitting weights achieves this goal by iteratively tuning the weights, adding a correction to \\neach weight each time the hypothesized evaluation function predicts a value that differs from the \\ntraining value. This algorithm works well when the hypothesis representation considered by the learner \\ndefines a continuously parameterized space of potential hypotheses.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 19}, page_content=\"15 \\n \\nMany of the chapters in this book present algorithms that search a hypothesis space defined by \\nsome underlying representation (e.g., linear functions, logical descriptions, decision trees, artificial \\nneural networks). These different hypothesis representations are appropriate for learning different \\nkinds of target functions. For each of these hypothesis representations, the corresponding learning \\nalgorithm takes advantage of a different underlying structure to organize the search through the \\nhypothesis space.  \\n \\nThroughout this book we will return to this perspective of learning as a search problem in order \\nto characterize learning methods by their search strategies and by the underlying structure of the \\nsearch spaces they explore. We will also find this viewpoint useful in formally analyzing the relationship \\nbetween the size of the hypothesis space to be searched, the number of training examples available, \\nand the confidence we can have that a hypothesis consistent with the training data will correctly \\ngeneralize to unseen examples. \\n \\nIssues in Machine Learning \\nOur checkers example raises a number of generic questions about machine learning. The field of \\nmachine learning, and much of this book, is concerned with answering questions such as the following: \\n \\n\\uf0b7 \\nWhat algorithms exist for learning general target functions from specific training examples? In \\nwhat settings will particular algorithms converge to the desired function, given sufficient \\ntraining data? Which algorithms perform best for which types of problems and representations? \\n\\uf0b7 \\nHow much training data is sufficient? What general bounds can be found to relate the \\nconfidence in learned hypotheses to the amount of training experience and the character of the \\nlearner's hypothesis space? \\n\\uf0b7 \\nWhen and how can prior knowledge held by the learner guide the process of generalizing from \\nexamples? Can prior knowledge be helpful even when it is only approximately correct? \\n\\uf0b7 \\nWhat is the best strategy for choosing a useful next training experience, and how does the \\nchoice of this strategy alter the complexity of the learning problem?  \\n\\uf0b7 \\nWhat is the best way to reduce the learning task to one or more function approximation \\nproblems? Put another way, what specific functions should the system attempt to learn? Can \\nthis process itself be automated?  \\n\\uf0b7 \\nHow can the learner automatically alter its representation to improve its ability to represent \\nand learn the target function? \\n \\n1.7 Version Spaces \\nDefinition (Version space). A concept is complete if it covers all positive examples. \\n \\nA concept is consistent if it covers none of the negative examples. The version space is the set of all \\ncomplete and consistent concepts. This set is convex and is fully defined by its least and most general \\nelements. \\n \\nThe key idea in the CANDIDATE-ELIMINATION algorithm is to output a description of the set of all \\nhypotheses consistent with the training examples \\n \\n1.7.1 Representation \\nThe Candidate ‚Äì Elimination  algorithm finds all describable hypotheses that are consistent with the\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 20}, page_content=\"16 \\n \\nobserved training examples. In order to define this algorithm precisely, we begin with a few basic \\ndefinitions. First, let us say that a hypothesis is consistent with the training examples if it correctly \\nclassifies these examples. \\n \\nDefinition: A hypothesis h is consistent with a set of training examples D if and only if h(x) = c(x) for \\neach example (x, c(x)) in D. \\n \\n \\n \\nNote difference between definitions of consistent and satisfies  \\n\\uf0b7 \\nAn example x is said to satisfy hypothesis h when h(x) = 1, regardless of whether x is a positive \\nor negative example of the target concept.  \\n\\uf0b7 \\nAn example x is said to consistent with hypothesis h iff h(x) = c(x)  \\n \\nDefinition: version space- The version space, denoted V SH, D with respect to hypothesis space H and \\ntraining examples D, is the subset of hypotheses from H consistent with the training examples in D \\n \\n \\n \\n1.7.2 The LIST-THEN-ELIMINATION algorithm  \\nThe LIST-THEN-ELIMINATE algorithm first initializes the version space to contain all hypotheses in H \\nand then eliminates any hypothesis found inconsistent with any training example. \\n \\n1. VersionSpace c a list containing every hypothesis in H  \\n2. \\nFor each training example, (x, c(x)) remove from VersionSpace any hypothesis h for which h(x) ‚â† c(x)  \\n3. \\nOutput the list of hypotheses in VersionSpace \\n \\n\\uf0b7 \\nList-Then-Eliminate works in principle, so long as version space is finite. \\n\\uf0b7 \\nHowever, since it requires exhaustive enumeration of all hypotheses in practice it is not feasible.  \\n \\nA More Compact Representation for Version Spaces \\nThe version space is represented by its most general and least general members. These members form general \\nand specific boundary sets that delimit the version space within the partially ordered hypothesis space.  \\nDefinition: The general boundary G, with respect to hypothesis space H and training data D, is the set of \\nmaximally general members of H consistent with D \\n \\nG \\uf0ba{g \\uf0ce H | Consistent (g, D)\\uf0d9(\\uf0d8\\uf024g' \\uf0ce H)[(g' \\uf03e g) \\uf0d9 Consistent(g', D)]} \\ng \\n \\nDefinition: The specific boundary S, with respect to hypothesis space H and training data D, is the set of \\nminimally general (i.e., maximally specific) members of H consistent with D. \\n \\nS \\uf0ba{s \\uf0ce H | Consistent (s, D)\\uf0d9(\\uf0d8\\uf024s' \\uf0ce H)[(s \\uf03e s') \\uf0d9 Consistent(s', D)]} \\ng \\n \\nTheorem: Version Space representation theorem  \\nTheorem: Let X be an arbitrary set of instances and Let H be a set of Boolean-valued hypotheses defined over X. \\nLet c: X ‚Üí{O, 1} be an arbitrary target concept defined over X, and let D be an arbitrary set of training examples\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 21}, page_content='17 \\n \\n{(x, c(x))). For all X, H, c, and D such that S and G are well defined, \\n \\nVS \\n={ h \\uf0ce H | (\\uf024s \\uf0ce S ) (\\uf024g \\uf0ce G ) ( g \\uf0b3 h \\uf0b3 s )} \\nH,D \\ng \\ng \\n \\nTo Prove: \\n1. Every h satisfying the right hand side of the above expression is in VS \\n                                                                                                                                            H, D \\n2. Every member of VS satisfies the right-hand side of the expression \\n                                         H, D \\n \\nSketch of proof: \\n1. let g, h, s be arbitrary members of G, H, S respectively with g \\uf0b3g h \\uf0b3g s \\n\\uf0b7 By the definition of S, s must be satisfied by all positive examples in D. Because h \\uf0b3g s, \\nh must also be satisfied by all positive examples in D. \\n\\uf0b7 By the definition of G, g cannot be satisfied by any negative example in D, and because g \\uf0b3g h \\nh cannot be satisfied by any negative example in D. Because h is satisfied by all positive \\nexamples in D and by no negative examples in D, h is consistent with D, and therefore h is a \\nmember of VSH,D. \\n2. It can be proven by assuming some h in VSH,D,that does not satisfy the right-hand side of \\nthe expression, then showing that this leads to an inconsistency \\n1.7.3 CANDIDATE-ELIMINATION Learning Algorithm \\n \\nThe CANDIDATE-ELIMINTION algorithm computes the version space containing all hypotheses \\nfrom H that are consistent with an observed sequence of training examples. \\n \\nInitialize G to the set of maximally general hypotheses in H Initialize S to the set of maximally specific \\nhypotheses in H For each training example d, do \\n‚Ä¢ \\nIf d is a positive example \\n‚Ä¢ \\nRemove from G any hypothesis inconsistent with d \\n‚Ä¢ \\nFor each hypothesis s in S that is not consistent with d \\n‚Ä¢ \\nRemove s from S \\n‚Ä¢ \\nAdd to S all minimal generalizations h of s such that \\n‚Ä¢ \\nh is consistent with d, and some member of G is more general than h \\n‚Ä¢ \\nRemove from S any hypothesis that is more general than another hypothesis in S \\n \\n‚Ä¢ If d is a negative example \\n‚Ä¢ \\nRemove from S any hypothesis inconsistent with d \\n‚Ä¢ \\nFor each hypothesis g in G that is not consistent with d \\n‚Ä¢ \\nRemove g from G'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 22}, page_content='18 \\n \\n‚Ä¢ \\nAdd to G all minimal specializations h of g such that \\n‚Ä¢ \\nh is consistent with d, and some member of S is more specific than h \\n‚Ä¢ \\nRemove from G any hypothesis that is less general than another hypothesis in G \\nCANDIDATE- ELIMINTION algorithm using version spaces \\n \\n1.7.4 An Illustrative Example \\n \\n \\nExample \\nSky \\nAirTemp \\nHumidity \\nWind \\nWater \\nForecast \\nEnjoySport \\n1 \\nSunny \\nWarm \\nNormal \\nStrong \\nWarm \\nSame \\nYes \\n2 \\nSunny \\nWarm \\nHigh \\nStrong \\nWarm \\nSame \\nYes \\n3 \\nRainy \\nCold \\nHigh \\nStrong \\nWarm \\nChange \\nNo \\n4 \\nSunny \\nWarm \\nHigh \\nStrong \\nCool \\nChange \\nYes \\n \\nCANDIDATE-ELIMINTION algorithm begins by initializing the version space to the set of all \\nhypotheses in H; \\n \\nInitializing the G boundary set to contain the most general hypothesis in H \\nG0  \\uf0b3?,  ?,  ?,  ?,  ?, ?\\uf0b3\\n \\n \\nInitializing the S boundary set to contain the most specific (least general) hypothesis \\nS0  \\uf0b3\\uf0b3, \\uf0b3, \\uf0b3, \\uf0b3, \\uf0b3, \\uf0b3\\uf0b3\\n \\n \\n\\uf0b7 When the first training example is presented, the CANDIDATE-ELIMINTION algorithm checks the \\nS boundary and finds that it is overly specific and it fails to cover the positive example. \\n\\uf0b7 The boundary is therefore revised by moving it to the least more general hypothesis that covers \\nthis new example \\n\\uf0b7 No update of the G boundary is needed in response to this training example because Go \\ncorrectly covers this example \\n \\n \\n \\n \\n\\uf0b7 \\nWhen the second training example is observed, it has a similar effect of generalizing S further to S2, \\nleaving G again unchanged i.e., G2 = G1 = G0'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 23}, page_content='19 \\n \\n \\n \\n \\n\\uf0b7 Consider the third training example. This negative example reveals that the G boundary of \\nthe version space is overly general, that is, the hypothesis in G incorrectly predicts that this \\nnew example is a positive example. \\n\\uf0b7 The hypothesis in the G boundary must therefore be specialized until it correctly classifies \\nthis new negative example. \\n \\n \\n \\nGiven that there are six attributes that could be specified to specialize G2, why are there only three \\nnew hypotheses in G3? \\nFor example, the hypothesis h = (?, ?, Normal, ?, ?, ?) is a minimal specialization of G2 that \\ncorrectly labels the new example as a negative example, but it is not included in G3. The \\nreason this hypothesis is excluded is that it is inconsistent with the previously encountered \\npositive examples \\n \\nConsider the fourth training example.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 24}, page_content='20 \\n \\n \\n \\n \\n\\uf0b7 This positive example further generalizes the S boundary of the version space. It also \\nresults in removing one member of the G boundary, because this member fails to cover \\nthe new positive example \\n \\nAfter processing these four examples, the boundary sets S4 and G4 delimit the version space of all \\nhypotheses consistent with the set of incrementally observed training examples. \\n \\n \\n \\n \\n \\n1.8 Probably approximately correct learning \\n \\nIn computer science, computational learning theory (or just learning theory) is a subfield of \\nartificial intelligence devoted to studying the design and analysis of machine learning algorithms. In \\ncomputational learning theory, probably approximately correct learning (PAC learning) is a framework \\nfor mathematical analysis of machine learning algorithms. It was proposed in 1984 by Leslie Valiant. \\n \\nIn this framework, the learner (that is, the algorithm) receives samples and must select a \\nhypothesis from a certain class of hypotheses. The goal is that, with high probability (the ‚Äúprobably‚Äù \\npart), the selected hypothesis will have low generalization error (the ‚Äúapproximately correct‚Äù part). In \\nthis section we first give an informal definition of PAC-learnability. After introducing a few nore notions, \\nwe give a more formal, mathematically oriented, definition of PAC-learnability. At the end, we mention \\none of the applications of PAC-learnability. \\n \\nPAC-learnability \\nTo define PAC-learnability we require some specific terminology and related notations.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 25}, page_content='21 \\n \\n\\uf0b7 \\nLet X be a set called the instance space which may be finite or infinite. For example, X may be \\nthe set of all points in a plane. \\n\\uf0b7 \\nA concept class C for X is a family of functions c : X \\uf0e0 {0; 1}. A member of C is called a concept. \\nA concept can also be thought of as a subset of X. If C is a subset of X, it defines a unique \\nfunction ¬µc : X \\uf0e0 {0; 1} as follows: \\n \\n \\n \\n\\uf0b7 \\nA hypothesis h is also a function h : X \\uf0e0 {0; 1}. So, as in the case of concepts, a hypothesis can \\nalso be thought of as a subset of X. H will denote a set of hypotheses. \\n\\uf0b7 \\nWe assume that F is an arbitrary, but fixed, probability distribution over X. \\n\\uf0b7 \\nTraining examples are obtained by taking random samples from X. We assume that the samples \\nare randomly generated from X according to the probability distribution F. \\n \\nNow, we give below an informal definition of PAC-learnability. \\n \\nDefinition (informal) \\nLet X be an instance space, C a concept class for X, h a hypothesis in C and F an arbitrary, but fixed, \\nprobability distribution. The concept class C is said to be PAC-learnable if there is an algorithm A which, \\nfor samples drawn with any probability distribution F and any concept c –Ñ C, will with high probability \\nproduce a hypothesis h –Ñ C whose error is small. \\n \\nExamples \\n \\nTo illustrate the definition of PAC-learnability, let us consider some concrete examples. \\n \\n \\nFigure : An axis-aligned rectangle in the Euclidean plane \\n \\nExample'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 26}, page_content='22 \\n \\n\\uf0b7 \\nLet the instance space be the set X of all points in the Euclidean plane. Each point is represented \\nby its coordinates (x; y). So, the dimension or length of the instances is 2.  \\n\\uf0b7 \\nLet the concept class C be the set of all ‚Äúaxis-aligned rectangles‚Äù in the plane; that is, the set of \\nall rectangles whose sides are parallel to the coordinate axes in the plane (see Figure).  \\n\\uf0b7 \\nSince an axis-aligned rectangle can be defined by a set of inequalities of the following form \\nhaving four parameters \\n \\na ‚â§ x ‚â§ b,    c ‚â§ y ‚â§ d \\n \\nthe size of a concept is 4. \\n\\uf0b7 \\nWe take the set H of all hypotheses to be equal to the set C of concepts, H = C. \\n \\nGiven a set of sample points labeled positive or negative, let L be the algorithm which outputs the \\nhypothesis defined by the axis-aligned rectangle which gives the tightest fit to the positive examples \\n(that is, that rectangle with the smallest area that includes all of the positive examples and none of the \\nnegative examples) (see Figure bleow). \\n \\n \\nFigure : Axis-aligned rectangle which gives the tightest fit to the positive examples \\n \\nIt can be shown that, in the notations introduced above, the concept class C is PAC-learnable by the \\nalgorithm L using the hypothesis space H of all axis-aligned rectangles. \\n \\n1.9 Vapnik-Chervonenkis (VC) dimension \\nThe concepts of Vapnik-Chervonenkis dimension (VC dimension) and probably approximate \\ncorrect (PAC) learning are two important concepts in the mathematical theory of learnability and hence \\nare mathematically oriented. The former is a measure of the capacity (complexity, expressive power, \\nrichness, or flexibility) of a space of functions that can be learned by a classification algorithm. It was \\noriginally defined by Vladimir Vapnik and Alexey Chervonenkis in 1971. The latter is a framework for the \\nmathematical analysis of learning algorithms. The goal is to check whether the probability for a selected \\nhypothesis to be approximately correct is very high. The notion of PAC \\nlearning was proposed by Leslie Valiant in 1984. \\n \\nV-C dimension \\nLet H be the hypothesis space for some machine learning problem. The Vapnik-Chervonenkis dimension \\nof H, also called the VC dimension of H, and denoted by V C(H), is a measure of the complexity (or, \\ncapacity, expressive power, richness, or flexibility) of the space H. To define the VC dimension we \\nrequire the notion of the shattering of a set of instances.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 27}, page_content='23 \\n \\n \\nShattering of a set \\nLet D be a dataset containing N examples for a binary classification problem with class labels 0 and 1. \\nLet H be a hypothesis space for the problem. Each hypothesis h in H partitions D into two disjoint \\nsubsets as follows: \\n \\n \\nSuch a partition of S is called a ‚Äúdichotomy‚Äù in D. It can be shown that there are 2N possible dichotomies \\nin D. To each dichotomy of D there is a unique assignment of the labels ‚Äú1‚Äù and ‚Äú0‚Äù to the elements of \\nD. Conversely, if S is any subset of D then, S defines a unique hypothesis h as follows: \\n \\n \\nThus to specify a hypothesis h, we need only specify the set {x –Ñ D |  h(x) = 1}. Figure 3.1 shows all \\npossible dichotomies of D if D has three elements. In the figure, we have shown only one of the two sets \\nin a dichotomy, namely the set {x –Ñ D |  h(x) = 1}.The circles and ellipses represent such sets. \\n \\n \\n \\n \\nDefinition \\nA set of examples D is said to be shattered by a hypothesis space H if and only if for every dichotomy of \\nD there exists some hypothesis in H consistent with the dichotomy of D. \\n \\nThe following example illustrates the concept of Vapnik-Chervonenkis dimension. \\n \\nExample \\n \\nIn figure , we see that an axis-aligned rectangle can shatter four points in two dimensions. Then  VC(H), \\nwhen H is the hypothesis class of axis-aligned rectangles in two dimensions, is four. In calculating the VC \\ndimension, it is enough that we find four points that can be shattered; it is not necessary that we be \\nable to shatter any four points in two dimensions.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 28}, page_content='24 \\n \\n \\nFig: An axis-aligned rectangle can shattered four points. Only rectangle covering two points are shown. \\n \\nVC dimension may seem pessimistic. It tells us that using a rectangle as our hypothesis class, we can \\nlearn only datasets containing four points and not more. \\n \\n \\n \\n \\n \\n \\n \\nUnit II \\nSupervised and Unsupervised Learning \\n \\nTopics: Decision Trees: ID3, Classification and Regression Trees, Regression: Linear Regression, \\nMultiple Linear Regression, Logistic Regression, Neural Networks: Introduction, Perception, \\nMultilayer Perception, Support Vector Machines: Linear and Non-Linear, Kernel Functions, K \\nNearest Neighbors. Introduction to clustering, K-means clustering, K-Mode Clustering. \\n \\n2.1. Decision Tree \\nIntroduction Decision Trees are a type of Supervised Machine Learning (that is you explain what \\nthe input is and what the corresponding output is in the training data) where the data is continuously \\nsplit according to a certain parameter. The tree can be explained by two entities, namely decision \\nnodes and leaves. The leaves are the decisions or the final outcomes. And the decision nodes are where \\nthe data is split. \\n \\nAn example of a decision tree can be explained using above binary tree. Let‚Äôs say you want to predict \\nwhether a person is fit given their information like age, eating habit, and physical activity, etc. The'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 29}, page_content='25 \\n \\ndecision nodes here are questions like ‚ÄòWhat‚Äôs the age?‚Äô, ‚ÄòDoes he exercise?‚Äô, and ‚ÄòDoes he eat a lot of \\npizzas‚Äô? And the leaves, which are outcomes like either ‚Äòfit‚Äô, or ‚Äòunfit‚Äô. In this case this was a binary \\nclassification problem (a yes no type problem). There are two main types of Decision Trees: \\n1. Classification trees (Yes/No types) \\nWhat we have seen above is an example of classification tree, where the outcome was a variable like \\n‚Äòfit‚Äô or ‚Äòunfit‚Äô. Here the decision variable is Categorical. \\n \\n2. Regression trees (Continuous data types) \\nHere the decision or the outcome variable is Continuous, e.g. a number like 123.  Working Now that we \\nknow what a Decision Tree is, we‚Äôll see how it works internally. There are many algorithms out there \\nwhich construct Decision Trees, but one of the best is called as ID3 Algorithm. ID3 Stands for Iterative \\nDichotomiser 3. Before discussing the ID3 algorithm, we‚Äôll go through few definitions. Entropy Entropy, \\nalso called as Shannon Entropy is denoted by H(S) for a finite set S, is the measure of the amount of \\nuncertainty or randomness in data. \\n \\nIntuitively, it tells us about the predictability of a certain event. Example, consider a coin toss whose \\nprobability of heads is 0.5 and probability of tails is 0.5. Here the entropy is the highest possible, since \\nthere‚Äôs no way of determining what the outcome might be. Alternatively, consider a coin which has \\nheads on both the sides, the entropy of such an event can be predicted perfectly since we know \\nbeforehand that it‚Äôll always be heads. In other words, this event has no randomness hence it‚Äôs entropy \\nis zero. In particular, lower values imply less uncertainty while higher values imply high \\nuncertainty. Information Gain Information gain is also called as Kullback-Leibler divergence denoted by \\nIG(S,A) for a set S is the effective change in entropy after deciding on a particular attribute A. It \\nmeasures the relative change in entropy with respect to the independent variables \\n \\n\\uf028\\n\\uf029\\n\\uf028\\uf029\\n\\uf028\\n\\uf029\\nA\\nS\\nH\\nS\\nH\\nA\\nS\\nIG\\n,\\n,\\n\\uf02d\\n\\uf03d\\n \\nAlternatively, \\n \\n \\n \\nwhere IG(S, A) is the information gain by applying feature A. H(S) is the Entropy of the entire set, while \\nthe second term calculates the Entropy after applying the feature A, where P(x) is the probability of \\nevent x. Let‚Äôs understand this with the help of an example Consider a piece of data collected over the \\ncourse of 14 days where the features are Outlook, Temperature, Humidity, Wind and the outcome \\nvariable is whether Golf was played on the day. Now, our job is to build a predictive model which takes \\nin above 4 parameters and predicts whether Golf will be played on the day. We‚Äôll build a decision tree \\nto do that using ID3 algorithm. \\n \\nDay \\nOutlook \\nTemperature \\nHumidity \\nWind \\nPlay Golf \\nD1 \\nSunny \\nHot \\nHigh \\nWeak \\nNo \\nD2 \\nSunny \\nHot \\nHigh \\nStrong \\nNo \\nD3 \\nOvercast \\nHot \\nHigh \\nWeak \\nYes \\n\\uf028\\n\\uf029\\n\\uf028\\uf029\\n\\uf028\\uf029\\n\\uf028\\uf029\\n\\uf0e5\\n\\uf03d\\n\\uf02a\\n\\uf02d\\n\\uf03d\\nn\\ni\\nx\\nH\\nx\\nP\\nS\\nH\\nA\\nS\\nIG\\n0\\n,'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 30}, page_content='26 \\n \\nD4 \\nRain \\nMild \\nHigh \\nWeak \\nYes \\nD5 \\nRain \\nCool \\nNormal \\nWeak \\nYes \\nD6 \\nRain \\nCool \\nNormal \\nStrong \\nNo \\nD7 \\nOvercast \\nCool \\nNormal \\nStrong \\nYes \\nD8 \\nSunny \\nMild \\nHigh \\nWeak \\nNo \\nD9 \\nSunny \\nCool \\nNormal \\nWeak \\nYes \\nD10 \\nRain \\nMild \\nNormal \\nWeak \\nYes \\nD11 \\nSunny \\nMild \\nNormal \\nStrong \\nYes \\nD12 \\nOvercast \\nMild \\nHigh \\nStrong \\nYes \\nD13 \\nOvercast \\nHot \\nNormal \\nWeak \\nYes \\nD14 \\nRain \\nMild \\nHigh \\nStrong \\nNo \\n \\n2.1.1 ID3 \\n ID3 Algorithm will perform following tasks recursively \\n \\n1. Create root node for the tree \\n2. If all examples are positive, return leaf node ‚Äûpositive‚Äü \\n3. Else if all examples are negative, return leaf node ‚Äûnegative‚Äü \\n4. Calculate the entropy of current state H(S) \\n5. For each attribute, calculate the entropy with respect to the attribute ‚Äûx‚Äü denoted by H(S, x) \\n6. Select the attribute which has maximum value of IG(S, x) \\n7. Remove the attribute that offers highest IG from the set of attributes \\n8. Repeat until we run out of all attributes, or the decision tree has all leaf nodes. \\n \\nNow we‚Äüll go ahead and grow the decision tree. The initial step is to calculate H(S), the Entropy of the current state. \\nIn the above example, we can see in total there are 5 No‚Äüs and 9 Yes‚Äüs. \\n \\nYes \\nNo \\nTotal \\n9 \\n5 \\n14 \\n \\n \\nwhere ‚Äûx‚Äü are the possible values for an attribute. Here, attribute ‚ÄûWind‚Äü takes two possible values in the sample \\ndata, hence x = {Weak, Strong} we‚Äüll have to calculate: \\n \\n \\n \\nAmongst all the 14 examples we have 8 places where the wind is weak and 6 where the wind is Strong. \\n \\nWind = Weak \\nWind = Strong \\nTotal \\n8 \\n6 \\n14'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 31}, page_content='27 \\n \\n \\nNow out of the 8 Weak examples, 6 of them were ‚ÄûYes‚Äü for Play Golf and 2 of them were ‚ÄûNo‚Äü for ‚ÄûPlay Golf‚Äü. So, \\nwe have, \\n \\n \\nSimilarly, out of 6 Strong examples, we have 3 examples where the outcome was ‚ÄûYes‚Äü for Play Golf and 3 \\nwhere we had ‚ÄûNo‚Äü for Play Golf. \\n \\n \\n \\nRemember, here half items belong to one class while other half belong to other. Hence we have perfect randomness. \\nNow we have all the pieces required to calculate the Information Gain, \\n \\n \\n \\nWhich tells us the Information Gain by considering ‚ÄûWind‚Äü as the feature and give us information gain of 0.048. \\nNow we must similarly calculate the Information Gain for all the features. \\n \\n \\nWe can clearly see that IG(S, Outlook) has the highest information gain of 0.246, hence we chose Outlook \\nattribute  as the root node. At this point, the decision tree looks like.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 32}, page_content='28 \\n \\nHere we observe that whenever the outlook is Overcast, Play Golf is always ‚ÄòYes‚Äô, it‚Äôs no coincidence by \\nany chance, the simple tree resulted because of the highest information gain is given by the attribute \\nOutlook. Now how do we proceed from this point? We can simply apply recursion, you might want to \\nlook at the algorithm steps described earlier. Now that we‚Äôve used Outlook, we‚Äôve got three of them \\nremaining Humidity, Temperature, and Wind. And, we had three possible values of Outlook: Sunny, \\nOvercast, Rain. Where the Overcast node already ended up having leaf node ‚ÄòYes‚Äô, so we‚Äôre left with \\ntwo subtrees to compute: Sunny and Rain. \\n \\nTable where the value of Outlook is Sunny looks like: \\nTemperature \\nHumidity \\nWind \\nPlay Golf \\nHot \\nHigh \\nWeak \\nNo \\nHot \\nHigh \\nStrong \\nNo \\nMild \\nHigh \\nWeak \\nNo \\nCool \\nNormal \\nWeak \\nYes \\nMild \\nNormal \\nStrong \\nYes \\n \\n \\nAs we can see the highest Information Gain is given by Humidity. Proceeding in the same way with \\n \\nwill give us Wind as the one with highest information gain. The final Decision Tree looks something like \\nthis. The final Decision Tree looks something like this. \\n \\n \\n \\n2.1.2. Classification and Regression Trees \\n2.1.2.1. Classification Trees \\nA classification tree is an algorithm where the target variable is fixed or categorical. The \\nalgorithm is then used to identify the ‚Äúclass‚Äù within which a target variable would most likely fall. \\nAn example of a classification-type problem would be determining who will or will not subscribe to a \\ndigital platform; or who will or will not graduate from high school. \\nThese are examples of simple binary classifications where the categorical dependent variable can \\nassume only one of two, mutually exclusive values. In other cases, you might have to predict among a \\nnumber of different variables. For instance, you may have to predict which type of smartphone a \\nconsumer may decide to purchase. \\nIn such cases, there are multiple values for the categorical dependent variable. Here‚Äôs what a classic \\nclassification tree looks like'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 33}, page_content='29 \\n \\n \\n2.1.2.2. Regression Trees \\nA regression tree refers to an algorithm where the target variable is and the algorithm is used to \\npredict it‚Äôs value. As an example of a regression type problem, you may want to predict the selling \\nprices of a residential house, which is a continuous dependent variable. \\nThis will depend on both continuous factors like square footage as well as categorical factors like the \\nstyle of home, area in which the property is located and so on. \\n \\n \\n \\nWhen to use Classification and Regression Trees \\nClassification trees are used when the dataset needs to be split into classes which belong to the \\nresponse variable. In many cases, the classes Yes or No. \\nIn other words, they are just two and mutually exclusive. In some cases, there may be more than two \\nclasses in which case a variant of the classification tree algorithm is used. \\nRegression trees, on the other hand, are used when the response variable is continuous. For instance, if \\nthe response variable is something like the price of a property or the temperature of the day, a \\nregression tree is used. \\nIn other words, regression trees are used for prediction-type problems while classification trees are \\nused for classification-type problems. \\n \\nHow Classification and Regression Trees Work \\nA classification tree splits the dataset based on the homogeneity of data. Say, for instance, \\nthere are two variables; income and age; which determine whether or not a consumer will buy a \\nparticular kind of phone. \\nIf the training data shows that 95% of people who are older than 30 bought the phone, the data gets \\nsplit there and age becomes a top node in the tree. This split makes the data ‚Äú95% pure‚Äù. Measures of \\nimpurity like entropy or Gini index are used to quantify the homogeneity of the data when it comes to \\nclassification trees.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 34}, page_content='30 \\n \\nIn a regression tree, a regression model is fit to the target variable using each of the independent \\nvariables. After this, the data is split at several points for each independent variable. \\nAt each such point, the error between the predicted values and actual values is squared to get ‚ÄúA Sum \\nof Squared Errors‚Äù (SSE). The SSE is compared across the variables and the variable or point which has \\nthe lowest SSE is chosen as the split point. This process is continued recursively. \\n \\n \\nAdvantages of Classification and Regression Trees \\nThe purpose of the analysis conducted by any classification or regression tree is to create a set of if-else \\nconditions that allow for the accurate prediction or classification of a case. \\n(i) The Results are Simplistic \\nThe interpretation of results summarized in classification or regression trees is usually fairly simple. The \\nsimplicity of results helps in the following ways. \\n\\uf0b7 \\nIt allows for the rapid classification of new observations. That‚Äôs because it is much simpler to \\nevaluate just one or two logical conditions than to compute scores using complex nonlinear \\nequations for each group. \\n\\uf0b7 \\nIt can often result in a simpler model which explains why the observations are either classified \\nor predicted in a certain way. For instance, business problems are much easier to explain with \\nif-then statements than with complex nonlinear equations. \\n(ii) Classification and Regression Trees are Nonparametric & Nonlinear \\nThe results from classification and regression trees can be summarized in simplistic if-then conditions. \\nThis negates the need for the following implicit assumptions. \\n\\uf0b7 \\nThe predictor variables and the dependent variable are linear. \\n\\uf0b7 \\nThe predictor variables and the dependent variable follow some specific nonlinear link function. \\n\\uf0b7 \\nThe predictor variables and the dependent variable are monotonic. \\nSince there is no need for such implicit assumptions, classification and regression tree methods are well \\nsuited to data mining. This is because there is very little knowledge or assumptions that can be made \\nbeforehand about how the different variables are related. \\nAs a result, classification and regression trees can actually reveal relationships between these variables \\nthat would not have been possible using other techniques. \\n(iii) Classification and Regression Trees Implicitly Perform Feature Selection \\nFeature selection or variable screening is an important part of analytics. When we use decision trees, \\nthe top few nodes on which the tree is split are the most important variables within the set. As a result, \\nfeature selection gets performed automatically and we don‚Äôt need to do it again. \\nLimitations of Classification and Regression Trees'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 35}, page_content='31 \\n \\nClassification and regression tree tutorials, as well as classification and regression tree ppts, exist in \\nabundance. This is a testament to the popularity of these decision trees and how frequently they are \\nused. However, these decision trees are not without their disadvantages. \\nThere are many classification and regression trees examples where the use of a decision tree has not \\nled to the optimal result. Here are some of the limitations of classification and regression trees. \\n(i) Overfitting \\nOverfitting occurs when the tree takes into account a lot of noise that exists in the data and \\ncomes up with an inaccurate result. \\n(ii) High variance \\nIn this case, a small variance in the data can lead to a very high variance in the prediction, \\nthereby affecting the stability of the outcome. \\n(iii) Low bias \\nA decision tree that is very complex usually has a low bias. This makes it very difficult for the \\nmodel to incorporate any new data. \\n \\nWhat is a CART in Machine Learning? \\nA Classification and Regression Tree (CART) is a predictive algorithm used in machine learning. It \\nexplains how a target variable‚Äôs values can be predicted based on other values. \\nIt is a decision tree where each fork is a split in a predictor variable and each node at the end has a \\nprediction for the target variable. \\nThe CART algorithm is an important decision tree algorithm that lies at the foundation of machine \\nlearning. Moreover, it is also the basis for other powerful machine learning algorithms like bagged \\ndecision trees, random forest and boosted decision trees. \\nSumming up \\nThe Classification and regression tree (CART) methodology is one of the oldest and most fundamental \\nalgorithms. It is used to predict outcomes based on certain predictor variables. \\nThey are excellent for data mining tasks because they require very little data pre-processing. Decision \\ntree models are easy to understand and implement which gives them a strong advantage when \\ncompared to other analytical models. \\n \\n2.2. Regression \\nRegression Analysis in Machine learning \\nRegression analysis is a statistical method to model the relationship between a dependent \\n(target) and independent (predictor) variables with one or more independent variables. More \\nspecifically, Regression analysis helps us to understand how the value of the dependent variable is \\nchanging corresponding to an independent variable when other independent variables are held fixed. It \\npredicts continuous/real values such as temperature, age, salary, price, etc. \\n \\nWe can understand the concept of regression analysis using the below example: \\n \\nExample: Suppose there is a marketing company A, who does various advertisement every year and get \\nsales on that. The below list shows the advertisement made by the company in the last 5 years and the \\ncorresponding sales:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 36}, page_content='32 \\n \\n \\n \\nNow, the company wants to do the advertisement of $200 in the year 2019 and wants to know the \\nprediction about the sales for this year. So to solve such type of prediction problems in machine \\nlearning, we need regression analysis. \\nRegression is a supervised learning technique which helps in finding the correlation between variables \\nand enables us to predict the continuous output variable based on the one or more predictor variables. \\nIt is mainly used for prediction, forecasting, time series modeling, and determining the causal-effect \\nrelationship between variables. \\nIn Regression, we plot a graph between the variables which best fits the given datapoints, using this \\nplot, the machine learning model can make predictions about the data. In simple words, \"Regression \\nshows a line or curve that passes through all the datapoints on target-predictor graph in such a way \\nthat the vertical distance between the datapoints and the regression line is minimum.\" The distance \\nbetween datapoints and line tells whether a model has captured a strong relationship or not. \\n \\nSome examples of regression can be as: \\no \\nPrediction of rain using temperature and other factors \\no \\nDetermining Market trends \\no \\nPrediction of road accidents due to rash driving. \\n \\nTerminologies Related to the Regression Analysis: \\no \\nDependent Variable: The main factor in Regression analysis which we want to predict or \\nunderstand is called the dependent variable. It is also called target variable. \\no \\nIndependent Variable: The factors which affect the dependent variables or which are used to \\npredict the values of the dependent variables are called independent variable, also called as \\na predictor. \\no \\nOutliers: Outlier is an observation which contains either very low value or very high value in \\ncomparison to other observed values. An outlier may hamper the result, so it should be \\navoided. \\no \\nMulticollinearity: If the independent variables are highly correlated with each other than other \\nvariables, then such condition is called Multicollinearity. It should not be present in the dataset, \\nbecause it creates problem while ranking the most affecting variable. \\no \\nUnderfitting and Overfitting: If our algorithm works well with the training dataset but not well \\nwith test dataset, then such problem is called Overfitting. And if our algorithm does not \\nperform well even with training dataset, then such problem is called underfitting.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 37}, page_content='33 \\n \\nWhy do we use Regression Analysis? \\nAs mentioned above, Regression analysis helps in the prediction of a continuous variable. There are \\nvarious scenarios in the real world where we need some future predictions such as weather condition, \\nsales prediction, marketing trends, etc., for such case we need some technology which can make \\npredictions more accurately. So for such case we need Regression analysis which is a statistical method \\nand used in machine learning and data science. Below are some other reasons for using Regression \\nanalysis: \\no \\nRegression estimates the relationship between the target and the independent variable. \\no \\nIt is used to find the trends in data. \\no \\nIt helps to predict real/continuous values. \\no \\nBy performing the regression, we can confidently determine the most important factor, the \\nleast important factor, and how each factor is affecting the other factors. \\n \\nTypes of Regression \\nThere are various types of regressions which are used in data science and machine learning. Each type \\nhas its own importance on different scenarios, but at the core, all the regression methods analyze the \\neffect of the independent variable on dependent variables. Here we are discussing some important \\ntypes of regression which are given below: \\no \\nLinear Regression \\no \\nLogistic Regression \\no \\nPolynomial Regression \\no \\nSupport Vector Regression \\no \\nDecision Tree Regression \\no \\nRandom Forest Regression \\no \\nRidge Regression \\no \\nLasso Regression \\n \\n \\n \\n2.2.1. Linear Regression: \\no \\nLinear regression is a statistical regression method which is used for predictive analysis. \\no \\nIt is one of the very simple and easy algorithms which works on regression and shows the relationship \\nbetween the continuous variables. \\no \\nIt is used for solving the regression problem in machine learning. \\no \\nLinear regression shows the linear relationship between the independent variable (X-axis) and the \\ndependent variable (Y-axis), hence called linear regression.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 38}, page_content='34 \\n \\no \\nIf there is only one input variable (x), then such linear regression is called simple linear regression. And if \\nthere is more than one input variable, then such linear regression is called multiple linear regression. \\no \\nThe relationship between variables in the linear regression model can be explained using the below image. \\nHere we are predicting the salary of an employee on the basis of the year of experience. \\n \\nBelow is the mathematical equation for Linear regression: \\nY= aX+b  \\n \\nHere, Y = dependent variables (target variables), \\nX= Independent variables (predictor variables), \\na and b are the linear coefficients \\n \\nSome popular applications of linear regression are: \\no \\nAnalyzing trends and sales estimates \\no \\nSalary forecasting \\no \\nReal estate prediction \\no \\nArriving at ETAs in traffic. \\n2.2.2. Logistic Regression: \\no \\nLogistic regression is another supervised learning algorithm which is used to solve the classification \\nproblems. In classification problems, we have dependent variables in a binary or discrete format such as 0 \\nor 1. \\no \\nLogistic regression algorithm works with the categorical variable such as 0 or 1, Yes or No, True or False, \\nSpam or not spam, etc. \\no \\nIt is a predictive analysis algorithm which works on the concept of probability. \\no \\nLogistic regression is a type of regression, but it is different from the linear regression algorithm in the \\nterm how they are used. \\no \\nLogistic regression uses sigmoid function or logistic function which is a complex cost function. This \\nsigmoid function is used to model the data in logistic regression. The function can be represented as:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 39}, page_content='35 \\n \\n \\no \\nf(x)= Output between the 0 and 1 value. \\no \\nx= input to the function \\no \\ne= base of natural logarithm. \\nWhen we provide the input values (data) to the function, it gives the S-curve as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\no \\nIt uses the concept of threshold levels, values above the threshold level are rounded up to 1, and values \\nbelow the threshold level are rounded up to 0. \\nThere are three types of logistic regression: \\no \\nBinary(0/1, pass/fail) \\no \\nMulti(cats, dogs, lions) \\no \\nOrdinal(low, medium, high) \\nLinear Regression in Machine Learning \\nLinear regression is one of the easiest and most popular Machine Learning algorithms. It is a statistical method that \\nis used for predictive analysis. Linear regression makes predictions for continuous/real or numeric variables such \\nas sales, salary, age, product price, etc. \\nLinear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) \\nvariables, hence called as linear regression. Since linear regression shows the linear relationship, which means it \\nfinds how the value of the dependent variable is changing according to the value of the independent variable. \\nThe linear regression model provides a sloped straight line representing the relationship between the variables. \\nConsider the below image:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 40}, page_content='36 \\n \\n \\nMathematically, we can represent a linear regression as: \\n \\n \\n \\n \\n \\n \\n \\ny= a0+a1x+ Œµ \\n \\nHere, \\nY= Dependent Variable (Target Variable) \\nX= Independent Variable (predictor Variable) \\na0= intercept of the line (Gives an additional degree of freedom) \\na1 = Linear regression coefficient (scale factor to each input value). \\nŒµ = random error \\nThe values for x and y variables are training datasets for Linear Regression model representation. \\n \\nTypes of Linear Regression \\n \\nLinear regression can be further divided into two types of the algorithm: \\no \\nSimple Linear Regression: \\nIf a single independent variable is used to predict the value of a numerical dependent variable, then such a \\nLinear Regression algorithm is called Simple Linear Regression. \\no \\nMultiple Linear regression: \\nIf more than one independent variable is used to predict the value of a numerical dependent variable, then \\nsuch a Linear Regression algorithm is called Multiple Linear Regression. \\nLinear Regression Line: \\nA linear line showing the relationship between the dependent and independent variables is called a regression line. \\nA regression line can show two types of relationship: \\no \\nPositive Linear Relationship: \\nIf the dependent variable increases on the Y-axis and independent variable increases on X-axis, then such a \\nrelationship is termed as a Positive linear relationship.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 41}, page_content='37 \\n \\n \\no \\nNegative Linear Relationship: \\nIf the dependent variable decreases on the Y-axis and independent variable increases on the X-axis, then \\nsuch a relationship is called a negative linear relationship. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFinding the best fit \\nline: \\n \\nWhen working with linear regression, our main goal is to find the best fit line that means the error between \\npredicted values and actual values should be minimized. The best fit line will have the least error. \\nThe different values for weights or the coefficient of lines (a0, a1) gives a different line of regression, so we \\nneed to calculate the best values for a0 and a1 to find the best fit line, so to calculate this we use cost function. \\nCost function- \\no \\nThe different values for weights or coefficient of lines (a0, a1) gives the different line of regression, and the \\ncost function is used to estimate the values of the coefficient for the best fit line. \\no \\nCost function optimizes the regression coefficients or weights. It measures how a linear regression model \\nis performing. \\no \\nWe can use the cost function to find the accuracy of the mapping function, which maps the input variable \\nto the output variable. This mapping function is also known as Hypothesis function. \\nFor Linear Regression, we use the Mean Squared Error (MSE) cost function, which is the average of \\nsquared error occurred between the predicted values and actual values. It can be written as:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 42}, page_content='38 \\n \\nFor the above linear equation, MSE can be calculated as: \\n \\n \\n \\nWhere, \\nN=Total number of observation \\nYi = Actual value \\n(a1xi+a0)= Predicted value. \\n \\nResiduals: The distance between the actual value and predicted values is called residual. If the observed points are \\nfar from the regression line, then the residual will be high, and so cost function will high. If the scatter points are \\nclose to the regression line, then the residual will be small and hence the cost function. \\n \\nGradient Descent: \\no \\nGradient descent is used to minimize the MSE by calculating the gradient of the cost function. \\no \\nA regression model uses gradient descent to update the coefficients of the line by reducing the cost \\nfunction. \\no \\nIt is done by a random selection of values of coefficient and then iteratively update the values to reach the \\nminimum cost function. \\nModel Performance: \\nThe Goodness of fit determines how the line of regression fits the set of observations. The process of \\nfinding the best model out of various models is called optimization. It can be achieved by below method: \\n \\n1. R-squared method: \\no \\nR-squared is a statistical method that determines the goodness of fit. \\no \\nIt measures the strength of the relationship between the dependent and independent variables on a scale of \\n0-100%. \\no \\nThe high value of R-square determines the less difference between the predicted values and actual values \\nand hence represents a good model. \\no \\nIt is also called a coefficient of determination, or coefficient of multiple determination for multiple \\nregression. \\no \\nIt can be calculated from the below formula: \\n \\nAssumptions of Linear Regression \\nBelow are some important assumptions of Linear Regression. These are some formal checks while building a \\nLinear Regression model, which ensures to get the best possible result from the given dataset. \\n \\no \\nLinear relationship between the features and target: \\nLinear regression assumes the linear relationship between the dependent and independent variables. \\no \\nSmall or no multicollinearity between the features: \\nMulticollinearity means high-correlation between the independent variables. Due to multicollinearity, it \\nmay difficult to find the true relationship between the predictors and target variables. Or we can say, it is'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 43}, page_content='39 \\n \\ndifficult to determine which predictor variable is affecting the target variable and which is not. So, the \\nmodel assumes either little or no multicollinearity between the features or independent variables. \\no \\nHomoscedasticity Assumption: \\nHomoscedasticity is a situation when the error term is the same for all the values of independent variables. \\nWith homoscedasticity, there should be no clear pattern distribution of data in the scatter plot. \\no \\nNormal distribution of error terms: \\nLinear regression assumes that the error term should follow the normal distribution pattern. If error terms \\nare not normally distributed, then confidence intervals will become either too wide or too narrow, which \\nmay cause difficulties in finding coefficients. \\nIt can be checked using the q-q plot. If the plot shows a straight line without any deviation, which means \\nthe error is normally distributed. \\no \\nNo autocorrelations: \\nThe linear regression model assumes no autocorrelation in error terms. If there will be any correlation in \\nthe error term, then it will drastically reduce the accuracy of the model. Autocorrelation usually occurs if \\nthere is a dependency between residual errors. \\nSimple Linear Regression in Machine Learning \\nSimple Linear Regression is a type of Regression algorithms that models the relationship between a dependent \\nvariable and a single independent variable. The relationship shown by a Simple Linear Regression model is linear or \\na sloped straight line, hence it is called Simple Linear Regression. \\nThe key point in Simple Linear Regression is that the dependent variable must be a continuous/real value. \\nHowever, the independent variable can be measured on continuous or categorical values. \\nSimple Linear regression algorithm has mainly two objectives: \\no \\nModel the relationship between the two variables. Such as the relationship between Income and \\nexpenditure, experience and Salary, etc. \\no \\nForecasting new observations. Such as Weather forecasting according to temperature, Revenue of a \\ncompany according to the investments in a year, etc. \\nSimple Linear Regression Model: \\nThe Simple Linear Regression model can be represented using the below equation: \\ny= a0+a1x+ Œµ  \\n \\n \\nWhere, \\na0= It is the intercept of the Regression line (can be obtained putting x=0) \\na1= It is the slope of the regression line, which tells whether the line is increasing or decreasing. \\nŒµ = The error term. (For a good model it will be negligible) \\n \\n2.2.3. Multiple Linear Regressions \\nIn the previous topic, we have learned about Simple Linear Regression, where a single \\nIndependent/Predictor(X) variable is used to model the response variable (Y). But there may be various cases in \\nwhich the response variable is affected by more than one predictor variable; for such cases, the Multiple Linear \\nRegression algorithm is used.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 44}, page_content='40 \\n \\n \\nMoreover, Multiple Linear Regression is an extension of Simple Linear regression as it takes more than one \\npredictor variable to predict the response variable. \\n \\n We can define it as: \\n‚ÄúMultiple Linear Regression is one of the important regression algorithms which models the linear relationship \\nbetween a single dependent continuous variable and more than one independent variable.‚Äù \\n \\nExample: \\nPrediction of CO2 emission based on engine size and number of cylinders in a car. \\n \\nSome key points about MLR: \\no \\nFor MLR, the dependent or target variable(Y) must be the continuous/real, but the predictor or independent \\nvariable may be of continuous or categorical form. \\no \\nEach feature variable must model the linear relationship with the dependent variable. \\no \\nMLR tries to fit a regression line through a multidimensional space of data-points. \\nMLR equation: \\nIn Multiple Linear Regression, the target variable(Y) is a linear combination of multiple predictor variables \\nx1, x2, x3, ...,xn. Since it is an enhancement of Simple Linear Regression, so the same is applied for the multiple \\nlinear regression equation, the equation becomes: \\nY= b<sub>0</sub>+b<sub>1</sub>x<sub>1</sub>+ b<sub>2</sub>x<sub>2</sub>+ b<sub>3</sub>x<sub>\\n3</sub>+...... bnxn       ............... (a)  \\nWhere, \\nY= Output/Response variable \\nb0, b1, b2, b3 , bn....= Coefficients of the model. \\nx1, x2, x3, x4,...= Various Independent/feature variable \\nAssumptions for Multiple Linear Regression: \\no \\nA linear relationship should exist between the Target and predictor variables. \\no \\nThe regression residuals must be normally distributed. \\no \\nMLR assumes little or no multicollinearity (correlation between the independent variable) in data. \\n2.3. Neural Networks (ANN - Artificial Neural Network) \\n \\n2.3.1. Introduction \\nThe term \"Artificial Neural Network\" is derived from Biological neural networks that develop the structure \\nof a human brain. Similar to the human brain that has neurons interconnected to one another, artificial neural \\nnetworks also have neurons that are interconnected to one another in various layers of the networks. These neurons \\nare known as nodes.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 45}, page_content='41 \\n \\n \\n \\nThe given figure illustrates the typical diagram of Biological Neural Network. \\n \\nThe typical Artificial Neural Network looks something like the given figure. \\n \\n \\nDendrites from Biological Neural Network represent inputs in Artificial Neural Networks, cell nucleus represents \\nNodes, synapse represents Weights, and Axon represents Output. \\n \\nRelationship between Biological neural network and artificial neural network: \\n \\nBiological Neural Network \\nArtificial Neural Network \\nDendrites \\nInputs \\nCell nucleus \\nNodes \\nSynapse \\nWeights \\nAxon \\nOutput \\n \\nAn Artificial Neural Network in the field of Artificial intelligence where it attempts to mimic the network of \\nneurons makes up a human brain so that computers will have an option to understand things and make decisions in \\na human-like manner. The artificial neural network is designed by programming computers to behave simply like \\ninterconnected brain cells. \\n \\nThere are around 1000 billion neurons in the human brain. Each neuron has an association point somewhere in the \\nrange of 1,000 and 100,000. In the human brain, data is stored in such a manner as to be distributed, and we can'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 46}, page_content='42 \\n \\nextract more than one piece of this data when necessary from our memory parallelly. We can say that the human \\nbrain is made up of incredibly amazing parallel processors. \\n \\n \\nWe can understand the artificial neural network with an example, consider an example of a digital logic gate that \\ntakes an input and gives an output. \"OR\" gate, which takes two inputs. If one or both the inputs are \"On,\" then we \\nget \"On\" in output. If both the inputs are \"Off,\" then we get \"Off\" in output. Here the output depends upon input. \\nOur brain does not perform the same task. The outputs to inputs relationship keep changing because of the neurons \\nin our brain, which are \"learning.\" \\n \\nThe architecture of an artificial neural network: \\n \\n \\n \\nInput Layer: \\nAs the name suggests, it accepts inputs in several different formats provided by the programmer. \\n \\nHidden Layer: \\nThe hidden layer presents in-between input and output layers. It performs all the calculations to find \\nhidden features and patterns. \\n \\nOutput Layer: \\nThe input goes through a series of transformations using the hidden layer, which finally results in output \\nthat is conveyed using this layer. \\n \\nThe artificial neural network takes input and computes the weighted sum of the inputs and includes a bias. This \\ncomputation is represented in the form of a transfer function. \\n \\n \\n \\nIt determines weighted total is passed as an input to an activation function to produce the output. Activation \\nfunctions choose whether a node should fire or not. Only those who are fired make it to the output layer. There are \\ndistinctive activation functions available that can be applied upon the sort of task we are performing. \\n \\nAdvantages of Artificial Neural Network (ANN) \\n \\nParallel processing capability: \\nArtificial neural networks have a numerical value that can perform more than one task simultaneously. \\n \\nStoring data on the entire network: \\nData that is used in traditional programming is stored on the whole network, not on a database. The \\ndisappearance of a couple of pieces of data in one place doesn\\'t prevent the network from working. \\n \\nCapability to work with incomplete knowledge: \\nAfter ANN training, the information may produce output even with inadequate data. The loss of'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 47}, page_content=\"43 \\n \\nperformance here relies upon the significance of missing data. \\n \\nHaving a memory distribution: \\nFor ANN is to be able to adapt, it is important to determine the examples and to encourage the network \\naccording to the desired output by demonstrating these examples to the network. The succession of the network is \\ndirectly proportional to the chosen instances, and if the event can't appear to the network in all its aspects, it can \\nproduce false output. \\n \\nHaving fault tolerance: \\nExtortion of one or more cells of ANN does not prohibit it from generating output, and this feature makes \\nthe network fault-tolerance. \\n \\nDisadvantages of Artificial Neural Network: \\n \\nAssurance of proper network structure: \\nThere is no particular guideline for determining the structure of artificial neural networks. The appropriate \\nnetwork structure is accomplished through experience, trial, and error. \\n \\nUnrecognized behavior of the network: \\nIt is the most significant issue of ANN. When ANN produces a testing solution, it does not provide insight \\nconcerning why and how. It decreases trust in the network. \\n \\nHardware dependence: \\nArtificial neural networks need processors with parallel processing power, as per their structure. Therefore, \\nthe realization of the equipment is dependent. \\n \\nDifficulty of showing the issue to the network: \\nANNs can work with numerical data. Problems must be converted into numerical values before being \\nintroduced to ANN. The presentation mechanism to be resolved here will directly impact the performance of the \\nnetwork. It relies on the user's abilities. \\n \\nThe duration of the network is unknown: \\nThe network is reduced to a specific value of the error, and this value does not give us optimum results. \\n‚ÄúScience artificial neural networks that have steeped into the world in the mid-20th century are exponentially \\ndeveloping. In the present time, we have investigated the pros of artificial neural networks and the issues \\nencountered in the course of their utilization. It should not be overlooked that the cons of ANN networks, which are \\na flourishing science branch, are eliminated individually, and their pros are increasing day by day. It means that \\nartificial neural networks will turn into an irreplaceable part of our lives progressively important.‚Äù \\n \\nHow do artificial neural networks work? \\nArtificial Neural Network can be best represented as a weighted directed graph, where the artificial \\nneurons form the nodes. The association between the neurons outputs and neuron inputs can be viewed as the \\ndirected edges with weights. The Artificial Neural Network receives the input signal from the external source in the \\nform of a pattern and image in the form of a vector. These inputs are then mathematically assigned by the notations \\nx(n) for every n number of inputs.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 48}, page_content='44 \\n \\n \\n \\nAfterward, each of the input is multiplied by its corresponding weights ( these weights are the details \\nutilized by the artificial neural networks to solve a specific problem ). In general terms, these weights normally \\nrepresent the strength of the interconnection between neurons inside the artificial neural network. All the weighted \\ninputs are summarized inside the computing unit. \\n \\nIf the weighted sum is equal to zero, then bias is added to make the output non-zero or something else to \\nscale up to the system\\'s response. Bias has the same input, and weight equals to 1. Here the total of weighted inputs \\ncan be in the range of 0 to positive infinity. Here, to keep the response in the limits of the desired value, a certain \\nmaximum value is benchmarked, and the total of weighted inputs is passed through the activation function. \\nThe activation function refers to the set of transfer functions used to achieve the desired output. There is a \\ndifferent kind of the activation function, but primarily either linear or non-linear sets of functions. Some of the \\ncommonly used sets of activation functions are the Binary, linear, and Tan hyperbolic sigmoidal activation \\nfunctions. Let us take a look at each of them in details: \\n \\nBinary: \\nIn binary activation function, the output is either a one or a 0. Here, to accomplish this, there is a threshold \\nvalue set up. If the net weighted input of neurons is more than 1, then the final output of the activation function is \\nreturned as one or else the output is returned as 0. \\n \\nSigmoidal Hyperbolic: \\nThe Sigmoidal Hyperbola function is generally seen as an \"S\" shaped curve. Here the tan hyperbolic \\nfunction is used to approximate output from the actual net input. The function is defined as: \\nF(x) = (1/1 + exp(-????x)) \\nWhere ???? is considered the Steepness parameter. \\n \\nTypes of Artificial Neural Network: \\nThere are various types of Artificial Neural Networks (ANN) depending upon the human brain neuron and \\nnetwork functions, an artificial neural network similarly performs tasks. The majority of the artificial neural \\nnetworks will have some similarities with a more complex biological partner and are very effective at their expected \\ntasks. For example, segmentation or classification. \\n \\nFeedback ANN: \\nIn this type of ANN, the output returns into the network to accomplish the best-evolved results internally. \\nAs per the University of Massachusetts, Lowell Centre for Atmospheric Research. The feedback networks feed \\ninformation back into itself and are well suited to solve optimization issues. The Internal system error corrections \\nutilize feedback ANNs. \\n \\nFeed-Forward ANN: \\nA feed-forward network is a basic neural network comprising of an input layer, an output layer, and at least \\none layer of a neuron. Through assessment of its output by reviewing its input, the intensity of the network can be \\nnoticed based on group behavior of the associated neurons, and the output is decided. The primary advantage of this \\nnetwork is that it figures out how to evaluate and recognize input patterns.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 49}, page_content='45 \\n \\nPrerequisite \\nNo specific expertise is needed as a prerequisite before starting this tutorial. \\n \\nAudience \\nOur Artificial Neural Network Tutorial is developed for beginners as well as professionals, to help them \\nunderstand the basic concept of ANNs. \\n \\n2.3.2. PERCEPTRONS \\nOne type of ANN system is based on a unit called a perceptron, illustrated in below Figure: A \\nperceptron takes a vector of real-valued inputs, calculates a linear combination of these inputs, then \\noutputs a 1 if the result is greater than some threshold and -1 otherwise. More precisely, given inputs xl \\nthrough xn the output o(xl, . . . , xn) computed by the perceptron is \\n \\n \\n \\n \\n \\nwhere eachwi  is a real-valued constant, or weight, that determines the contribution of input xi  to \\nthe perceptron output. Notice the quantity \\n)\\n(\\n0\\nw\\n\\uf02d\\n  is a threshold that the weighted combination of \\ninputs \\nx\\nw\\nx\\nw\\nn\\nn\\n\\uf02b\\n\\uf02b....\\n1\\n1\\n must surpass in order for the perceptron to output a 1. \\n \\nTo simplify notation, we imagine an additional constant input\\n1\\n0 \\uf03d\\nx\\n, allowing us to write the above \\ninequality as\\n0\\n0\\n\\uf03e\\n\\uf0e5\\uf03d\\nn\\ni\\ni\\nix\\nw\\n, or in vector form as \\no\\nx\\nw \\uf03e\\n\\uf0ae\\n\\uf0ae\\n.\\n. For brevity, we will sometimes write the \\nperceptron function as \\n \\n  \\n \\nLearning a perceptron involves choosing values for the weights \\nw\\nw\\nn\\n,....,\\n0\\nTherefore, the space H of \\ncandidate hypotheses considered in perceptron learning is the set of all possible real-valued weight \\nvectors. \\n \\nRepresentational Power of Perceptrons: \\n \\nWe can view the perceptron as representing a hyperplane decision surface in the n--dimensional space \\nof instances (i.e., points). The perceptron outputs a 1 for instances lying on one side of the hyperplane'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 50}, page_content='46 \\n \\nand outputs a -1 for instances lying on the other side, as illustrated in Figure below The equation for this \\ndecision hyperplane is \\n0\\n.\\n\\uf03d\\n\\uf0ae\\n\\uf0ae\\nx\\nw\\n. Of course, some sets of positive and negative examples cannot be \\nseparated by any hyperplane. Those that can be separated are called linearly separable sets of \\nexamples.  \\n \\n \\nThe decision surface represented by a two-input perceptron. (a) A set of training examples and \\nthe decision surface of a perceptron that classifies them correctly. (b) A set of training examples that is \\nnot linearly separable (i.e., that cannot be correctly classified by any straight line). xl and x2 are the \\nPerceptron inputs. Positive examples are indicated by \"+\", negative by \"-\". The inputs are fed to multiple \\nunits, and the outputs of these units are then input to a second, final stage. One way is to represent the \\nBoolean function in disjunctive normal form (i.e., as the disjunction (OR) of a set of conjunctions (ANDs) \\nof the inputs and their negations). Note that the input to an AND perceptron can be negated simply by \\nchanging the sign of the corresponding input weight. Because networks of threshold units can represent \\na rich variety of functions and because single units alone cannot, we will generally be interested in \\nlearning multilayer networks of threshold units. \\n \\nThe Perceptron Training Rule \\nAlthough we are interested in learning networks of many interconnected units, let us begin by \\nunderstanding how to learn the weights for a single perceptron. Here the precise learning problem is to \\ndetermine a weight vector that causes the perceptron to produce the correct 1\\n\\uf0b1 output for each of the \\ngiven training examples. \\nSeveral algorithms are known to solve this learning problem. Here we consider two: the \\nperceptron rule and the delta rule. These two algorithms are guaranteed to converge to somewhat \\ndifferent acceptable hypotheses, under somewhat different conditions. They are important to ANNs \\nbecause they provide the basis for learning networks of many units. \\nOne way to learn an acceptable weight vector is to begin with random weights, then iteratively \\napply the perceptron to each training example, modifying the perceptron weights whenever it \\nmisclassifies an example. This process is repeated, iterating through the training examples as many \\ntimes as needed until \\nthe perceptron classifies all training examples correctly. Weights are modified at each step according to \\nthe perceptron training rule, which revises the weight wi associated with input xi according to the rule \\n \\n \\nHere t is the target output for the current training example, o is the output generated by the'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 51}, page_content='47 \\n \\nperceptron, and \\uf068is a positive constant called the learning rate. The role of the learning rate is to \\nmoderate the degree to which weights are changed at each step. It is usually set to some small value \\n(e.g., 0.1) and is sometimes made to decay as the number of weight-tuning iterations increases. \\nWhy should this update rule converge toward successful weight values? To get an intuitive feel, \\nconsider some specific cases. Suppose the training example is correctly classified already by the \\nperceptron. In this case, (t - o) is zero, making wi\\n\\uf044\\n zero, so that no weights are updated. Suppose the \\nperceptron outputs a -1, when the target output is +1. To make the perceptron output a+1 instead of -1 \\nin this case, the weights must be altered to increase the value of \\n\\uf0ae\\n\\uf0ae\\nx\\nw.\\n For example, if xi>0, then \\nincreasing wi will bring the perceptron closer to correctly classifying this example. Notice the training \\nrule will increase w, in this case, because (t - o),\\uf068, and xi are all positive. For example, if xi = .8, \\uf068 = 0.1, \\nt = 1, and o = - 1, then the weight update will be wi\\n\\uf044\\n = \\uf068 (t - o)xi = O.1(1 - (-1))0.8 = 0.16. On the \\nother hand, if t = -1 and o = 1, then weights associated with positive xi will be decreased rather than \\nincreased. \\n \\nIn fact, the above learning procedure can be proven to converge within a finite number of applications \\nof the perceptron training rule to a weight vector that correctly classifies all training examples, provided \\nthe training examples are linearly separable and provided a sufficiently small \\uf068 is used. If the data are \\nnot linearly separable, convergence is not assured. \\n \\nGradient Descent and the Delta Rule \\nAlthough the perceptron rule finds a successful weight vector when the training examples are \\nlinearly separable, it can fail to converge if the examples are not linearly separable. A second training \\nrule, called the delta rule, is designed to overcome this difficulty. If the training examples are not \\nlinearly separable, the delta rule converges toward a best-fit approximation to the target concept. The \\nkey idea behind the delta rule is to use gradient descent to search the hypothesis space of possible \\nweight vectors to find the weights that best fit the training examples. This rule is important because \\ngradient descent provides the basis for the BACKPROPAGATION algorithm, which can learn networks \\nwith many interconnected units. It is also important because gradient descent can serve as the basis for \\nlearning algorithms that must search through hypothesis spaces containing many different types of \\ncontinuously parameterized hypotheses.  \\nThe delta training rule is best understood by considering the task of training an unthresholded \\nperceptron; that is, a linear unit for which the output o is given by \\n \\n \\n \\nThus, a linear unit corresponds to the first stage of a perceptron, without the threshold. \\nIn order to derive a weight learning rule for linear units, let us begin by specifying a measure for the \\ntraining error of a hypothesis (weight vector), relative to the training examples. Although there are \\nmany ways to define this error, one common measure that will turn out to be especially convenient is \\n \\nwhere D is the set of training examples, td is the target output for training example d, and od is the \\noutput of the linear unit for training example d. By this definition, \\n\\uf028\\uf029\\n\\uf0ae\\nw\\nE\\n is simply half the squared'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 52}, page_content='48 \\n \\ndifference between the target output td and the hear unit output od, summed over all training \\nexamples. Here we characterize E as a function of \\uf028\\uf029\\n\\uf0ae\\nw , because the linear unit output o depends on this \\nweight vector. Of course E also depends on the particular set of training examples, but we assume these \\nare fixed during training, so we do not bother to write E as an explicit function of these. In particular, \\nthere we show that under certain conditions the hypothesis that minimizes E is also the most probable \\nhypothesis in H given the training data. \\n \\n2.3.2. Multi-layer Perceptron \\n \\nMulti-layer \\nPerceptron \\n(MLP) is \\na \\nsupervised \\nlearning \\nalgorithm \\nthat \\nlearns \\na \\nfunction f(‚ãÖ):Rm‚ÜíRo by training on a dataset, where m is the number of dimensions for input and o is the \\nnumber of dimensions for output. Given a set of features X=x1,x2,...,xm and a target y, it can learn a non-\\nlinear function approximator for either classification or regression. It is different from logistic \\nregression, in that between the input and the output layer, there can be one or more non-linear layers, \\ncalled hidden layers. Figure  shows a one hidden layer MLP with scalar output. \\n \\nThe leftmost layer, known as the input layer, consists of a set of neurons {xi|x1,x2,...,xm} representing the \\ninput features. Each neuron in the hidden layer transforms the values from the previous layer with a \\nweighted linear summation w1x1+w2x2+...+wmxm, followed by a non-linear activation function g(‚ãÖ):R‚ÜíR - \\nlike the hyperbolic tan function. The output layer receives the values from the last hidden layer and \\ntransforms them into output values. \\nThe module contains the public attributes coefs_ and intercepts_. coefs_ is a list of weight matrices, \\nwhere weight matrix at index i represents the weights between layer i and layer i+1. intercepts_ is a list \\nof bias vectors, where the vector at index i represents the bias values added to layer i+1. \\nThe advantages of Multi-layer Perceptron are: \\n\\uf0b7 \\nCapability to learn non-linear models. \\n\\uf0b7 \\nCapability to learn models in real-time (on-line learning) using partial_fit. \\nThe disadvantages of Multi-layer Perceptron (MLP) include: \\n\\uf0b7 \\nMLP with hidden layers have a non-convex loss function where there exists more than one local \\nminimum. Therefore different random weight initializations can lead to different validation \\naccuracy. \\n\\uf0b7 \\nMLP requires tuning a number of hyperparameters such as the number of hidden neurons, \\nlayers, and iterations. \\n\\uf0b7 \\nMLP is sensitive to feature scaling.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 53}, page_content='49 \\n \\n2.4. Support Vector Machines  \\n \\nSupport Vector Machine or SVM is one of the most popular Supervised Learning algorithms, \\nwhich is used for Classification as well as Regression problems. However, primarily, it is used for \\nClassification problems in Machine Learning. The goal of the SVM algorithm is to create the best line or \\ndecision boundary that can segregate n-dimensional space into classes so that we can easily put the \\nnew data point in the correct category in the future. This best decision boundary is called a hyperplane. \\nSVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are \\ncalled as support vectors, and hence algorithm is termed as Support Vector Machine. Consider the \\nbelow diagram in which there are two different categories that are classified using a decision boundary \\nor hyperplane:  \\n \\n \\nExample: SVM can be understood with the example that we have used in the KNN classifier. Suppose \\nwe see a strange cat that also has some features of dogs, so if we want a model that can accurately \\nidentify whether it is a cat or dog, so such a model can be created by using the SVM algorithm. We will \\nfirst train our model with lots of images of cats and dogs so that it can learn about different features of \\ncats and dogs, and then we test it with this strange creature. So as support vector creates a decision \\nboundary between these two data (cat and dog) and choose extreme cases (support vectors), it will see \\nthe extreme case of cat and dog. On the basis of the support vectors, it will classify it as a cat. Consider \\nthe below diagram: \\n \\n \\nSVM algorithm can be used for Face detection, image classification, text categorization, etc. \\nTypes of SVM \\nSVM can be of two types:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 54}, page_content='50 \\n \\no \\nLinear SVM: Linear SVM is used for linearly separable data, which means if a dataset can be \\nclassified into two classes by using a single straight line, then such data is termed as linearly \\nseparable data, and classifier is used called as Linear SVM classifier. \\no \\nNon-linear SVM: Non-Linear SVM is used for non-linearly separated data, which means if a \\ndataset cannot be classified by using a straight line, then such data is termed as non-linear data \\nand classifier used is called as Non-linear SVM classifier. \\nHyperplane and Support Vectors in the SVM algorithm: \\n \\nHyperplane: There can be multiple lines/decision boundaries to segregate the classes in n-\\ndimensional space, but we need to find out the best decision boundary that helps to classify the data \\npoints. This best boundary is known as the hyperplane of SVM. \\nThe dimensions of the hyperplane depend on the features present in the dataset, which means if there \\nare 2 features (as shown in image), then hyperplane will be a straight line. And if there are 3 features, \\nthen hyperplane will be a 2-dimension plane. \\nWe always create a hyperplane that has a maximum margin, which means the maximum distance \\nbetween the data points. \\n \\nSupport Vectors: \\nThe data points or vectors that are the closest to the hyperplane and which affect the position of the \\nhyperplane are termed as Support Vector. Since these vectors support the hyperplane, hence called a \\nSupport vector. How does SVM works? \\n \\n2.4.1. Linear SVM: \\nThe working of the SVM algorithm can be understood by using an example. Suppose we have a dataset \\nthat has two tags (green and blue), and the dataset has two features x1 and x2. We want a classifier \\nthat can classify the pair(x1, x2) of coordinates in either green or blue. Consider the below image: \\n \\nSo as it is 2-d space so by just using a straight line, we can easily separate these two classes. But there \\ncan be multiple lines that can separate these classes. Consider the below image:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 55}, page_content='51 \\n \\n \\n \\nHence, the SVM algorithm helps to find the best line or decision boundary; this best boundary or region \\nis called as a hyperplane. SVM algorithm finds the closest point of the lines from both the classes. These \\npoints are called support vectors. The distance between the vectors and the hyperplane is called \\nas margin. And the goal of SVM is to maximize this margin. The hyperplane with maximum margin is \\ncalled the optimal hyperplane.  \\n \\n2.4.2. Non-Linear SVM: \\n           If data is linearly arranged, then we can separate it by using a straight line, but for non-linear \\ndata, we cannot draw a single straight line. Consider the below image: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSo to separate these data points, we need to add one more dimension. For linear data, we have used two dimensions \\nx and y, so for non-linear data, we will add a third dimension z. It can be calculated as: \\nz=x2 +y2 \\nBy adding the third dimension, the sample space will become as below image:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 56}, page_content='52 \\n \\n \\nSo now, SVM will divide the datasets into classes in the following way. Consider the below image: \\n \\n \\nSince we are in 3-d Space, hence it is looking like a plane parallel to the x-axis. If we convert it in 2d \\nspace with z=1, then it will become as: \\n \\n \\nHence we get a circumference of radius 1 in case of non-linear data. \\n \\n2.4.3. SVM Kernels \\nIn practice, SVM algorithm is implemented with kernel that transforms an input data space into'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 57}, page_content='53 \\n \\nthe required form. SVM uses a technique called the kernel trick in which kernel takes a low dimensional \\ninput space and transforms it into a higher dimensional space. In simple words, kernel converts non-\\nseparable problems into separable problems by adding more dimensions to it. It makes SVM more \\npowerful, flexible and accurate. The following are some of the types of kernels used by SVM. \\nLinear Kernel \\nIt can be used as a dot product between any two observations. The formula of linear kernel is as below  \\n \\nK(x,xi)=sum(x‚àóxi) \\n \\nFrom the above formula, we can see that the product between two vectors say ùë• & ùë•ùëñ is the sum of the \\nmultiplication of each pair of input values. \\n \\n2.5. Unsupervised Machine Learning: \\n2.5.1. Introduction to clustering \\n \\nAs the name suggests, unsupervised learning is a machine learning technique in which models \\nare not supervised using training dataset. Instead, models itself find the hidden patterns and insights \\nfrom the given data. It can be compared to learning which takes place in the human brain while learning \\nnew things. It can be defined as: \\n \\n‚ÄúUnsupervised learning is a type of machine learning in which models are trained using \\nunlabeled dataset and are allowed to act on that data without any supervision.‚Äù \\n \\nUnsupervised learning cannot be directly applied to a regression or classification problem \\nbecause unlike supervised learning, we have the input data but no corresponding output data. The goal \\nof unsupervised learning is to find the underlying structure of dataset, group that data according to \\nsimilarities, and represent that dataset in a compressed format \\n \\nExample: Suppose the unsupervised learning algorithm is given an input dataset containing images of \\ndifferent types of cats and dogs. The algorithm is never trained upon the given dataset, which means it \\ndoes not have any idea about the features of the dataset. The task of the unsupervised learning \\nalgorithm is to identify the image features on their own. Unsupervised learning algorithm will perform \\nthis task by clustering the image dataset into the groups according to similarities between images. \\n \\n \\nWhy use Unsupervised Learning?'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 58}, page_content='54 \\n \\nBelow are some main reasons which describe the importance of Unsupervised Learning: \\no \\nUnsupervised learning is helpful for finding useful insights from the data. \\no \\nUnsupervised learning is much similar as a human learns to think by their own experiences, \\nwhich makes it closer to the real AI. \\no \\nUnsupervised learning works on unlabeled and uncategorized data which make unsupervised \\nlearning more important. \\no \\nIn real-world, we do not always have input data with the corresponding output so to solve such \\ncases, we need unsupervised learning. \\nWorking of Unsupervised Learning \\n \\nWorking of unsupervised learning can be understood by the below diagram: \\n \\n \\nHere, we have taken an unlabeled input data, which means it is not categorized and \\ncorresponding outputs are also not given. Now, this unlabeled input data is fed to the machine learning \\nmodel in order to train it. Firstly, it will interpret the raw data to find the hidden patterns from the data \\nand then will apply suitable algorithms such as k-means clustering, Decision tree, etc. \\nOnce it applies the suitable algorithm, the algorithm divides the data objects into groups according to \\nthe similarities and difference between the objects. \\nTypes of Unsupervised Learning Algorithm: \\nThe unsupervised learning algorithm can be further categorized into two types of problems:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 59}, page_content=\"55 \\n \\no \\nClustering: Clustering is a method of grouping the objects into clusters such that objects with \\nmost similarities remains into a group and has less or no similarities with the objects of another \\ngroup. Cluster analysis finds the commonalities between the data objects and categorizes them \\nas per the presence and absence of those commonalities. \\no \\nAssociation: An association rule is an unsupervised learning method which is used for finding \\nthe relationships between variables in the large database. It determines the set of items that \\noccurs together in the dataset. Association rule makes marketing strategy more effective. Such \\nas people who buy X item (suppose a bread) are also tend to purchase Y (Butter/Jam) item. A \\ntypical example of Association rule is Market Basket Analysis. \\n \\n \\nUnsupervised Learning algorithms: \\n \\nBelow is the list of some popular unsupervised learning algorithms: \\no \\nK-means clustering \\no \\nKNN (k-nearest neighbors) \\no \\nHierarchal clustering \\no \\nAnomaly detection \\no \\nNeural Networks \\no \\nPrinciple Component Analysis \\no \\nIndependent Component Analysis \\no \\nApriori algorithm \\no \\nSingular value decomposition \\nAdvantages of Unsupervised Learning \\no \\nUnsupervised learning is used for more complex tasks as compared to supervised learning \\nbecause, in unsupervised learning, we don't have labeled input data. \\no \\nUnsupervised learning is preferable as it is easy to get unlabeled data in comparison to labeled \\ndata. \\nDisadvantages of Unsupervised Learning \\no \\nUnsupervised learning is intrinsically more difficult than supervised learning as it does not have \\ncorresponding output. \\no \\nThe result of the unsupervised learning algorithm might be less accurate as input data is not \\nlabeled, and algorithms do not know the exact output in advance.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 60}, page_content='56 \\n \\nSupervised Learning \\nUnsupervised Learning \\nSupervised learning algorithms are trained using labeled data. \\nUnsupervised learning algorithms are trained using unlabeled data. \\nSupervised learning model takes direct feedback to check if it is predicting \\ncorrect output or not. \\nUnsupervised learning model does not take any feedback. \\nSupervised learning model predicts the output. \\nUnsupervised learning model finds the hidden patterns in data. \\nIn supervised learning, input data is provided to the model along with the \\noutput. \\nIn unsupervised learning, only input data is provided to the model. \\nThe goal of supervised learning is to train the model so that it can predict \\nthe output when it is given new data. \\nThe goal of unsupervised learning is to find the hidden patterns and \\nuseful insights from the unknown dataset. \\nSupervised learning needs supervision to train the model. \\nUnsupervised learning does not need any supervision to train the \\nmodel. \\nSupervised learning can be categorized \\nin Classification and Regression problems. \\nUnsupervised Learning can be classified \\nin Clustering and Associations problems. \\nSupervised learning can be used for those cases where we know the input \\nas well as corresponding outputs. \\nUnsupervised learning can be used for those cases where we have \\nonly input data and no corresponding output data. \\nSupervised learning model produces an accurate result. \\nUnsupervised learning model may give less accurate result as \\ncompared to supervised learning. \\nSupervised learning is not close to true Artificial intelligence as in this, we \\nfirst train the model for each data, and then only it can predict the correct \\noutput. \\nUnsupervised learning is more close to the true Artificial \\nIntelligence as it learns similarly as a child learns daily routine \\nthings by his experiences. \\nIt includes various algorithms such as Linear Regression, Logistic \\nRegression, Support Vector Machine, Multi-class Classification, Decision \\ntree, Bayesian Logic, etc. \\nIt includes various algorithms such as Clustering, KNN, and Apriori \\nalgorithm. \\n \\n2.5.2. K-Mean Clustering  \\n \\nk-means clustering algorithm \\nOne of the most used clustering algorithm is k-means. It allows to group the data according to the \\nexisting similarities among them in k clusters, given as input to the algorithm. I‚Äôll start with a simple \\nexample. \\nLet‚Äôs imagine we have 5 objects (say 5 people) and for each of them we know two features (height and \\nweight). We want to group them into k=2 clusters. \\n \\nOur dataset will look like this:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 61}, page_content='57 \\n \\n \\nFirst of all, we have to initialize the value of the centroids for our clusters. For instance, let‚Äôs choose \\nPerson 2 and Person 3 as the two centroids c1 and c2, so that c1=(120,32) and c2=(113,33). \\nNow we compute the euclidian distance between each of the two centroids and each point in the data. \\nIf you did all the calculations, you should have come up with the following numbers: \\n \\n \\nDistance of object from c1 \\nDistance of object from c2 \\nPerson 1 \\n52.3 \\n58.3 \\nPerson 2 \\n0 \\n7.1 \\nPerson 3 \\n7.1 \\n0 \\nPerson 4 \\n70.4 \\n75.4 \\nPerson 5 \\n13.9 \\n9.4 \\n \\nAt this point, we will assign each object to the cluster it is closer to (that is taking the minimum between \\nthe two computed distances for each object). \\n \\nWe can then arrange the points as follows: \\n \\nPerson 1 ‚Üí cluster 1 \\nPerson 2 ‚Üí cluster 1 \\nPerson 3 ‚Üí cluster 2 \\nPerson 4 ‚Üí cluster 1 \\nPerson 5‚Üí cluster 2 \\n \\nLet‚Äôs iterate, which means to redefine the centroids by calculating the mean of the members of each of \\nthe two clusters. \\n \\nSo c‚Äô1 = ((167+120+175)/3, (55+32+76)/3) = (154, 54.3) and c‚Äô2 = ((113+108)/2, (33+25)/2) = (110.5, 29) \\n \\nThen, we calculate the distances again and re-assign the points to the new centroids. \\n \\nWe repeat this process until the centroids don‚Äôt move anymore (or the difference between them is \\nunder a certain small threshold). \\n \\nIn our case, the result we get is given in the figure below. You can see the two different clusters labelled \\nwith two different colours and the position of the centroids, given by the crosses.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 62}, page_content='58 \\n \\n \\nHow to apply k-means? \\nAs you probably already know, I‚Äôm using Python libraries to analyze my data. The k-means algorithm is \\nimplemented in the scikit-learn package. To use it, you will just need the following line in your script: \\n \\nWhat if our data is‚Ä¶ non-numerical? \\n \\nAt this point, you will maybe have noticed something. The basic concept of k-means stands on \\nmathematical calculations (means, euclidian distances). But what if our data is non-numerical or, in \\nother words, categorical? Imagine, for instance, to have the ID code and date of birth of the five people \\nof the previous example, instead of their heights and weights. \\nWe could think of transforming our categorical values in numerical values and eventually apply k-\\nmeans. But beware: k-means uses numerical distances, so it could consider close two really distant \\nobjects that merely have been assigned two close numbers. \\n \\n \\n \\n \\n \\nk-modes is an extension of k-means. Instead of distances it uses dissimilarities (that is, \\nquantification of the total mismatches between two objects: the smaller this number, the more similar \\nthe two objects). And instead of means, it uses modes. A mode is a vector of elements that minimizes \\nthe dissimilarities between the vector itself and each object of the data. We will have as many modes as \\nthe number of clusters we required, since they act as centroids.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 63}, page_content='59 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUnit III \\nEnsemble and Probabilistic Learning \\n \\nEnsemble  Learning: Model Combination Schemes, Voting, Error-Correcting Output Codes, \\nBagging: Random Forest Trees, Boosting: Adaboost, Stacking. \\nProbabilistic Learning: Gaussian mixture models - The Expectation-Maximization (EM) \\nAlgorithm, Information Criteria, Nearest neighbour methods - Nearest Neighbour Smoothing, \\nEfficient Distance Computations: the KD-Tree, Distance Measures. \\n \\n3. Introduction:      \\n \\nEnsemble Learning \\nEnsemble learning usually produces more accurate solutions than a single model would.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 64}, page_content='60 \\n \\nEnsemble Learning is a technique that create multiple models and then combine them them to produce \\nimproved results. Ensemble learning usually produces more accurate solutions than a single model \\nwould.  \\n\\uf0b7 \\nEnsemble learning methods is applied to regression as well as classification.  \\no Ensemble learning for regression creates multiple repressors i.e. multiple regression \\nmodels such as linear, polynomial, etc.  \\no Ensemble learning for classification creates multiple classifiers i.e. multiple classification \\nmodels such as logistic, decision tress, KNN, SVM, etc. \\n \\nFigure 1: Ensemble learning view \\nWhich components to combine? \\n‚Ä¢ \\ndifferent learning algorithms \\n‚Ä¢ \\nsame learning algorithm trained in different ways \\n‚Ä¢ \\nsame learning algorithm trained the same way \\n \\nThere are two steps in ensemble learning:  \\nMultiples machine learning models were generated using same or different machine learning \\nalgorithm. These are called ‚Äúbase models‚Äù.  The prediction perform on the basis of base models. \\nTechniques/Methods in ensemble learning \\nVoting, Error-Correcting Output Codes, Bagging: Random Forest Trees, Boosting: Adaboost, Stacking. \\n3.1 Model Combination Schemes - Combining Multiple Learners \\nWe discussed many different learning algorithms in the previous chapters. Though these are \\ngenerally successful, no one single algorithm is always the most accurate. Now, we are going to discuss \\nmodels composed of multiple learners that complement each other so that by combining them, we \\nattain higher accuracy. \\n \\nThere are also different ways the multiple base-learners are combined to generate the final \\noutput: \\n \\nFigure2: General Idea - Combining Multiple Learners'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 65}, page_content='61 \\n \\n \\n \\nMultiexpert combination  \\nMultiexpert combination methods have base-learners that work in parallel. These methods can \\nin turn be divided into two: \\n \\n\\uf0b7 \\nIn the global approach, also called learner fusion, given an input, all base-learners generate an \\noutput and all these outputs are used.  \\nExamples are voting and stacking. \\n\\uf0b7 \\nIn the local approach, or learner selection, for example, in mixture of experts, there is a gating \\nmodel, which looks at the input and chooses one (or very few) of the learners as responsible for \\ngenerating the output. \\n \\nMultistage combination \\nMultistage combination methods use a serial approach where the next base-learner is trained \\nwith or tested on only the instances where the previous base-learners are not accurate enough. The \\nidea is that the base-learners (or the different representations they use) are sorted in increasing \\ncomplexity so that a complex base-learner is not used (or its complex representation is not extracted) \\nunless the preceding simpler base-learners are not confident.  \\nAn example is cascading. \\n \\nLet us say that we have L base-learners. We denote by dj(x) the prediction of base-learner Mj given the \\narbitrary dimensional input x. In the case of multiple representations, each Mj uses a different input \\nrepresentation xj . The final prediction is calculated from the predictions of \\nthe base-learners: \\n \\ny = f (d1, d2, . . . , dL |Œ¶) \\n \\nwhere f (¬∑) is the combining function with Œ¶ denoting its parameters.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 66}, page_content='62 \\n \\n \\nFigure 1: Base-learners are dj and their outputs are combined using f (¬∑). This is for a single \\noutput; in the case of classification, each base-learner has K outputs that are separately used to \\ncalculate yi, and then we choose the maximum.  Note that here all learners observe the same input; it \\nmay be the case that different learners observe different representations of the same input object or \\nevent.  \\n \\nWhen there are K outputs, for each learner there are dji(x), i = 1, . . . , K, \\nj = 1, . . . , L, and, combining them, we also generate K values, yi, i = 1, . . . , K and then for example in \\nclassification, we choose the class with \\nthe maximum yi value: \\n                                   \\n \\n \\n3.2 Voting \\nThe simplest way to combine multiple classifiers is by voting, which corresponds to taking a \\nlinear combination of the learn \\n \\ners, Refer figure 1. \\n \\n \\nThis is also known as ensembles and linear opinion pools. In the sim plest case, all learners are \\ngiven equal weight and we have simple voting that corresponds to taking an average. Still, taking a \\n(weighted) sum is only one of the possibilities and there are also other combination rules, as shown in \\ntable 1. If the outputs are not posterior probabilities, these rules require that outputs be normalized to \\nthe same scale \\n \\nTable 1 - Classifier combination rules'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 67}, page_content='63 \\n \\nAn example of the use of these rules is shown in table 2, which demonstrates the effects of \\ndifferent rules. Sum rule is the most intuitive and is the most widely used in practice. Median rule is \\nmore robust to outliers; minimum and maximum rules are pessimistic and optimistic, respectively. With \\nthe product rule, each learner has veto power; regardless of the other ones, if one learner has an \\noutput of 0, the overall output goes to 0. Note that after the combination rules, yi do not necessarily \\nsum up to 1. \\n \\nTable 2: Example of combination rules on three learners and three classes \\n \\nIn weighted sum, dji is the vote of learner j for class Ci and wj is the weight of its vote. Simple voting is a \\nspecial case where all voters have equal weight, namely, wj = 1/L. In classification, this is called plurality \\nvoting where the class having the maximum number of votes is the winner. \\n \\nWhen there are two classes, this is majority voting where the winning class gets more than half of the \\nvotes. If the voters can also supply the additional information of how much they vote for each class \\n(e.g., by the posterior probability), then after normalization, these can be used as weights in a weighted \\nvoting scheme. Equivalently, if dji are the class posterior probabilities, P(Ci | x,Mj ), then we can just sum \\nthem up (wj = 1/L) and choose the class with maximum yi . \\n \\nIn the case of regression, simple or weighted averaging or median can be used to fuse the outputs of \\nbase-regressors. Median is more robust to noise than the average. \\n \\nAnother possible way to find wj is to assess the accuracies of the learners (regressor or classifier) on a \\nseparate validation set and use that information to compute the weights, so that we give more weights \\nto more accurate learners. \\n \\nVoting schemes can be seen as approximations under a Bayesian framework with weights \\napproximating prior model probabilities, and model decisions approximating model-conditional \\nlikelihoods.  \\n \\n \\n \\nSimple voting corresponds to a uniform prior. If we have a prior distribution preferring simpler models, \\nthis would give larger weights to them. We cannot integrate over all models; we only choose a subset \\nfor which we believe P(Mj ) is high, or we can have another Bayesian step and calculate P(Ci | x,Mj ), the \\nprobability of a model given the sample, and sample high probable models from this density. \\n \\nLet us assume that dj are iid with expected value E[dj] and variance Var(dj ), then when we take a simple'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 68}, page_content='64 \\n \\naverage with wj = 1/L, the expected value and variance of the output are \\n \\n \\nWe see that the expected value does not change, so the bias does not change. But variance, and \\ntherefore mean square error, decreases as the number of independent voters, L, increases. In the \\ngeneral case, \\n \\n \\n \\nwhich implies that if learners are positively correlated, variance (and error) increase. We can thus view \\nusing different algorithms and input features as efforts to decrease, if not completely eliminate, the \\npositive correlation. \\n \\n3.3 Error-Correcting Output Codes \\nThe Error-Correcting Output Codes method is a technique that allows a multi-class classification \\nproblem to be reframed as multiple binary classification problems, allowing the use of native binary \\nclassification models to be used directly. \\n \\nUnlike one-vs-rest and one-vs-one methods that offer a similar solution by dividing a multi-class \\nclassification problem into a fixed number of binary classification problems, the error-correcting output \\ncodes technique allows each class to be encoded as an arbitrary number of binary classification \\nproblems. When an overdetermined representation is used, it allows the extra models to act as ‚Äúerror-\\ncorrection‚Äù predictions that can result in better predictive performance. \\n \\nIn error-correcting output codes (ECOC), the main classification task is defined in terms of a \\nnumber of subtasks that are implemented by the base-learners. The idea is that the original task of \\nseparating one class from all other classes may be a difficult problem. Instead, we want to define a set \\nof simpler classification problems, each specializing in one aspect of the task, and combining these \\nsimpler classifiers, we get the final classifier. \\n \\nBase-learners are binary classifiers having output ‚àí1/ + 1, and there is a code matrix W of K √ó L whose K \\nrows are the binary codes of classes in terms of the L base-learners dj. For example, if the second row of \\nW is [‚àí1,+1,+1,‚àí1], this means that for us to say an instance belongs to C2, the instance should be on the \\nnegative side of d1 and d4, and on the positive side of d2 and d3. Similarly, the columns of the code \\nmatrix defines the task of the base-learners. For example, if the third column is [‚àí1,+1,+1]T , we \\nunderstand that the task of the third base-learner, d3, is to separate the instances of C1 from the \\ninstances of C2 and C3 combined. This is how we form the training set of the base-learners. For example \\nin this case, all instances labeled with C2 and C3 form X+\\n3 and instances labeled with C1 form X‚àí\\n3, and d3 is \\ntrained so that xt ‚àà X+\\n3 give output +1 and xt ‚àà X‚àí\\n3 give output ‚àí1. \\n \\nThe code matrix thus allows us to define a polychotomy (K > 2 classification problem) in terms of \\ndichotomies (K = 2 classification problem), and it is a method that is applicable using any learning'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 69}, page_content='65 \\n \\nalgorithm to implement the dichotomizer base-learners‚Äîfor example, linear or multilayer perceptrons \\n(with a single output), decision trees, or SVMs whose original definition is for two-class problems. \\nThe typical one discriminant per class setting corresponds to the diagonal code matrix where L = K. For \\nexample, for K = 4, \\n \\n \\nwe have \\n                    \\n \\nThe problem here is that if there is an error with one of the baselearners, there may be a \\nmisclassification because the class code words are so similar. So the approach in error-correcting codes \\nis to have L > K and increase the Hamming distance between the code words. One possibility is pairwise \\nseparation of classes where there is a separate baselearner to separate Ci from Cj, for i < j. In this case, L \\n= K(K ‚àí 1)/2 and with K = 4, the code matrix is \\n \\n \\nwhere a 0 entry denotes ‚Äúdon‚Äôt care.‚Äù That is, d1 is trained to separate C1 from C2 and does not use the \\ntraining instances belonging to the other classes. Similarly, we say that an instance belongs to C2 if d1 = \\n‚àí1 and d4 = d5 = +1, and we do not consider the values of d2, d3, and d6. The problem here is that L is \\nO(K2), and for large K pairwise separation may not be feasible. \\n \\nIf we can have L high, we can just randomly generate the code matrix with ‚àí1/ + 1 and this will work \\nfine, but if we want to keep L low, we need to optimize W. The approach is to set L beforehand and \\nthen find W such that the distances between rows, and at the same time the distances between \\ncolumns, are as large as possible, in terms of Hamming distance. With K classes, there are 2(K-1) ‚àí 1 \\npossible columns, namely, two-class problems. This is because K bits can be written in 2K different ways \\nand complements (e.g., ‚Äú0101‚Äù and ‚Äú1010,‚Äù from our point of view, define the same discriminant) \\ndividing the possible combinations by 2 and then subtracting 1 because a column of all 0s (or 1s) is \\nuseless. For example, when K = 4, we have \\n \\n \\n \\nWhen K is large, for a given value of L, we look for L columns out of the 2(K-1)‚àí1. We would like these \\ncolumns of W to be as different as possible so that the tasks to be learned by the base-learners are as \\ndifferent from each other as possible. At the same time, we would like the rows of W to be as different \\nas possible so that we can have maximum error correction in case one or more base-learners fail. \\n \\nECOC can be written as a voting scheme where the entries of W, wij , are considered as vote weights:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 70}, page_content='66 \\n \\n \\nand then we choose the class with the highest yi . Taking a weighted sum and then choosing the \\nmaximum instead of checking for an exact match allows dj to no longer need to be binary but to take a \\nvalue between ‚àí1 and +1, carrying soft certainties instead of hard decisions. Note that a value pj \\nbetween 0 and 1, for example, a posterior probability, can be converted to a value dj between ‚àí1 and +1 \\nsimply as \\n \\nOne problem with ECOC is that because the code matrix W is set a priori, there is no guarantee that the \\nsubtasks as defined by the columns of W will be simple. \\n \\n3.4 Bagging \\nBootstrap aggregating, often abbreviated as bagging, involves having each model in the \\nensemble vote with equal weight. In order to promote model variance, bagging trains each model in the \\nensemble using a randomly drawn subset of the training set. As an example, the random \\nforest algorithm combines random decision trees with bagging to achieve very high classification \\naccuracy. \\nThe simplest method of combining classifiers is known as bagging, which stands for bootstrap \\naggregating, the statistical description of the method. This is fine if you know what a bootstrap is, but \\nfairly useless if you don‚Äôt. A bootstrap sample is a sample taken from the original dataset with \\nreplacement, so that we may get some data several times and others not at all. The bootstrap sample is \\nthe same size as the original, and lots and lots of these samples are taken: B of them, where B is at least \\n50, and could even be in the thousands. The name bootstrap is more popular in computer science than \\nanywhere else, since there is also a bootstrap loader, which is the first program to run when a computer \\nis turned on. It comes from the nonsensical idea of ‚Äòpicking yourself up by your bootstraps,‚Äô which \\nmeans lifting yourself up by your shoelaces, and is meant to imply starting from nothing. \\nBootstrap sampling seems like a very strange thing to do. We‚Äôve taken a perfectly good dataset, \\nmucked it up by sampling from it, which might be good if we had made a smaller dataset (since it would \\nbe faster), but we still ended up with a dataset the same size. Worse, we‚Äôve done it lots of times. Surely \\nthis is just a way to burn up computer time without gaining anything. The benefit of it is that we will get \\nlots of learners that perform slightly differently, which is exactly what we want for an ensemble \\nmethod. Another benefit is that estimates of the accuracy of the classification function can be made \\nwithout complicated analytic work, by throwing computer resources at the problem (technically, \\nbagging is a variance reducing algorithm; the meaning of this will become clearer when we talk about \\nbias and variance). Having taken a set of bootstrap samples, the bagging method simply requires that \\nwe fit a model to each dataset, and then combine them by taking the output to be the majority vote of \\nall the classifiers. A NumPy implementation is shown next, and then we will look at a simple example. \\n \\n# Compute bootstrap samples \\nsamplePoints = np.random.randint(0,nPoints,(nPoints,nSamples)) \\nclassifiers = [] \\n \\nfor i in range(nSamples): \\nsample = [] \\nsampleTarget = [] \\nfor j in range(nPoints): \\nsample.append(data[samplePoints[j,i]])'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 71}, page_content='67 \\n \\nsampleTarget.append(targets[samplePoints[j,i]]) \\n# Train classifiers \\nclassifiers.append(self.tree.make_tree(sample,sampleTarget,features)) \\n \\nThe example consists of taking the party data that was used to demonstrate the decision tree, and \\nrestricting the trees to stumps, so that they can make a classification based on just one variable \\n \\nWhen we want to construct the decision tree to decide what to do in the evening, we start by listing \\neverything that we‚Äôve done for the past few days to get a suitable dataset (here, the last ten days): \\n \\n \\nThe output of a decision tree that uses the whole dataset for this is not surprising: it takes the two \\nlargest classes, and separates them. However, using just stumps of trees and 20 samples, bagging can \\nseparate the data perfectly, as this output shows: \\n \\n \\n \\n3.4.1 RANDOM FORESTS \\nA random forest is an ensemble learning method where multiple decision trees are constructed \\nand then they are merged to get a more accurate prediction. \\nIf there is one method in machine learning that has grown in popularity over the last few years, \\nthen it is the idea of random forests. The concept has been around for longer than that, with several \\ndifferent people inventing variations, but the name that is most strongly attached to it is that of \\nBreiman, who also described the CART algorithm in unit 2. \\n \\nFigure 3: Example of random forest with majority voting'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 72}, page_content='68 \\n \\n \\n \\nThe idea is largely that if one tree is good, then many trees (a forest) should be better, provided \\nthat there is enough variety between them. The most interesting thing about a random forest is the \\nways that it creates randomness from a standard dataset. The first of the methods that it uses is the \\none that we have just seen: bagging. If we wish to create a forest then we can make the trees different \\nby training them on slightly different data, so we take bootstrap samples from the dataset for each tree. \\nHowever, this isn‚Äôt enough randomness yet. The other obvious place where it is possible to add \\nrandomness is to limit the choices that the decision tree can make. At each node, a random subset of \\nthe features is given to the tree, and it can only pick from that subset rather than from the whole set. \\nAs well as increasing the randomness in the training of each tree, it also speeds up the training, \\nsince there are fewer features to search over at each stage. Of course, it does introduce a new \\nparameter (how many features to consider), but the random forest does not seem to be very sensitive \\nto this parameter; in practice, a subset size that is the square root of the number of features seems to \\nbe common. The effect of these two forms of randomness is to reduce the variance without effecting \\nthe bias. Another benefit of this is that there is no need to prune the trees. There is another parameter \\nthat we don‚Äôt know how to choose yet, which is the number of trees to put into the forest. However, \\nthis is fairly easy to pick if we want optimal results: we can keep on building trees until the error stops \\ndecreasing.  \\nOnce the set of trees are trained, the output of the forest is the majority vote for classification, \\nas with the other committee methods that we have seen, or the mean response for regression. And \\nthose are pretty much the main features needed for creating a random forest. The algorithm is given \\nnext before we see some results of using the random forest. \\n \\nAlgorithm \\nHere is an outline of the random forest algorithm. \\n1. The random forests algorithm generates many classification trees. Each tree is generated as \\nfollows: \\na) If the number of examples in the training set is N, take a sample of N examples at \\nrandom - but with replacement, from the original data. This sample will be the training \\nset for generating the tree. \\nb) If there are M input variables, a number m is specified such that at each node, m \\nvariables are selected at random out of the M and the best split on these m is used to'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 73}, page_content='69 \\n \\nsplit the node. The value of m is held constant during the generation of the various \\ntrees in the forest. \\nc) Each tree is grown to the largest extent possible. \\n2. To classify a new object from an input vector, put the input vector down each of the trees in the \\nforest. Each tree gives a classification, and we say the tree ‚Äúvotes‚Äù for that class. The forest \\nchooses the classification \\n \\nThe implementation of this is very easy: we modify the decision to take an extra parameter, which is m, \\nthe number of features that should be used in the selection set at each stage. We will look at an \\nexample of using it shortly as a comparison to boosting. \\n \\nLooking at the algorithm you might be able to see that it is a very unusual machine learning \\nmethod because it is embarrassingly parallel: since the trees do not depend upon each other, you can \\nboth create and get decisions from different trees on different individual processors if you have them. \\nThis means that the random forest can run on as many processors as you have available with nearly \\nlinear speedup. \\n \\nThere is one more nice thing to mention about random forests, which is that with a little bit of \\nprogramming effort they come with built-in test data: the bootstrap sample will miss out about 35% of \\nthe data on average, the so-called out-of-bootstrap examples. If we keep track of these datapoints then \\nthey can be used as novel samples for that particular tree, giving an estimated test error that we get \\nwithout having to use any extra datapoints. \\n \\nThis avoids the need for cross-validation. \\n \\nAs a brief example of using the random forest, we start by demonstrating that the random \\nforest gets the correct results on the Party example that has been used in both this and the previous \\nchapters, based on 10 trees, each trained on 7 samples, and with just two levels allowed in each tree: \\n \\n \\n \\nAs a rather more involved example, the car evaluation dataset in the UCI Repository contains 1,728 \\nexamples aiming to classify whether or not a car is a good purchase based on six attributes. The \\nfollowing results compare a single decision tree, bagging, and a random forest with 50 trees, each based \\non 100 samples, and with a maximum depth of five for each tree. It can be seen that the random forest \\nis the most accurate of the three methods.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 74}, page_content='70 \\n \\n \\n \\n \\nStrengths and weaknesses \\n \\nStrengths \\nThe following are some of the important strengths of random forests. \\n‚Ä¢ \\nIt runs efficiently on large data bases. \\n‚Ä¢ \\nIt can handle thousands of input variables without variable deletion. \\n‚Ä¢ \\nIt gives estimates of what variables are important in the classification. \\n‚Ä¢ \\nIt has an effective method for estimating missing data and maintains accuracy when a large \\nproportion of the data are missing. \\n‚Ä¢ \\nGenerated forests can be saved for future use on other data. \\n‚Ä¢ \\nPrototypes are computed that give information about the relation between the variables and the \\nclassification. \\n‚Ä¢ \\nThe capabilities of the above can be extended to unlabeled data, leading to unsupervised \\nclustering, data views and outlier detection. \\n‚Ä¢ \\nIt offers an experimental method for detecting variable interactions. \\n‚Ä¢ \\nRandom forest run times are quite fast, and they are able to deal with unbalanced and missing \\ndata. \\n‚Ä¢ \\nThey can handle binary features, categorical features, numerical features without any need for \\nscaling. \\nWeaknesses \\n‚Ä¢ \\nA weakness of random forest algorithms is that when used for regression they cannot predict \\nbeyond the range in the training data, and that they may over-fit data sets that are particularly \\nnoisy.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 75}, page_content='71 \\n \\n‚Ä¢ \\nThe sizes of the models created by random forests may be very large. It may take hundreds of \\nmegabytes of memory and may be slow to evaluate. \\n‚Ä¢ \\nRandom forest models are black boxes that are very hard to interpret. \\n3.5 Boosting \\n\\uf0a7 \\nBoosting: train next learner on mistakes made by previous learner(s) \\n \\nIn bagging, generating complementary base-learners is left to chance and to the unstability of the \\nlearning method. In boosting, we actively try to generate complementary base-learners by training the \\nnext learner on the mistakes of the previous learners. The original boosting algorithm combines three \\nweak learners to generate a strong learner. A weak learner has error probability less than 1/2, which \\nmakes it better than random guessing on a two-class problem, and a strong learner has arbitrarily small \\nerror probability. \\n \\nOriginal Boosting Concept \\nGiven a large training set, we randomly divide it into three. We use X1 and train d1. We then take X2 \\nand feed it to d1. We take all instances misclassified by d1 and also as many instances on which d1 is \\ncorrect \\nfrom X2, and these together form the training set of d2. We then take X3 and feed it to d1 and d2. The \\ninstances on which d1 and d2 disagree form the training set of d3. During testing, given an instance, we \\ngive it to d1 and d2; if they agree, that is the response, otherwise the response of d3 is taken as the \\noutput. \\n \\n1. Split data X into {X1, X2, X3} \\n2. \\nTrain d1 on X1 \\n\\uf0a7 \\nTest d1 on X2 \\n3. Train d2 on d1‚Äôs mistakes on X2 (plus some right) \\n\\uf0a7 \\nTest d1 and d2 on X3 \\n4. Train d3 on disagreements between d1 and d2 \\n\\uf0a7 \\nTesting: apply d1 and d2; if disagree, use d3 \\n\\uf0a7 \\nDrawback: need large X \\n \\noverall system has reduced error rate, and the error rate can arbitrarily be reduced by using such \\nsystems recursively, that is, a boosting system of three models used as dj in a higher system. \\n \\nThough it is quite successful, the disadvantage of the original boosting method is that it requires a very \\nlarge training sample. The sample should be divided into three and furthermore, the second and third \\nclassifiers are only trained on a subset on which the previous ones err. So unless one has a quite large \\ntraining set, d2 and d3 will not have training \\nsets of reasonable size. \\n \\n3.5.1AdaBoost \\n         \\nFreund and Schapire (1996) proposed a variant, named AdaBoost, short for adaptive boosting, \\nthat uses the same training set over and over and thus need not be large, but the classifiers should be \\nsimple so that they do not overfit. AdaBoost can also combine an arbitrary number of baselearners, not \\nthree. \\n \\nAdaBoost algorithm'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 76}, page_content='72 \\n \\n \\n \\nThe idea is to modify the probabilities of drawing the instances as a function of the error. Let us say pt\\nj \\ndenotes the probability that the instance pair (xt, rt) is drawn to train the jth base-learner. \\nInitially, all pt\\n1 = 1/N. Then we add new base-learners as follows, starting from j = 1:  –Ñ j denotes the \\nerror rate of dj .  \\nAdaBoost requires that learners are weak, that is,  –Ñ j < 1/2,‚àÄj;  if  not, we stop adding new base-\\nlearners. Note that this error rate is not on the original problem but on the dataset used at step j. We \\ndefine  Œ≤j = –Ñ j /(1 ‚àí–Ñ j) < 1, and we set pt\\nj+1 = Œ≤j pt\\nj if dj correctly classifies xt ; otherwise, pt\\nj +1 = pt\\nj.   \\nBecause pt\\nj+1  should be probabilities, there is a normalization where we divide pt\\nj+1 by  ùë° pt\\nj+1 , so that \\nthey sum up to 1. This has the effect that the probability of a correctly classified instance is decreased, \\nand the probability of a misclassified instance increases. Then a new sample of the same size is drawn \\nfrom the original sample according to these modified probabilities, pt\\nj+1 with replacement, and is used to \\ntrain dj+1. \\n  \\nThis has the effect that dj+1 focuses more on instances misclassified by dj ; that is why the base-learners \\nare chosen to be simple and not accurate, since otherwise the next training sample would contain only \\na few outlier and noisy instances repeated many times over. For example, with decision trees, decision \\nstumps, which are trees grown only one or two levels, are used. So it is clear that these would have bias \\nbut the decrease in variance is larger and the overall error decreases. An algorithm like the linear \\ndiscriminant has low variance, and we cannot gain by AdaBoosting linear discriminants. \\n. \\n3.5.2 Stacking - Stacked Generalization \\nStacked generalization is a technique proposed by Wolpert (1992) that extends voting in that \\nthe way the output of the base-learners is combined need not be linear but is learned through a \\ncombiner system, f (¬∑|Œ¶), which is another learner, whose parameters Œ¶ are also trained. (see the \\nbelow given figure)'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 77}, page_content='73 \\n \\n \\nFigure: In stacked generalization, the combiner is another learner and is not restricted to being a linear \\ncombination as in voting. \\n \\ny = f (d1, d2, . . . , dL |Œ¶) \\n \\nThe combiner learns what the correct output is when the base-learners give a certain output \\ncombination. We cannot train the combiner function on the training data because the base-learners \\nmay be memorizing the training set; the combiner system should actually learn how the baselearners \\nmake errors. Stacking is a means of estimating and correcting for the biases of the base-learners. \\nTherefore, the combiner should be trained on data unused in training the base-learners. \\n \\nIf f (¬∑|w1, . . . , wL) is a linear model with constraints, wi ‚â• 0,  ùëóWj = 1, the optimal weights can be found \\nby constrained regression, but of course we do not need to enforce this; in stacking, there is no \\nrestriction on the combiner function and unlike voting, f (¬∑) can be nonlinear. For example, it may be \\nimplemented as a multilayer perceptron with Œ¶ its connection weights. \\n \\nThe outputs of the base-learners dj define a new L-dimensional space in which the output \\ndiscriminant/regression function is learned by the combiner function. \\n \\nIn stacked generalization, we would like the base-learners to be as different as possible so that they will \\ncomplement each other, and, for this, it is best if they are based on different learning algorithms. If we \\nare combining classifiers that can generate continuous outputs, for example, posterior probabilities, it is \\nbetter that they be the combined rather than hard decisions. \\nWhen we compare a trained combiner as we have in stacking, with a fixed rule such as in \\nvoting, we see that both have their advantages: A trained rule is more flexible and may have less bias, \\nbut adds extra parameters, risks introducing variance, and needs extra time and data for training. Note \\nalso that there is no need to normalize classifier outputs before stacking. \\n \\n3.6 Probabilistic Learning \\nIn machine learning, a probabilistic classifier is a classifier that is able to predict, given an \\nobservation of an input, a probability distribution over a set of classes, rather than only outputting the \\nmost likely class that the observation should belong to. Probabilistic classifiers provide classification \\nthat can be useful in its own right or when combining classifiers into ensembles. \\n \\nOne criticism that is often made of neural networks‚Äîespecially the MLP‚Äîis that it is not clear exactly \\nwhat it is doing: while we can go and have a look at the activations of the neurons and the weights, they \\ndon‚Äôt tell us much.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 78}, page_content='74 \\n \\nIn this topic (probabilistic classifier ) we are going to look at methods that are based on statistics, and \\nthat are therefore more transparent, in that we can always extract and look at the probabilities and see \\nwhat they are, rather than having to worry about weights that have no obvious meaning. \\n \\n \\n3.7 GAUSSIAN MIXTURE MODELS \\nHowever, suppose that we have the same data, but without target labels. This requires \\nunsupervised learning,  Suppose that the different classes each come from their own Gaussian \\ndistribution. This is known as multi-modal data, since there is one distribution (mode) for each different \\nclass. We can‚Äôt fit one Gaussian to the data, because it doesn‚Äôt look Gaussian overall. \\n \\nThere is, however, something we can do. If we know how many classes there are in the data, \\nthen we can try to estimate the parameters for that many Gaussians, all at once. If we don‚Äôt know, then \\nwe can try different numbers and see which one works best. We will talk about this issue more for a \\ndifferent method (the k-means algorithm) in Unit 2. It is perfectly possible to use any other probability \\ndistribution instead of a Gaussian, but Gaussians are by far the most common choice. Then the output \\nfor any particular datapoint that is input to the algorithm will be the sum of the values expected by all \\nof the M Gaussians: \\n \\n \\nwhere _(x ; Œºm,  ùëö) is a Gaussian function with mean Œºm and covariance matrix  ùëö, and the  Œ±m are \\nweights with the constraint that  \\nùõºùëö \\nùëÄ\\nùëö=1\\n =1. \\n \\nThe given figures 4 shows two examples, where the data (shown by the histograms) comes from two \\ndifferent Gaussians, and the model is computed as a sum or mixture of the two Gaussians together.  \\n \\n \\nFIGURE 4: Histograms of training data from a mixture of two Gaussians and two fitted models, shown as \\nthe line plot. The model shown on the left fits well, but the one on the right produces two Gaussians \\nright on top of each other that do not fit the data well. \\n \\n \\nThe figure also gives you some idea of how to use the mixture model once it has been created. The \\nprobability that input xi belongs to class m can be written as (where a hat on a variable (ÀÜ¬∑) means that \\nwe are estimating the value of that variable): \\n \\nThe problem is how to choose the weights Œ±m. The common approach is to aim for the maximum'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 79}, page_content='75 \\n \\nlikelihood solution (the likelihood is the conditional probability of the data given the model, and the \\nmaximum likelihood solution varies the model to maximise this conditional probability). In fact, it is \\ncommon to compute the log likelihood and then to maximise that; it is guaranteed to be negative, since \\nprobabilities are all less than 1, and the logarithm spreads out the values, making the optimisation more \\neffective. The algorithm that is used is an example of a very general one known as the expectation-\\nmaximisation (or more compactly, EM) algorithm. \\n \\n3.8 The Expectation-Maximisation (EM) Algorithm \\nThe basic idea of the EM algorithm is that sometimes it is easier to add extra variables that are \\nnot actually known (called hidden or latent variables) and then to maximise the function over those \\nvariables. This might seem to be making a problem much more complicated than it needs to be, but it \\nturns out for many problems that it makes finding the solution significantly easier. \\nIn order to see how it works, we will consider the simplest interesting case of the Gaussian \\nmixture model: a combination of just two Gaussian mixtures. The assumption now is that sample from \\nthat Gaussian. If the probability of picking Gaussian one is p, then the entire model looks like this \\n(where N(Œº, œÉ2) specifies a Gaussian distribution with mean Œº and standard deviation œÉ): \\n \\n \\n \\nIf the probability distribution of p is written as œÄ, then the probability density is: \\n \\n \\n \\nFinding the maximum likelihood solution (actually the maximum log likelihood) to this problem \\nis then a case of computing the sum of the logarithm of Equation  over all of the training data, and \\ndifferentiating it, which would be rather difficult. Fortunately, there is a way around it. The key insight \\nthat we need is that if we knew which of the two Gaussian components the datapoint came from, then \\nthe computation would be easy. The mean and standard deviation for each component could be \\ncomputed from the datapoints that belong to that component, and there would not be a problem. \\nAlthough we don‚Äôt know which component each datapoint came from, we can pretend we do, by \\nintroducing a new variable f. If f = 0 then the data came from Gaussian one, if f = 1 then it came from \\nGaussian two. \\n \\nThis is the typical initial step of an EM algorithm: adding latent variables. Now we just need to \\nwork out how to optimise over them. This is the time when the reason for the algorithm being called \\nexpectation-maximisation becomes clear.We don‚Äôt know much about variable f (hardly surprising, since \\nwe invented it), but we can compute its expectation (that is, the value that we ‚Äòexpect‚Äô to see, which is \\nthe mean average) from the data: \\n \\n \\n \\nwhere D denotes the data. Note that since we have set f = 1 this means that we are choosing Gaussian \\ntwo.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 80}, page_content='76 \\n \\n \\nComputing the value of this expectation is known as the E-step. Then this estimate of the \\nexpectation is maximised over the model parameters (the parameters of the two Gaussians and the \\nmixing parameter œÄ), the M-step. This requires differentiating the expectation with respect to each of \\nthe model parameters. These two steps are simply iterated until the algorithm converges. Note that the \\nestimate never gets any smaller, and it turns out that EM algorithms are guaranteed to reach a local \\nmaxima. To see how this looks for the two-component Gaussian mixture, we‚Äôll take a closer look at the \\nalgorithm: \\n \\n \\nThe trick with applying EM algorithms to problems is in identifying the correct latent variables \\nto include, and then simply working through the steps. They are very powerful methods for a wide \\nvariety of statistical learning problems. We are now going to turn our attention to something much \\nsimpler, which is how we can use information about nearby datapoints to decide on classification \\noutput. For this we don‚Äôt use a model of the data at all, but directly use the data that is available. \\n \\n3.9 Information Criteria \\nwe introduced the idea of a validation set, or using cross-validation if there was not enough \\ndata. However, this replaces data with computation time, as many models are trained on different \\ndatasets. \\n \\nAn alternative idea is to identify some measure that tells us about how well we can expect this \\ntrained model to perform. Probabilistic model selection (or ‚Äúinformation criteria‚Äù) provides an \\nanalytical technique for scoring and choosing among candidate models. Models are scored both on \\ntheir performance on the training dataset and based on the complexity of the model.There are two \\nsuch information criteria that are commonly used: \\n \\n \\n \\nIn these equations, k is the number of parameters in the model, N is the number of training \\nexamples, and L is the best (largest) likelihood of the model. In both cases, based on the way that they \\nare written here, the model with the largest value is taken. \\n \\n3.10 Nearest neighbour methods'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 81}, page_content='77 \\n \\nSuppose that you are in a nightclub and decide to dance. It is unlikely that you will know the \\ndance moves for the particular song that is playing, so you will probably try to work out what to do by \\nlooking at what the people close to you are doing. The first thing you could do would be just to pick the \\nperson closest to you and copy them. However, since most of the people who are in the nightclub are \\nalso unlikely to know all the moves, you might decide to look at a few more people and do what most of \\nthem are doing. This is pretty much exactly the idea behind nearest neighbour methods: if we don‚Äôt \\nhave a model that describes the data, then the best thing to do is to look at similar data and choose to \\nbe in the same class as them. \\n \\nWe have the datapoints positioned within input space, so we just need to work out which of the \\ntraining data are close to it. This requires computing the distance to each datapoint in the training set, \\nwhich is relatively expensive: if we are in normal Euclidean space, then we have to compute d \\nsubtractions and d squarings (we can ignore the square root since we only want to know which points \\nare the closest, not the actual distance) and this has to be done O(N2) times. We can then identify the k \\nnearest neighbours to the test point, and then set the class of the test point to be the most common \\none out of those for the nearest neighbours. The choice of k is not trivial. Make it too small and nearest \\nneighbour methods are sensitive to noise, too large and the accuracy reduces as points that are too far \\naway are considered. Some possible effects of changing the size of k on the decision boundary are \\nshown in below Figure 5. \\n \\n \\nFIGURE 5: The nearest neighbours decision boundary with left: one neighbour and right: \\ntwo neighbours. \\n \\nThis method suffers from the curse of dimensionality. First, as shown above, the computational \\ncosts get higher as the number of dimensions grows. This is not as bad as it might appear at first: there \\nare sets of methods such as KD-Trees (will discuss in upcoming topics) that compute this in O(N log N) \\ntime. However, more importantly, as the number of dimensions increases, so the distance to other \\ndatapoints tends to increase. In addition, they can be far away in a variety of different directions‚Äîthere \\nmight be points that are relatively close in some dimensions, but a long way in others. There are \\nmethods for dealing with these problems, known as adaptive nearest neighbour methods, and there is a \\nreference to them in the Further Reading section at the end of the chapter. \\n \\nThe only part of this that requires any care during the implementation is what to do when there \\nis more than one class found in the closest points, but even with that the implementation is nice and \\nsimple:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 82}, page_content='78 \\n \\n \\n \\nWe are going to look next at how we can use these methods for regression, before we turn to the \\nquestion of how to perform the distance calculations as efficiently as possible, something that is done \\nsimply but inefficiently in the code above. We will then consider briefly whether or not the Euclidean \\ndistance is always the most useful way to calculate distances, and what alternatives there are. \\n \\nFor the k-nearest neighbours algorithm the bias-variance decomposition can be computed as: \\n \\n \\nThe way to interpret this is that when k is small, so that there are few neighbours considered, the model \\nhas flexibility and can represent the underlying model well, but that it makes mistakes (has high \\nvariance) because there is relatively little data. As k increases, the variance decreases, but at the cost of \\nless flexibility and so more bias. \\n \\n3.11 Nearest Neighbour Smoothing \\nNearest neighbour methods can also be used for regression by returning the average value of the \\nneighbours to a point, or a spline or similar fit as the new value. The most common methods are known \\nas kernel smoothers, and they use a kernel (a weighting function between pairs of points) that decides \\nhow much emphasis (weight) to put onto the contribution from each datapoint according to its distance \\nfrom the input.  \\n \\nHere we shall simply use two kernels that are used for smoothing. Both of these kernels are \\ndesigned to give more weight to points that are closer to the current input, with the weights decreasing \\nsmoothly to zero as they pass out of the range of the current input, with the range specified by a \\nparameter Œª. \\n \\nThey are the Epanechnikov quadratic kernel:'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 83}, page_content='79 \\n \\nand the tricube kernel: \\n \\n \\nThe results of using these kernels are shown in below Figure 6 on a dataset that consists of the time \\nbetween eruptions (technically known as the repose) and the duration of the eruptions of Mount \\nRuapehu, the large volcano in the centre of New Zealand‚Äôs north island. Values of Œª of 2 and 4 were \\nused here. Picking Œª requires experimentation. Large values average over more datapoints, and \\ntherefore produce lower variance, but at the cost of higher bias.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 84}, page_content='80 \\n \\n \\nFIGURE 6:  Output of the nearest neighbour method and two kernel smoothers on the data of duration \\nand repose of eruptions of Mount Ruapehu 1860‚Äì2006. \\n \\n3.12 Efficient Distance Computations: the KD-Tree \\n \\nAs was mentioned above, computing the distances between all pairs of points is very \\ncomputationally expensive. Fortunately, as with many problems in computer science, designing an \\nefficient data structure can reduce the computational overhead a lot. For the problem of finding \\nnearest neighbours the data structure of choice is the KD-Tree. It has been around since the late 1970s, \\nwhen it was devised by Friedman and Bentley, and it reduces the cost of finding a nearest neighbour to \\nO(log N) for O(N) storage. The construction of the tree is O(N log2 N), with much of the computational \\ncost being in the computation of the median, which with a na√Øve algorithm requires a sort and is \\ntherefore O(N log N), or can be computed with a randomised algorithm in O(N) time. \\n \\nThe idea behind the KD-tree is very simple. You create a binary tree by choosing one dimension \\nat a time to split into two, and placing the line through the median of the point coordinates of that \\ndimension. The points themselves end up as leaves of the tree. Making the tree follows pretty much the \\nsame steps as usual for constructing a binary tree: we identify a place to split into two choices, left and \\nright, and then carry on down the tree. This makes it natural to write the algorithm recursively. The \\nchoice of what to split and where is what makes the KD-tree special. Just one dimension is split in each \\nstep, and the position of the split is found by computing the median of the points that are to be split in \\nthat one dimension, and putting the line there. In general, the choice of which dimension to split'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 85}, page_content='81 \\n \\nalternates through the different choices, or it can be made randomly. The algorithm below cycles \\nthrough the possible dimensions based on the depth of the tree so far, so that in two dimensions it \\nalternates horizontal and vertical splits.  \\nThe centre of the construction method is simply a recursive function that picks the axis to split \\non, finds the median value on that axis, and separates the points according to that value, which in \\nPython can be written as: \\n \\n \\n \\nSuppose that we had seven two-dimensional points to make a tree from: (5, 4), (1, 6), (6, 1), (7, 5), (2, \\n7), (2, 2), (5, 8) (as plotted in Figure 7).  \\n \\nFIGURE 7: The initial set of 2D data. \\n \\nThe algorithm will pick the first coordinate to split on initially, and the median point here is 5, so the \\nsplit is through x = 5. Of those on the left of the line, the median y coordinate is 6, and for those on the \\nright it is 5. At this point we have separated all the points, and so the algorithm terminates with the split \\nshown in Figure 8 and the tree shown in Figure 9.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 86}, page_content='82 \\n \\n \\nFIGURE 8: The splits and leaf points found by the KD-tree. \\n \\n \\nFIGURE 9: The KD-tree that made the splits. \\n \\nSearching the tree is the same as any other binary tree; we are more interested in finding the nearest \\nneighbours of a test point. This is fairly easy: starting at the root of the tree you recurse down through \\nthe tree comparing just one dimension at a time until you find a leaf node that is in the region \\ncontaining the test point. Using the tree shown in Figure 9 we introduce the test point (3, 5), which \\nfinds (2, 2) as the leaf for the box that (3, 5) is in. However, looking at Figure 10 we see that this is not \\nthe closest point at all, so we need to do some more work. \\n \\n \\nFIGURE 10 Two test points for the example KD-tree.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 87}, page_content='83 \\n \\n3.13 Distance Measures \\n \\nWe have computed the distance between points as the Euclidean distance, which is something \\nthat you learnt about in high school. However, it is not the only option, nor is it necessarily the most \\nuseful. In this section we will look at the underlying idea behind distance calculations and possible \\nalternatives. \\n \\nIf I were to ask you to find the distance between my house and the nearest shop, then your first \\nguess might involve taking a map of my town, locating my house and the shop, and using a ruler to \\nmeasure the distance between them. By careful application of the map scale you can now tell me how \\nfar it is. However, when I set out to buy some milk I‚Äôm liable to find that I have to walk rather further \\nthan you‚Äôve told me, since the direct line that you measured would involve walking through (or over) \\nseveral houses, and some serious fence-scaling. Your ‚Äòas the crow flies‚Äô distance is the shortest possible \\npath, and it is the straight-line, or Euclidean, distance. You can measure it on the map by just using a \\nruler, but it essentially consists of measuring the distance in one direction (we‚Äôll call it \\nnorth-south) and then the distance in another direction that is perpendicular to the first (let‚Äôs call it \\neast-west) and then squaring them, adding them together, and then taking the square root of that. \\nWriting that out, the Euclidean distance that we are all used to is: \\n \\n \\nwhere (x1, y1) is the location of my house in some coordinate system (say by using a GPS tracker) and \\n(x2, y2) is the location of the shop. \\n \\nIf I told you that my town was laid out on a grid block system, as is common in towns that were \\nbuilt in the interval between the invention of the motor car and the invention of innovative town \\nplanners, then you would probably use a different measure. You would measure the distance between \\nmy house and the shop in the ‚Äònorth-south‚Äô direction and the distance in the ‚Äòeast-west‚Äô direction, and \\nthen add the two distances together. This would correspond to the distance I actually had to walk. It is \\noften known as the city-block or Manhattan distance and looks like: \\n \\nThe point of this discussion is to show that there is more than one way to measure a distance, \\nand that they can provide radically different answers. These two different distances can be seen in \\nFigure 11. Mathematically, these distance measures are known as metrics. A metric function or norm \\ntakes two inputs and gives a scalar (the distance) back, which is positive, and 0 if and only if the two \\npoints are the same, symmetric (so that the distance \\nto the shop is the same as the distance back), and obeys the triangle inequality, which says that the \\ndistance from a to b plus the distance from b to c should not be less than the direct distance from a to c.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 88}, page_content='84 \\n \\n \\nFIGURE 10: The Euclidean and city-block distances between two points. \\n \\nMost of the data that we are going to have to analyse lives in rather more than two dimensions. \\nFortunately, the Euclidean distance that we know about generalises very well to higher dimensions (and \\nso does the city-block metric). In fact, these two measures are both instances of a class of metrics that \\nwork in any number of dimensions. The general measure is the Minkowski metric and it is written as: \\n \\n \\nIf we put k = 1 then we get the city-block distance (Equation (7.12)), and k = 2 gives the \\nEuclidean distance (Equation (7.11)). Thus, you might possibly see the Euclidean metric written as the L2 \\nnorm and the city-block distance as the L1 norm. These norms have another interesting feature. \\nRemember that we can define different averages of a set of numbers. If we define the average as the \\npoint that minimises the sum of the distance to every datapoint, then it turns out that the mean \\nminimises the Euclidean distance (the sum-of-squares distance), and the median minimises the L1 \\nmetric. \\n \\nThere are plenty of other possible metrics to choose, depending upon the dataspace. We \\ngenerally assume that the space is flat (if it isn‚Äôt, then none of these techniques work, and we don‚Äôt \\nwant to worry about that). However, it can still be beneficial to look at other metrics. Suppose that we \\nwant our classifier to be able to recognise images, for example of faces. We take a set of digital photos \\nof faces and use the pixel values as features. Then we use the nearest neighbour algorithm that we‚Äôve \\njust seen to identify each face. Even if we ensure that all of the photos are taken fully face-on, there are \\nstill a few things that will get in the way of this method. One is that slight variations in the angle of the \\nhead (or the camera) could make a difference; another is that different distances between the face and \\nthe camera (scaling) will change the results; and another is that different lighting conditions will make a \\ndifference. We can try to fix all of these things in preprocessing, but there is also another alternative: \\nuse a different metric that is invariant to these changes, i.e., it does not vary as they do. The idea of \\ninvariant metrics is to find measures that ignore changes that you don‚Äôt want. So if you want to be able \\nto rotate shapes around and still recognize them, you need a metric that is invariant to rotation. \\n \\nA common invariant metric in use for images is the tangent distance, which is an approximation \\nto the Taylor expansion in first derivatives, and works very well for small rotations and scalings; for \\nexample, it was used to halve the final error rate on nearest neighbor classification of a set of \\nhandwritten letters. Invariant metrics are an interesting topic for further study, and there is a reference \\nfor them in the Further Reading section if you are interested.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 89}, page_content='85 \\n \\nUnit IV  \\nReinforcement Learning and Evaluating Hypotheses \\n \\nIntroduction, Learning Task, Q Learning, Non deterministic Rewards and actions, temporal-\\ndifference learning, Relationship to Dynamic Programming, Active reinforcement learning, \\nGeneralization in reinforcement learning. \\nMotivation, Basics of Sampling Theory: Error Estimation and Estimating Binomial Proportions, \\nThe Binomial Distribution, Estimators, Bias, and Variance   \\n \\nReinforcement learning addresses the question of how an autonomous agent that senses and acts in its \\nenvironment can learn to choose optimal actions to achieve its goals. \\n \\n4.1. Introduction \\n\\uf0b7 \\nConsider building a learning robot. The robot, or agent, has a set of sensors to observe the state of \\nits environment, and a set of actions it can perform to alter this state.  \\n\\uf0b7 \\nIts task is to learn a control strategy, or policy, for choosing actions that achieve its goals.  \\n\\uf0b7 \\nThe goals of the agent can be defined by a reward function that assigns a numerical value to each \\ndistinct action the agent may take from each distinct state.  \\n\\uf0b7 \\nThis reward function may be built into the robot, or known only to an external teacher who \\nprovides the reward value for each action performed by the robot.  \\n\\uf0b7 \\nThe task of the robot is to perform sequences of actions, observe their consequences, and learn a \\ncontrol policy.  \\n\\uf0b7 \\nThe control policy is one that, from any initial state, chooses actions that maximize the reward \\naccumulated over time by the agent.  \\nExample:  \\n\\uf0b7 \\nA mobile robot may have sensors such as a camera and sonars, and actions such as \"move \\nforward\" and \"turn.\"  \\n\\uf0b7 \\nThe robot may have a goal of docking onto its battery charger whenever its battery level is low.  \\n\\uf0b7 \\nThe goal of docking to the battery charger can be captured by assigning a positive reward (Eg., \\n+100) to state-action transitions that immediately result in a connection to the charger and a \\nreward of zero to every other state-action transition.  \\n \\nReinforcement Learning Problem  \\n\\uf0b7 \\nAn agent interacting with its environment. The agent exists in an environment described by some \\nset of possible states S.  \\n\\uf0b7 \\nAgent perform any of a set of possible actions A. Each time it performs an action a, in some state st \\nthe agent receives a real-valued reward r, that indicates the immediate value of this state-action \\ntransition. This produces a sequence of states si, actions ai, and immediate rewards ri as shown in \\nthe figure.  \\n\\uf0b7 \\nThe agent\\'s task is to learn a control policy, ùùÖ: S ‚Üí A, that maximizes the expected sum of these \\nrewards, with future rewards discounted exponentially by their delay.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 90}, page_content=\"86 \\n \\n \\n \\n \\nReinforcement learning problem characteristics \\n \\n1. Delayed reward: The task of the agent is to learn a target function ùúã that maps from the current state \\ns to the optimal action a = ùúã (s). In reinforcement learning, training information is not available in (s, ùúã \\n(s)). Instead, the trainer provides only a sequence of immediate reward values as the agent executes its \\nsequence of actions. The agent, therefore, faces the problem of temporal credit assignment: \\ndetermining which of the actions in its sequence are to be credited with producing the eventual \\nrewards.  \\n \\n2. Exploration: In reinforcement learning, the agent influences the distribution of training examples by \\nthe action sequence it chooses. This raises the question of which experimentation strategy produces \\nmost effective learning. The learner faces a trade-off in choosing whether to favor exploration of \\nunknown states and actions, or exploitation of states and actions that it has already learned will yield \\nhigh reward.  \\n \\n3. Partially observable states: The agent's sensors can perceive the entire state of the environment at \\neach time step, in many practical situations sensors provide only partial information. In such cases, the \\nagent needs to consider its previous observations together with its current sensor data when choosing \\nactions, and the best policy may be one that chooses actions specifically to improve the observability of \\nthe environment.  \\n \\n4. Life-long learning: Robot requires to learn several related tasks within the same environment, using \\nthe same sensors. For example, a mobile robot may need to learn how to dock on its battery charger, \\nhow to navigate through narrow corridors, and how to pick up output from laser printers. This setting \\nraises the possibility of using previously obtained experience or knowledge to reduce sample complexity \\nwhen learning new tasks.  \\n \\n4.2. Learning Task \\n\\uf0b7 \\nConsider Markov decision process (MDP) where the agent can perceive a set S of distinct states of \\nits environment and has a set A of actions that it can perform.  \\n\\uf0b7 \\nAt each discrete time step t, the agent senses the current state st, chooses a current action at, and \\nperforms it.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 91}, page_content='87 \\n \\n\\uf0b7 \\nThe environment responds by giving the agent a reward rt = r(st, at) and by producing the \\nsucceeding state st+l = Œ¥(st, at). Here the functions Œ¥(st, at) and r(st, at) depend only on the current \\nstate and action, and not on earlier states or actions.  \\n \\nThe task of the agent is to learn a policy, ùùÖ: S ‚Üí A, for selecting its next action a, based on the current \\nobserved state st; that is, (st) = at.  \\n \\nHow shall we specify precisely which policy œÄ we would like the agent to learn? \\n \\n1. One approach is to require the policy that produces the greatest possible cumulative reward for the \\nrobot over time.  \\n\\uf0b7 \\nTo state this requirement more precisely, define the cumulative value VœÄ (st) achieved by following \\nan arbitrary policy œÄ from an arbitrary initial state st as follows:  \\n \\n \\n\\uf0b7 \\nWhere, the sequence of rewards rt+i is generated by beginning at state st and by repeatedly using \\nthe policy œÄ to select actions.  \\n\\uf0b7 \\nHere 0 ‚â§ Œ≥ ‚â§ 1 is a constant that determines the relative value of delayed versus immediate \\nrewards. if we set Œ≥ = 0, only the immediate reward is considered. As we set Œ≥ closer to 1, future \\nrewards are given greater emphasis relative to the immediate reward.  \\n\\uf0b7 \\nThe quantity VœÄ (st) is called the discounted cumulative reward achieved by policy œÄ from initial \\nstate s. It is reasonable to discount future rewards relative to immediate rewards because, in many \\ncases, we prefer to obtain the reward sooner rather than later.  \\n \\n2. Other definitions of total reward is finite horizon reward,  \\n \\n \\nConsiders the undiscounted sum of rewards over a finite number h of steps  \\n \\n3. Another approach is average reward  \\n \\n \\nConsiders the average reward per time step over the entire lifetime of the agent.  \\n \\nWe require that the agent learn a policy œÄ that maximizes VœÄ (st) for all states s. such a policy is called \\nan optimal policy and denote it by œÄ*'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 92}, page_content='88 \\n \\n \\n \\nRefer the value function VœÄ*(s) an optimal policy as V*(s). V*(s) gives the maximum discounted \\ncumulative reward that the agent can obtain starting from state s. \\n \\nExample:  \\nA simple grid-world environment is depicted in the diagram  \\n \\n\\uf0b7 \\nThe six grid squares in this diagram represent six possible states, or locations, for the agent.  \\n\\uf0b7 \\nEach arrow in the diagram represents a possible action the agent can take to move from one state \\nto another.  \\n\\uf0b7 \\nThe number associated with each arrow represents the immediate reward r(s, a) the agent receives \\nif it executes the corresponding state-action transition  \\n\\uf0b7 \\nThe immediate reward in this environment is defined to be zero for all state-action transitions \\nexcept for those leading into the state labelled G. The state G as the goal state, and the agent can \\nreceive reward by entering this state.  \\n \\nOnce the states, actions, and immediate rewards are defined, choose a value for the discount factor Œ≥, \\ndetermine the optimal policy œÄ * and its value function V*(s). \\n \\nLet‚Äôs choose Œ≥ = 0.9. The diagram at the bottom of the figure shows one optimal policy for this setting.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 93}, page_content='89 \\n \\n \\n \\nValues of V*(s) and Q(s, a) follow from r(s, a), and the discount factor Œ≥ = 0.9. An optimal policy, \\ncorresponding to actions with maximal Q values, is also shown.  \\n \\nThe discounted future reward from the bottom centre state is  \\n0+ Œ≥ 100+ Œ≥2 0+ Œ≥3 0+... = 90 \\n4.1.3. Q LEARNING \\nHow can an agent learn an optimal policy œÄ * for an arbitrary environment?  \\nThe training information available to the learner is the sequence of immediate rewards r(si,ai) \\nfor i = 0, 1,2, . . . . Given this kind of training information it is easier to learn a numerical evaluation \\nfunction defined over states and actions, then implement the optimal policy in terms of this evaluation \\nfunction.  \\n \\nWhat evaluation function should the agent attempt to learn?  \\nOne obvious choice is V*. The agent should prefer state sl over state s2 whenever V*(sl) > V*(s2), \\nbecause the cumulative future reward will be greater from sl  \\nThe optimal action in state s is the action a that maximizes the sum of the immediate reward r(s, a) plus \\nthe value V* of the immediate successor state, discounted by Œ≥. \\n \\n \\n \\n4.1.3.1. The Q Function \\nThe value of Evaluation function Q(s, a) is the reward received immediately upon executing \\naction a from state s, plus the value (discounted by Œ≥ ) of following the optimal policy thereafter'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 94}, page_content='90 \\n \\n \\nRewrite Equation (3) in terms of Q(s, a) as  \\n \\n \\nEquation (5) makes clear, it need only consider each available action a in its current state s and choose \\nthe action that maximizes Q(s, a).  \\n \\n4.1.3.2. An Algorithm for Learning Q  \\n\\uf0b7 \\nLearning the Q function corresponds to learning the optimal policy.  \\n\\uf0b7 \\nThe key problem is finding a reliable way to estimate training values for Q, given only a sequence of \\nimmediate rewards r spread out over time. This can be accomplished through iterative \\napproximation  \\n \\nRewriting Equation \\n \\n \\n \\n \\n \\n \\n \\n \\nQ learning algorithm:  \\n \\n \\n\\uf0b7 \\nQ learning algorithm assuming deterministic rewards and actions. The discount factor Œ≥ may be any \\nconstant such that 0 ‚â§ Œ≥ < 1'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 95}, page_content=\"91 \\n \\n\\uf0b7 \\nùëÑÃÇ to refer to the learner's estimate, or hypothesis, of the actual Q function \\n \\n4.1.3.2. An Illustrative Example \\n \\n\\uf0b7 \\nTo illustrate the operation of the Q learning algorithm, consider a single action taken by an agent, \\nand the corresponding refinement to ùëÑÃÇ shown in below figure  \\n \\n\\uf0b7 \\nThe agent moves one cell to the right in its grid world and receives an immediate reward of zero for \\nthis transition.  \\n\\uf0b7 \\nApply the training rule of Equation  \\n \\nto refine its estimate Q for the state-action transition it just executed.  \\n \\n\\uf0b7 According to the training rule, the new ùëÑÃÇ estimate for this transition is the sum of the received \\nreward (zero) and the highest ùëÑÃÇ value associated with the resulting state (100), discounted by Œ≥ (.9).  \\n \\n \\n4.1.3.3. Convergence  \\nWill the Q Learning Algorithm converge toward a Q equal to the true Q function?  \\nYes, under certain conditions.  \\n1. Assume the system is a deterministic MDP.  \\n2. Assume the immediate reward values are bounded; that is, there exists some positive constant c such \\nthat for all states s and actions a, | r(s, a)| < c  \\n3. Assume the agent selects actions in such a fashion that it visits every possible state-action pair \\ninfinitely often\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 96}, page_content='92'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 97}, page_content='93 \\n \\n \\n \\n \\n4.1.3.4. Experimentation Strategies  \\nThe Q learning algorithm does not specify how actions are chosen by the agent.  \\n\\uf0b7 \\nOne obvious strategy would be for the agent in state s to select the action a that maximizes ùëÑÃÇ(s, a), \\nthereby exploiting its current approximation ùëÑÃÇ.  \\n\\uf0b7 \\nHowever, with this strategy the agent runs the risk that it will overcommit to actions that are \\nfound during early training to have high Q values, while failing to explore other actions that have \\neven higher values.  \\n\\uf0b7 \\nFor this reason, Q learning uses a probabilistic approach to selecting actions. Actions with higher ùëÑÃÇ \\nvalues are assigned higher probabilities, but every action is assigned a nonzero probability.  \\n\\uf0b7 \\nOne way to assign such probabilities is  \\n \\n \\n\\uf0b7 \\nWhere, P(ai |s) is the probability of selecting action ai, given that the agent is in state s, and k > 0 is \\na constant that determines how strongly the selection favors actions with high ùëÑÃÇ values \\n4.2. Evaluating Hypotheses \\n4.2.1. Motivation  \\nIt is important to evaluate the performance of learned hypotheses as precisely as possible.  \\n\\uf0b7 \\nOne reason is simply to understand whether to use the hypothesis.  \\n\\uf0b7 \\nA second reason is that evaluating hypotheses is an integral component of many learning \\nmethods.  \\n \\nTwo key difficulties arise while learning a hypothesis and estimating its future accuracy given only a \\nlimited set of data:  \\n \\n1. Bias in the estimate. The observed accuracy of the learned hypothesis over the training examples is \\noften a poor estimator of its accuracy over future examples. Because the learned hypothesis was \\nderived from these examples, they will typically provide an optimistically biased estimate of hypothesis \\naccuracy over future examples. This is especially likely when the learner considers a very rich hypothesis \\nspace, enabling it to overfit the training examples. To obtain an unbiased estimate of future accuracy, \\ntest the hypothesis on some set of test examples chosen independently of the training examples and'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 98}, page_content='94 \\n \\nthe hypothesis.  \\n \\n2. Variance in the estimate. Even if the hypothesis accuracy is measured over an unbiased set of test \\nexamples independent of the training examples, the measured accuracy can still vary from the true \\naccuracy, depending on the makeup of the particular set of test examples. The smaller the set of test \\nexamples, the greater the expected variance.  \\n \\n4.2.2. Estimating Hypothesis Accuracy  \\n \\nSample Error ‚Äì  \\nThe sample error of a hypothesis with respect to some sample S of instances drawn from X is the \\nfraction of S that it misclassifies.  \\n \\nDefinition: The sample error (errors(h)) of hypothesis h with respect to target function f and data \\nsample S is \\n \\n \\n \\nWhere n is the number of examples in S, and the quantity Œ¥(f(x), h(x)) is 1 if f (x) ‚â† h(x), and 0 \\notherwise. \\nTrue Error ‚Äì  \\nThe true error of a hypothesis is the probability that it will misclassify a single randomly drawn \\ninstance from the distribution D.  \\nDefinition: The true error (errorD (h)) of hypothesis h with respect to target function f and \\ndistribution D, is the probability that h will misclassify an instance drawn at random according to D. \\n \\n \\nConfidence Intervals for Discrete-Valued Hypotheses  \\nSuppose we wish to estimate the true error for some discrete valued hypothesis h, based on its \\nobserved sample error over a sample S, where  \\n\\uf0b7 \\nThe sample S contains n examples drawn independent of one another, and independent of h, \\naccording to the probability distribution D  \\n\\uf0b7 \\nn ‚â• 30  \\n\\uf0b7 \\nHypothesis h commits r errors over these n examples (i.e., errors (h) = r/n).  \\n \\nUnder these conditions, statistical theory allows to make the following assertions:  \\n1. Given no other information, the most probable value of errorD (h) is errors(h)  \\n2. With approximately 95% probability, the true error errorD (h) lies in the interval'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 99}, page_content='95 \\n \\n \\nExample:  \\nSuppose the data sample S contains n = 40 examples and that hypothesis h commits r = 12 errors over \\nthis data.  \\n\\uf0b7 \\nThe sample error is errors(h) = r/n = 12/40 = 0.30  \\n\\uf0b7 \\nGiven no other information, true error is errorD (h) = errors(h), i.e., errorD (h) = 0.30  \\n\\uf0b7 \\nWith the 95% confidence interval estimate for errorD (h).  \\n \\n \\n \\n= 0.30 ¬± (1.96 * 0.07)  \\n= 0.30 ¬± 0.14 \\n3. A different constant, ZN, is used to calculate the N% confidence interval. The general expression for \\napproximate N% confidence intervals for errorD (h) is  \\n \\n \\n \\nWhere,  \\n \\n \\nThe above equation describes how to calculate the confidence intervals, or error bars, for estimates of \\nerrorD (h) that are based on errors(h)  \\n \\nExample:  \\nSuppose the data sample S contains n = 40 examples and that hypothesis h commits r = 12 errors over \\nthis data.  \\n\\uf0b7 \\nThe sample error is errors(h) = r/n = 12/40 = 0.30  \\n\\uf0b7 \\nWith the 68% confidence interval estimate for errorD (h).'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 100}, page_content='96 \\n \\n \\n= 0.30 ¬± (1.00 * 0.07)  \\n= 0.30 ¬± 0.07 \\n \\n4.2.3. Basics of Sampling Theory \\n4.2.3.1. Error Estimation and Estimating Binomial Proportions  \\n\\uf0b7 \\nCollect a random sample S of n independently drawn instances from the distribution D, and then \\nmeasure the sample error errors(h). Repeat this experiment many times, each time drawing a \\ndifferent random sample Si of size n, we would expect to observe different values for the various \\nerrorsi(h), depending on random differences in the makeup of the various Si. We say that errorsi(h), \\nthe outcome of the ith such experiment, is a random variable.  \\n\\uf0b7 \\nImagine that we were to run k random experiments, measuring the random variables errors1(h), \\nerrors2(h) . . . errorssk(h) and plotted a histogram displaying the frequency with which each \\npossible error value is observed.  \\n\\uf0b7 \\nAs k grows, the histogram would approach a particular probability distribution called the Binomial \\ndistribution which is shown in below figure.  \\n \\nA Binomial distribution is defined by the probability function \\n \\n \\n \\nIf the random variable X follows a Binomial distribution, then:  \\n\\uf0b7 \\nThe probability Pr(X = r) that X will take on the value r is given by P(r)'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 101}, page_content='97 \\n \\n \\n \\n4.2.3.2. The Binomial Distribution  \\nConsider the following problem for better understanding of Binomial Distribution  \\n\\uf0b7 \\nGiven a worn and bent coin and estimate the probability that the coin will turn up heads when \\ntossed.  \\n\\uf0b7 \\nUnknown probability of heads p. Toss the coin n times and record the number of times r that it \\nturns up heads.  \\nEstimate of p = r / n \\n\\uf0b7 \\nIf the experiment were rerun, generating a new set of n coin tosses, we might expect the \\nnumber of heads r to vary somewhat from the value measured in the first experiment, yielding \\na somewhat different estimate for p.  \\n\\uf0b7 \\nThe Binomial distribution describes for each possible value of r (i.e., from 0 to n), the probability \\nof observing exactly r heads given a sample of n independent tosses of a coin whose true \\nprobability of heads is p.  \\n \\nThe general setting to which the Binomial distribution applies is:  \\n1. There is a base experiment (e.g., toss of the coin) whose outcome can be described by a random \\nvariable ‚ÄòY‚Äô. The random variable Y can take on two possible values (e.g., Y = 1 if heads, Y = 0 if tails).  \\n2. The probability that Y = 1 on any single trial of the base experiment is given by some constant p, \\nindependent of the outcome of any other experiment. The probability that Y = 0 is therefore (1 - p). \\nTypically, p is not known in advance, and the problem is to estimate it.  \\n3. A series of n independent trials of the underlying experiment is performed (e.g., n independent coin \\ntosses), producing the sequence of independent, identically distributed random variables Y1, Y2, . . . , \\nYn. Let R denote the number of trials for which Yi = 1 in this series of n experiments  \\n \\n4. The probability that the random variable R will take on a specific value r (e.g., the probability of \\nobserving exactly r heads) is given by the Binomial distribution'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 102}, page_content='98 \\n \\n \\n \\nMean, Variance and Standard Deviation \\nThe Mean (expected value) is the average of the values taken on by repeatedly sampling the random \\nvariable  \\n \\nDefinition: Consider a random variable Y that takes on the possible values y1, . . . yn. The expected \\nvalue (Mean) of Y, E[Y], is  \\n \\nThe Variance captures how far the random variable is expected to vary from its mean value.  \\nDefinition: The variance of a random variable Y, Var[Y], is  \\n \\nThe variance describes the expected squared error in using a single observation of Y to estimate its \\nmean E[Y].  \\n \\nThe square root of the variance is called the standard deviation of Y, denoted œÉy  \\n \\nDefinition: The standard deviation of a random variable Y, œÉy, is  \\n \\nIn case the random variable Y is governed by a Binomial distribution, then the Mean, Variance and standard \\ndeviation are given by \\n \\n \\n4.2.3.3. Estimators, Bias, and Variance  \\nLet us describe errors(h) and errorD(h) using the terms in Equation (1) defining the Binomial \\ndistribution. We then have  \\n \\nWhere,  \\n\\uf0b7 \\nn is the number of instances in the sample S,'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 103}, page_content='99 \\n \\n\\uf0b7 \\nr is the number of instances from S misclassified by h  \\n\\uf0b7 \\np is the probability of misclassifying a single instance drawn from D  \\n \\n\\uf0b7 Estimator:  \\n \\nerrors(h) an estimator for the true error errorD(h): An estimator is any random variable used to \\nestimate some parameter of the underlying population from which the sample is drawn  \\n\\uf0b7 Estimation bias: is the difference between the expected value of the estimator and the true value of \\nthe parameter.  \\n \\nDefinition: The estimation bias of an estimator Y for an arbitrary parameter p is \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUNIT V \\nGenetic Algorithms \\n \\nMotivation, Genetic Algorithms: Representing Hypotheses, Genetic Operator, Fitness Function \\nand Selection, An Illustrative Example, Hypothesis Space Search, Genetic Programming, Models'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 104}, page_content='100 \\n \\nof Evolution and Learning: Lamarkian Evolution, Baldwin Effect, Parallelizing Genetic \\nAlgorithms. \\n \\n5.1. Motivation \\nGenetic algorithms (GAS) provide a learning method motivated by an analogy to biological \\nevolution. Rather than search from general-to-specific hypotheses, or from simple-to-complex, GAS \\ngenerate successor hypotheses by repeatedly mutating and recombining parts of the best currently \\nknown hypotheses. At each step, a collection of hypotheses called the current population is updated by \\nreplacing some fraction of the population by offspring of the most fit current hypotheses. The process \\nforms a generate-and-test beam-search of hypotheses, in which variants of the best current hypotheses \\nare most likely to be considered next. The popularity of GAS is motivated by a number of factors \\nincluding: \\n\\uf0b7 \\nEvolution is known to be a successful, robust method for adaptation within biological systems. \\n\\uf0b7 \\nGAS can search spaces of hypotheses containing complex interacting parts, where the impact of \\neach part on overall hypothesis fitness may be difficult to model. \\n\\uf0b7 \\nGenetic algorithms are easily parallelized and can take advantage of the decreasing costs of \\npowerful computer hardware. \\n \\n9.2 Genetic Algorithms \\nThe problem addressed by GAS is to search a space of candidate hypotheses to identify the best \\nhypothesis. In GAS the \"best hypothesis\" is defined as the one that optimizes a predefined numerical \\nmeasure for the problem at hand, called b the hypothesis fitness. For example, if the learning task is the \\nproblem of approximating an unknown function given training examples of its input and output, then \\nfitness could be defined as the accuracy of the hypothesis over this training data. If the task is to learn a \\nstrategy for playing chess, fitness could be defined as the number of games won by the individual when \\nplaying against other individuals in the current population. \\nAlthough different implementations of genetic algorithms vary in their details, they typically share the \\nfollowing structure: The algorithm operates by iteratively updating a pool of hypotheses, called the \\npopulation. On each iteration, all members of the population are evaluated according to the fitness \\nfunction. A new population is then generated by probabilistically selecting the fit individuals from the \\ncurrent population. Some of these selected individuals are carried forward into the next generation \\npopulation intact. Others are used as the basis for creating new offspring individuals by applying genetic \\noperations such as crossover and mutation.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 105}, page_content='101 \\n \\n \\n \\n \\nThe inputs to this algorithm include the fitness function for ranking candidate hypotheses, a \\nthreshold defining an acceptable level of fitness for terminating the algorithm, the size of the \\npopulation to be maintained, and parameters that determine how successor populations are to be \\ngenerated: the fraction of the population to be replaced at each generation and the mutation rate. \\nNotice in this algorithm each iteration through the main loop produces a new generation of hypotheses \\nbased on the current population. First, a certain number of hypotheses from the current population are \\nselected for inclusion in the next generation. These are selected probabilistically, where the probability \\nof selecting hypothesis hi is given by  \\n \\nThus, the probability that a hypothesis will be selected is proportional to its own fitness and is \\ninversely proportional to the fitness of the other competing hypotheses in the current population. \\nOnce these members of the current generation have been selected for inclusion in the next generation \\npopulation, additional members are generated using a crossover operation. Crossover, defined in detail \\nin the next section, takes two parent hypotheses from the current generation and creates two offspring \\nhypotheses \\nby recombining portions of both parents. The parent hypotheses are chosen probabilistically from the \\ncurrent population, again using the probability function given by Equation (9.1). After new members \\nhave been created by this crossover operation, the new generation population now contains the'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 106}, page_content='102 \\n \\ndesired number of members. At this point, a certain fraction m of these members are chosen at \\nrandom, and random mutations all performed to alter these members. \\n \\n \\nThis GA algorithm thus performs a randomized, parallel beam search for hypotheses that perform well \\naccording to the fitness function. In the following subsections, we describe in more detail the \\nrepresentation of hypotheses and genetic operators used in this algorithm. \\n \\nRepresenting Hypotheses \\nHypotheses in GAS are often represented by bit strings, so that they can be easily manipulated \\nby genetic operators such as mutation and crossover. The hypotheses represented by these bit strings \\ncan be quite complex. For example, sets of if-then rules can easily be represented in this way, by \\nchoosing an encoding of rules that allocates specific substrings for each rule precondition and \\npostcondition. \\nTo see how if-then rules can be encoded by bit strings, .first consider how we might use a bit \\nstring to describe a constraint on the value of a single attribute. To pick an example, consider the \\nattribute Outlook, which can take on any of the three values Sunny, Overcast, or Rain. One obvious way \\nto represent a constraint on Outlook is to use a bit string of length three, in which each bit position \\ncorresponds to one of its three possible values. Placing a 1 in some position indicates that the attribute \\nis allowed to take on the corresponding value. For example, the string 010 represents the constraint \\nthat Outlook must take on the second of these values, or Outlook = Overcast. Similarly, the string 011 \\nrepresents the more general constraint that allows two possible values, or (Outlook = Overcast v Rain). \\nNote 11 1 represents the most general possible constraint, indicating that we don\\'t care which of its \\npossible values the attribute takes on. \\nGiven this method for representing constraints on a single attribute, conjunctions of constraints \\non multiple attributes can easily be represented by concatenating the corresponding bit strings. For \\nexample, consider a second attribute, Wind, that can take on the value Strong or Weak. A rule \\nprecondition such as  \\n \\n(Outlook = Overcast ^Rain) A (Wind = Strong) \\n \\ncan then be represented by the following bit string of length five: \\n \\n    Outlook    Wind \\n01 1 \\n     10 \\n \\nRule postconditions (such as PlayTennis = yes) can be represented in a similar fashion. Thus, an entire \\nrule can be described by concatenating the bit strings describing the rule preconditions, together with \\nthe bit string describing the rule postcondition. For example, the rule \\n \\nIF Wind = Strong THEN PlayTennis = yes \\n \\nwould be represented by the string \\n \\n    Outlook    Wind    PlayTennis \\n111  \\n    10 \\n    10 \\n \\nwhere the first three bits describe the \"don\\'t care\" constraint on Outlook, the next two bits describe the \\nconstraint on Wind, and the final two bits describe the rule postcondition (here we assume PlayTennis'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 107}, page_content='103 \\n \\ncan take on the values Yes or No). Note the bit string representing the rule contains a substring for each \\nattribute in the hypothesis space, even if that attribute is not constrained by the rule preconditions. This \\nyields a fixed length bit-string representation for rules, in which substrings at specific locations describe \\nconstraints on specific attributes. Given this representation for single rules, we can represent sets of \\nrules by similarly concatenating the bit string representations of the individual rules. \\n \\n \\nIn designing a bit string encoding for some hypothesis space, it is useful to arrange for every \\nsyntactically legal bit string to represent a well-defined hypothesis. To illustrate, note in the rule \\nencoding in the above paragraph the bit string 11 1 10 11 represents a rule whose postcondition does \\nnot constrain the target attribute PlayTennis. If we wish to avoid considering this hypothesis, we may \\nemploy a different encoding (e.g., allocate just one bit to the PlayTennis postcondition to indicate \\nwhether the value is Yes or No), alter the genetic operators so that they explicitly avoid constructing \\nsuch bit strings, or simply assign a very low fitness to such bit strings. \\n \\nIn some GAS, hypotheses are represented by symbolic descriptions rather than bit strings.  \\n \\nGenetic Operators \\nThe generation of successors in a GA is determined by a set of operators that recombine and \\nmutate selected members of the current population. These operators correspond to idealized versions \\nof the genetic operations found in biological evolution. The two most common operators are crossover \\nand mutation. \\nThe crossover operator produces two new offspring from two parent strings, by copying \\nselected bits from each parent. The bit at position i in each offspring is copied from the bit at position i \\nin one of the two parents. The choice of which parent contributes the bit for position i is determined by \\nan additional string called the crossover mask. To illustrate, consider the single-point crossover \\noperator at the top of Table Consider the topmost of the two offspring in this case. This offspring takes \\nits first five bits from the first parent and its remaining six bits from the second parent, because the \\ncrossover mask 11 11 1000000 specifies these choices for each of the bit positions. The second offspring \\nuses the same crossover mask, but switches the roles of the two parents. Therefore, it contains the bits \\nthat were not used by the first offspring. In single-point crossover, the crossover mask is always \\nconstructed so that it begins with a string containing n contiguous Is, followed by the necessary number \\nof 0s to complete the string. This results in offspring in which the first n bits are contributed by one \\nparent and the remaining bits by the second parent. Each time the single-point crossover operator is \\napplied the crossover point n is chosen at random, and the crossover mask is then created and applied.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 108}, page_content='104 \\n \\n \\n \\n \\n \\n \\n \\n \\nIn two-point crossover, offspring are created by substituting intermediate segments of one parent into \\nthe middle of the second parent string. Put another way, the crossover mask is a string beginning with \\nno zeros, followed by a contiguous string of nl ones, followed by the necessary number of zeros to \\ncomplete the string. Each time the two-point crossover operator is applied, a mask is generated by \\nrandomly choosing the integers no and nl.  \\n \\nFitness Function and Selection \\nThe fitness function defines the criterion for ranking potential hypotheses and for \\nprobabilistically selecting them for inclusion in the next generation population. If the task is to learn \\nclassification rules, then the fitness function typically has a component that scores the classification \\naccuracy of the rule over a set of provided training examples. Often other criteria may be included as \\nwell, such as the complexity or generality of the rule. More generally, when the bit-string hypothesis is \\ninterpreted as a complex procedure (e.g., when the bit string represents a collection of if-then rules that \\nwill be chained together to control a robotic device), the fitness function may measure the overall \\nperformance of the resulting procedure rather than performance of individual rules. \\nIn our prototypical GA shown in above Table , the probability that a hypothesis will be selected is given \\nby the ratio of its fitness to the fitness of other members of the current population as seen in Equation \\nabove . This method is sometimes called fitness proportionate selection, or roulette wheel selection. \\nOther methods for using fitness to select hypotheses have also been proposed. For example, in \\ntournament selection, two hypotheses are first chosen at random from the current population. With \\nsome predefined probability p the more fit of these two is then selected, and with probability (1 - p) the \\nless fit hypothesis is selected. Tournament selection often yields a more diverse population than fitness \\nproportionate selection. In another method called rank selection, the hypotheses in the current \\npopulation are first sorted by fitness. The probability that a hypothesis will be selected is then \\nproportional to its rank in this sorted list, rather than its fitness.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 109}, page_content=\"105 \\n \\n \\n5.3. An Illustrative Example \\nA genetic algorithm can be viewed as a general optimization method that searches a large space \\nof candidate objects seeking one that performs best according to the fitness function. Although not \\nguaranteed to find an optimal object, GAS often succeed in finding an object with high fitness. GAS have \\nbeen applied to a number of optimization problems outside machine learning, including problems such \\nas circuit layout and job-shop scheduling. Within machine learning, they have been applied both to \\nfunction-approximation problems and to tasks such as choosing the network topology for artificial \\nneural network learning systems. \\nTo illustrate the use of GAS for concept learning, we briefly summarize the GABIL system \\ndescribed by DeJong et al. (1993). GABIL uses a GA to learn boolean concepts represented by a \\ndisjunctive set of propositional rules. In experiments over several concept learning problems, GABIL was \\nfound to be roughly comparable in generalization accuracy to other learning algorithms such as the \\ndecision tree learning algorithm C4.5 and the rule learning system AQ14. The learning tasks in this study \\nincluded both artificial learning tasks designed to explore the systems' generalization accuracy and the \\nreal world problem of breast cancer diagnosis. \\nThe specific instantiation of the GA algorithm in GABIL can be summarized as follows: \\nRepresentation. Each hypothesis in GABIL corresponds to a disjunctive set of propositional rules, \\nencoded as described in Section 9.2.1. In particular, the hypothesis space of rule preconditions consists \\nof a conjunction of constraints on a fixed set of attributes, as described in that earlier section. To \\nrepresent a set of rules, the bit-string representations of individual rules are concatenated. To illustrate, \\nconsider a hypothesis space in which rule preconditions are conjunctions of constraints over two \\nBoolean attributes, a1 and a2.The rule postcondition is described by a single bit that indicates the \\npredicted value of the target attribute c. Thus, the hypothesis consisting of the two rules \\n \\nIF al=T^a2=F THEN c=T; IF a2=T THEN c=F \\n \\n \\nwould be represented by the string \\n \\na1   a2   c   \\na1   a2   c \\n10  01  1 \\n11  01 0 \\n \\nNote the length of the bit string grows with the number of rules in the hypothesis. This variable bit-\\nstring length requires a slight modification to the crossover operator, as described below. \\n \\nGenetic operators. GABIL uses the standard mutation operator of  above Table in which a single \\nbit is chosen at random and replaced by its complement. The crossover operator that it uses is a fairly \\nstandard extension to the two-point crossover operator described in Table 9.2. In particular, to \\naccommodate the variable-length bit strings that encode rule sets, and to constrain the system so that \\ncrossover occurs only between like sections of the bit strings that encode rules, the following approach \\nis taken. To perform a crossover operation on two parents, two crossover points are first chosen at \\nrandom in the first parent string. Let dl (dz) denote the distance from the leftmost (rightmost) of these \\ntwo crossover points to the rule boundary immediately to its left. The crossover points in the second \\nparent are now randomly chosen, subject to the constraint that they must have the same dl and d2 \\nvalue. For example, if the two parent strings are\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 110}, page_content='106 \\n \\n \\n \\nand the crossover points chosen for the first parent are the points following bit positions 1 and 8, \\n \\n \\n \\nwhere \"[\" and \"1\" indicate crossover points, then dl = 1 and dz = 3. Hence the allowed pairs of crossover \\npoints for the second parent include the pairs of bit positions (1,3), (1,8), and (6,8). If the pair (1,3) \\nhappens to  be chosen, \\n \\n \\n \\nthen the two resulting offspring will be \\n \\n \\n \\nAs this example illustrates, this crossover operation enables offspring to contain a different number of \\nrules than their parents, while assuring that all bit strings generated in this fashion represent well-\\ndefined rule sets. \\nFitness function. The fitness of each hypothesized rule set is based on its classification accuracy over \\nthe training data. In particular, the function used to measure fitness is \\n \\n \\nwhere correct (h) is the percent of all training examples correctly classified by hypothesis h. \\n \\nIn experiments comparing the behavior of GABIL to decision tree learning algorithms such as \\nC4.5 and ID5R, and to the rule learning algorithm AQ14report roughly comparable performance among \\nthese systems, tested on a variety of learning problems. For example, over a set of 12 synthetic \\nproblems, GABIL achieved an average generalization accuracy of 92.1 %, whereas the performance of \\nthe other systems ranged from 91.2 % to 96.6 %. \\n \\nExtensions'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 111}, page_content='107 \\n \\nIn one set of experiments they explored the addition of two new genetic operators that were \\nmotivated by the generalization operators common in many symbolic learning methods. The first of \\nthese operators,  AddAlternative, generalizes the constraint on a specific attribute by changing a 0 to a \\n1 in the substring corresponding to the attribute. For example, if the constraint on an attribute is \\nrepresented by the string 10010, this operator might change it to 101 10. This operator was applied \\nwith probability .O1 to selected members of the population on each generation. The second operator, \\nDropcondition performs a more drastic generalization step, by replacing all bits for a particular attribute \\nby a 1. This operator corresponds to generalizing the rule by completely dropping the constraint on the \\nattribute, and was applied on each generation with probability .60. The authors report this revised \\nsystem achieved an average performance of 95.2% over the above set of synthetic learning tasks, \\ncompared to 92.1% for the basic GA algorithm. \\n \\nIn the above experiment, the two new operators were applied with the same probability to each \\nhypothesis in the population on each generation. In a second experiment, the bit-string representation \\nfor hypotheses was extended to include two bits that determine which of these operators may be \\napplied to the hypothesis. In this extended representation, the bit string for a typical rule set hypothesis \\nwould be  \\n \\n \\n \\nwhere the final two bits indicate in this case that the AddAlternative operator may be applied to this bit \\nstring, but that the Dropcondition operator may not. These two new bits define part of the search \\nstrategy used by the GA and are themselves altered and evolved using the same crossover and mutation \\noperators that operate on other bits in the string. While the authors report mixed results with this \\napproach (i.e., improved performance on some problems, decreased performance on others), it \\nprovides an interesting illustration of how GAS might in principle be used to evolve their own \\nhypothesis search methods. \\n \\n5.4 Hypothesis Space Search \\nAs illustrated above, GAS employ a randomized beam search method to seek a maximally fit hypothesis. \\nThis search is quite different from that of other learning methods we have considered in this book. To \\ncontrast the hypothesis space search of GAS with that of neural network BACKPROPAGATION, for \\nexample, the radiant descent search in BACKPROPAGATION moves smoothly from one hypothesis to a \\nnew hypothesis that is very similar. In contrast, the GA search can move much more abruptly, replacing \\na parent hypothesis by an offspring that may be radically different from the parent. Note the GA search \\nis therefore less likely to fall into the same kind of local minima that can plague gradient descent \\nmethods.  \\nOne practical difficulty in some GA applications is the problem of crowding. Crowding is a phenomenon \\nin which some individual that is more highly fit than others in the population quickly reproduces, so that \\ncopies of this individual and very similar individuals take over a large fraction of the population. The \\nnegative impact of crowding is that it reduces the diversity of the population, thereby slowing further \\nprogress by the GA. Several strategies have been explored for reducing crowding. One approach is to \\nalter the selection function, using criteria such as tournament selection or rank selection in place of \\nfitness proportionate roulette wheel selection. A related strategy is \"fitness sharing,\" in which the \\nmeasured fitness of an individual is reduced by the presence of other, similar individuals in the \\npopulation. A third approach is to restrict the kinds of individuals allowed to recombine to form \\noffspring. For example, by allowing only the most similar individuals to recombine, we can encourage'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 112}, page_content='108 \\n \\nthe formation of clusters of similar individuals, or multiple \"subspecies\" within the population. A related \\napproach is to spatially distribute individuals and allow only nearby individuals to recombine. Many of \\nthese techniques are inspired by the analogy to biological evolution. \\n \\nPopulation Evolution and the Schema Theorem \\nIt is interesting to ask whether one can mathematically characterize the evolution over time of the \\npopulation within a GA. The schema theorem provides one such characterization. It is based on the \\nconcept of schemas, or patterns that describe sets of bit strings. To be precise, a schema is any string \\ncomposed of 0s, 1s, and *\\'s. Each schema represents the set of bit strings containing the indicated 0s \\nand 1s, with each ‚Äú*‚Äù interpreted as a \"don\\'t care.\" For example, the schema 0*10 represents the set of \\nbit strings that includes exactly 0010 and 01 10. \\nAn individual bit string can be viewed as a representative of each of the different schemas that it \\nmatches. For example, the bit string 0010 can be thought of as a representative of 24 distinct schemas \\nincluding 00**, 0* 10, ****, etc. Similarly, a population of bit strings can be viewed in terms of the set \\nof schemas that it represents and the number of individuals associated with each of these schema.  \\nThe schema theorem characterizes the evolution of the population within a GA in terms of the number \\nof instances representing each schema. Let m(s, t) denote the number of instances of schema s in the \\npopulation at time t (i.e., during the tth generation). The schema theorem describes the expected value \\nof m(s,t+1) in terms of m(s, t) and other properties of the schema, population, and GA algorithm \\nparameters. \\nThe evolution of the population in the GA depends on the selection step, the recombination step, and \\nthe mutation step. Let us start by considering just the effect of the selection step. Let f (h) denote the \\nfitness of the individual bit string h and \\n\\uf028\\uf029t\\nf\\n\\uf04b\\ndenote the average fitness of all individuals in the \\npopulation at time t. Let n be the total number of individuals in the population. Let \\npt\\ns\\nh\\n\\uf0c7\\n\\uf065\\n, indicate \\nthat the individual h is both a representative of schema s and a member of the population at time t. \\nFinally, let \\uf028\\n\\uf029t\\ns\\nu ,\\n\\uf0d9\\ndenote the average fitness of instances of schema s in the population at time t. \\nWe are interested in calculating the expected value of m(s,t+1), which we denote E[m(s,t+1)]. We can \\ncalculate E[m(s,t+1)] using the probability distribution for selection given in Equation, which can be \\nrestated using our current terminology as follows \\n \\nNow if we select one member for the new population according to this probability distribution, then the \\nprobability that we will select a representative of schema s is'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 113}, page_content=\"109 \\n \\n \\nThe second step above follows from the fact that by definition, \\n \\n \\n \\nEquation gives the probability that a single hypothesis selected by the GA will be an instance of schema \\ns. Therefore, the expected number of instances of s resulting from the n independent selection steps \\nthat create the entire new generation is just n times this probability. \\n \\n \\n \\nEquation states that the expected number of instances of schema s at generation t+1 is proportional to \\nthe average fitness \\uf028\\n\\uf029t\\ns\\nu ,\\n\\uf0d9\\n of instances of this schema at time t , and inversely proportional to the \\naverage fitness \\n\\uf028\\uf029t\\nf\\n\\uf04b\\n of all members of the population at time t. Thus, we can expect schemas with \\nabove average fitness to be represented with increasing frequency on successive generations. If we \\nview the GA as performing a virtual parallel search through the space of possible schemas at the same \\ntime it performs its explicit parallel search through the space of individuals, then Equation indicates that \\nmore fit schemas will grow in influence over time.  \\nWhile the above analysis considered only the selection step of the GA, the crossover and mutation \\nsteps must be considered as well. The schema theorem considers only the possible negative influence \\nof these genetic operators (e.g., random mutation may decrease the number of representatives of s, \\nindependent of \\uf028\\n\\uf029t\\ns\\nu ,\\n\\uf0d9\\n and considers only the case of single-point crossover. The full schema theorem \\nthus provides a lower bound on the expected frequency of schema s, as follows: \\n \\n \\nHere, pc is the probability that the single-point crossover operator will be applied \\nto an arbitrary individual, and pm, is the probability that an arbitrary bit of an arbitrary individual will be \\nmutated by the mutation operator. o(s) is the number of defined bits in schema s, where 0 and 1 are \\ndefined bits, but * is not. d(s) is the distance between the leftmost and rightmost defined bits in s. \\nFinally, l is the length of the individual bit strings in the population. Notice the leftmost term in Equation \\nis identical to the term from Equation and describes the effect of the selection step. The middle term \\ndescribes the effect of the single-point crossover operator-in particular, it describes the probability that \\nan arbitrary individual representing s will still represent s following application of this crossover \\noperator. The rightmost term describes the probability that an arbitrary individual representing schema \\ns will still represent schema s following application of the mutation operator. Note that the effects of \\nsingle-point crossover and mutation increase with the number of defined bits o(s) in the schema and \\nwith the distance d(s) between the defined bits. Thus, the schema theorem can be roughly interpreted \\nas stating that more fit schemas will tend to grow in influence, especially schemas containing a small \\nnumber of defined bits (i.e., containing a large number of *'s), and especially when these defined bits\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 114}, page_content='110 \\n \\nare near one another within the bit string. The schema theorem is perhaps the most widely cited \\ncharacterization of population evolution within a GA. One way in which it is incomplete is that it fails to \\nconsider the (presumably) positive effects of crossover and mutation. Numerous more recent \\ntheoretical analyses have been proposed, including analyses based on Markov chain models and on \\nstatistical mechanics models. \\n \\n5.5 GENETIC PROGRAMMING \\nGenetic programming (GP) is a form of evolutionary computation in which the individuals in the \\nevolving population are computer programs rather than bit strings. The basic genetic programming \\napproach and presents a broad range of simple programs that can be successfully learned by GP.  \\n \\nRepresenting Programs \\nPrograms manipulated by a GP are typically represented by trees corresponding to the parse tree of the \\nprogram. Each function call is represented by a node in the tree, and the arguments to the function are \\ngiven by its descendant nodes. For example, below Figure illustrates this tree representation for the \\nfunction sin(x) + \\uf028\\n\\uf029\\ny\\nx \\uf02b\\n2\\n. To apply genetic programming to a particular domain, the user must define \\nthe primitive functions to be considered (e.g., sin, cos, \\n, +, -, exponential~), as well as the terminals \\n(e.g., x, y, constants such as 2). The genetic programming algorithm then uses an evolutionary search to \\nexplore the vast space of programs that can be described using these primitives. As in a genetic \\nalgorithm, the prototypical genetic programming algorithm maintains a population of individuals (in this \\ncase, program trees). On each iteration, it produces a new generation of individuals using selection, \\ncrossover, and mutation. The fitness of a given individual program in the population is typically \\ndetermined by executing the program on a set of training data. Crossover operations are performed by \\nreplacing a randomly chosen subtree of one parent program by a subtree from the other parent \\nprogram.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 115}, page_content='111 \\n \\n \\n \\nAbove Figure  illustrates a typical crossover operation. It describes a set of experiments applying \\na GP to a number of applications. In his experiments, 10% of the current population, selected \\nprobabilistically according to fitness, is retained unchanged in the next generation. The remainder of \\nthe new generation is created by applying crossover to pairs of programs from the current generation, \\nagain selected probabilistically according to their fitness. The mutation operator was not used in this \\nparticular set of experiments. \\n \\nIllustrative Example \\nOne illustrative example presented by Koza (1992) involves learning an algorithm for stacking the blocks \\nshown in below Figure The task is to develop a general algorithm for stacking the blocks into a single \\nstack that spells the word \"universal,\" independent of the initial configuration of blocks in the world. \\nThe actions available for manipulating blocks allow moving only a single block at a time. In particular, \\nthe top block on the stack can be moved to the table surface, or a block on the table surface can be \\nmoved to the top of the stack.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 116}, page_content='112 \\n \\n \\n \\nAs in most GP applications, the choice of problem representation has a significant impact on the \\nease of solving the problem. In Koza\\'s formulation, the primitive functions used to compose programs \\nfor this task include the following three terminal arguments: \\n\\uf0b7 \\nCS (current stack), which refers to the name of the top block on the stack, or F if there is no \\ncurrent stack. \\n\\uf0b7 \\nTB (top correct block), which refers to the name of the topmost block on the stack, such that it \\nand those blocks beneath it are in the correct order. \\n\\uf0b7 \\nNN (next necessary), which refers to the name of the next block needed above TB in the stack, \\nin order to spell the word \"universal,\" or F if no more blocks are needed.  \\n \\nAs can be seen, this particular choice of terminal arguments provides a natural representation for \\ndescribing programs for manipulating blocks for this task. Imagine, in contrast, the relative difficulty of \\nthe task if we were to instead define the terminal arguments to be the x and y coordinates of each \\nblock. \\nIn addition to these terminal arguments, the program language in this application included the \\nfollowing primitive functions:  \\n\\uf0b7 \\n(MS x) (move to stack), if block x is on the table, this operator moves x to the top of the stack \\nand returns the value T. Otherwise, it does nothing and returns the value F. \\n\\uf0b7 \\n(MT x) (move to table), if block x is somewhere in the stack, this moves the block at the top of \\nthe stack to the table and returns the value T. Otherwise, it returns the value F. \\n\\uf0b7 \\n(EQ x y) (equal), which returns T if x equals y, and returns F otherwise. \\n\\uf0b7 \\n(NOT x), which returns T if x = F, and returns F if x = T. \\n\\uf0b7 \\n(DU x y) (do until), which executes the expression x repeatedly until expressiony returns the \\nvalue T. \\n \\nTo allow the system to evaluate the fitness of any given program, Koza provided a set of 166 training \\nexample problems representing a broad variety of initial block configurations, including problems of \\ndiffering degrees of difficulty. The fitness of any given program was taken to be the number of these \\nexamples solved by the algorithm. The population was initialized to a set of 300 random programs. \\nAfter 10 generations, the system discovered the following program, which solves all 166 problems. \\n \\n(EQ (DU (MT CS)(NOT CS)) (DU (MS NN)(NOT NN)) ) \\n \\nNotice this program contains a sequence of two DU, or \"Do Until\" statements. The first repeatedly'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 117}, page_content='113 \\n \\nmoves the current top of the stack onto the table, until the stack becomes empty. The second \"Do \\nUntil\" statement then repeatedly moves the next necessary block from the table onto the stack. The \\nrole played by the top level EQ expression here is to provide a syntactically legal way to sequence these \\ntwo \"Do Until\" loops. \\nSomewhat surprisingly, after only a few generations, this GP was able to discover a program that solves \\nall 166 training problems. Of course the ability of the system to accomplish this depends strongly on the \\nprimitive arguments and functions provided, and on the set of training example cases used to evaluate \\nfitness. \\n \\nRemarks on Genetic Programming \\nAs illustrated in the above example, genetic programming extends genetic algorithms to the \\nevolution of complete computer programs. Despite the huge size of the hypothesis space it must \\nsearch, genetic programming has been demonstrated to produce intriguing results in a number of \\napplications. A comparison of GP to other methods for searching through the space of computer \\nprograms, such as hillclimbing and simulated annealing, is given by O\\'Reilly and Oppacher (1994). \\nWhile the above example of GP search is fairly simple, Koza et al. (1996) summarize the use of a GP in \\nseveral more complex tasks such as designing electronic filter circuits and classifying segments of \\nprotein molecules. The filter circuit design problem provides an example of a considerably more \\ncomplex problem. Here, programs are evolved that transform a simple fixed seed circuit into a final \\ncircuit design. The primitive functions used by the GP to construct its programs are functions that edit \\nthe seed circuit by inserting or deleting circuit components and wiring connections. The fitness of each \\nprogram is calculated by simulating the circuit it outputs (using the SPICE circuit simulator) to determine \\nhow closely this circuit meets the design specifications for the desired filter. More precisely, the fitness \\nscore is the sum of the magnitudes of errors between the desired and actual circuit output at 101 \\ndifferent input frequencies. In this case, a population of size 640,000 was maintained, with selection \\nproducing 10% of the successor population, crossover producing 89%, and mutation producing 1%. The \\nsystem was executed on a 64-node parallel processor. Within the first randomly generated population, \\nthe circuits produced were so unreasonable that the SPICE simulator could not even simulate the \\nbehavior of 98% of the circuits. The percentage of unsimulatable circuits dropped to 84.9% following \\nthe first generation, to 75.0% following the second generation, and to an average of 9.6% over \\nsucceeding generations. The fitness score of the best circuit in the initial population was 159, compared \\nto a score of 39 after 20 generations and a score of 0.8 after 137 generations. The best circuit, produced \\nafter 137 generations, exhibited performance very similar to the desired behavior. \\nIn most cases, the performance of genetic programming depends crucially on the choice of \\nrepresentation and on the choice of fitness function. For this reason, an active area of current research \\nis aimed at the automatic discovery and incorporation of subroutines that improve on the original set of \\nprimitive functions, thereby allowing the system to dynamically alter the primitives from which it \\nconstructs individuals. See, for example, Koza (1994). \\n \\n5.6 Models of Evolution and Learning \\nIn many natural systems, individual organisms learn to adapt significantly during their lifetime. \\nAt the same time, biological and social processes allow their species to adapt over a time frame of many \\ngenerations. One interesting question regarding evolutionary systems is \"What is the relationship \\nbetween learning during the lifetime of a single individual, and the longer time frame species-level \\nlearning afforded by evolution?\\' \\n \\nLamarckian Evolution \\nLarnarck was a scientist who, in the late nineteenth century, proposed that evolution over many \\ngenerations was directly influenced by the experiences of individual organisms during their lifetime. In'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 118}, page_content='114 \\n \\nparticular, he proposed that experiences of a single organism directly affected the genetic makeup of \\ntheir offspring: If an individual learned during its lifetime to avoid some toxic food, it could pass this \\ntrait on genetically to its offspring, which therefore would not need to learn the trait. This is an \\nattractive conjecture, because it would presumably allow for more efficient evolutionary progress than \\na generate-and-test process (like that of GAS and GPs) that ignores the experience gained during an \\nindividual\\'s lifetime. Despite the attractiveness of this theory, current scientific evidence \\noverwhelmingly contradicts Lamarck\\'s model. The currently accepted view is that the genetic makeup \\nof an individual is, in fact, unaffected by the lifetime experience of one\\'s biological parents. Despite this \\napparent biological fact, recent computer studies have shown that Lamarckian processes can \\nsometimes improve the effectiveness of computerized genetic algorithms (see Grefenstette 1991; \\nAckley and Littman 1994; and Hart and Belew 1995). \\n \\nBaldwin Effect \\nAlthough Lamarckian evolution is not an accepted model of biological evolution, other mechanisms \\nhave been suggested by which individual learning can alter the course of evolution. One such \\nmechanism is called the Baldwin effect, after J. M. Baldwin (1896), who first suggested the idea. The \\nBaldwin effect is based on the following observations: \\n\\uf0b7 \\nIf a species is evolving in a changing environment, there will be evolutionary pressure to favor \\nindividuals with the capability to learn during their lifetime. For example, if a new predator \\nappears in the environment, then individuals capable of learning to avoid the predator will be \\nmore successful than individuals who cannot learn. In effect, the ability to learn allows an \\nindividual to perform a small local search during its lifetime to maximize its fitness. In contrast, \\nnonlearning individuals whose fitness is fully determined by their genetic makeup will operate \\nat a relative disadvantage. \\n\\uf0b7 \\nThose individuals who are able to learn many traits will rely less strongly on their genetic code \\nto \"hard-wire\" traits. As a result, these individuals can support a more diverse gene pool, relying \\non individual learning to overcome the \"missing\" or \"not quite optimized\" traits in the genetic \\ncode. This more diverse gene pool can, in turn, support more rapid evolutionary adaptation. \\nThus, the ability of individuals to learn can have an indirect accelerating effect on the rate of \\nevolutionary adaptation for the entire population. \\n \\nTo illustrate, imagine some new change in the environment of some species, such as a new \\npredator. Such a change will selectively favor individuals capable of learning to avoid the predator. As \\nthe proportion of such self-improving individuals in the population grows, the population will be able to \\nsupport a more diverse gene pool, allowing evolutionary processes (even non-Lamarckian generate-\\nand-test processes) to adapt more rapidly. This accelerated adaptation may in turn enable standard \\nevolutionary processes to more quickly evolve a genetic (nonlearned) trait to avoid the predator (e.g., \\nan instinctive fear of this animal). Thus, the Baldwin effect provides an indirect mechanism for \\nindividual learning to positively impact the rate of evolutionary progress. By increasing survivability and \\ngenetic diversity of the species, individual learning supports more rapid evolutionary progress, thereby \\nincreasing the chance that the species will evolve genetic, nonlearned traits that better fit the new \\nenvironment.  \\nThere have been several attempts to develop computational models to study the Baldwin \\neffect. For example, Hinton and Nowlan (1987) experimented with evolving a population of simple \\nneural networks, in which some network weights were fixed during the individual network \"lifetime,\" \\nwhile others were trainable. The genetic makeup of the individual determined which weights were'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'total_pages': 120, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 119}, page_content='115 \\n \\ntrainable and which were fixed. In their experiments, when no individual learning was allowed, the \\npopulation failed to improve its fitness over time. However, when individual learning was allowed, the \\npopulation quickly improved its fitness. During early generations of evolution the population contained \\na greater proportion of individuals with many trainable weights. However, as evolution proceeded, the \\nnumber of fixed, correct network weights tended to increase, as the population evolved toward \\ngenetically given weight values and toward less dependence on individual learning of weights. \\nAdditional computational studies of the Baldwin effect have been reported by Belew (1990), Harvey \\n(1993), and French and Messinger (1994). An excellent overview of this topic can be found in Mitchell \\n(1996). A special issue of the journal Evolutionary Computation on this topic (Turney et al. 1997) \\ncontains several articles on the Baldwin effect. \\n \\n5.7 Parallelizing Genetic Algorithms \\nGAS are naturally suited to parallel implementation, and a number of approaches to \\nparallelization have been explored. Coarse grain approaches to parallelization subdivide the population \\ninto somewhat distinct groups of individuals, called demes. Each deme is assigned to a different \\ncomputational node, and a standard GA search is performed at each node. Communication and cross-\\nfertilization between demes occurs on a less frequent basis than within demes. Transfer between \\ndemes occurs by a migration process, in which individuals from one deme are copied or transferred to \\nother demes. This process is modeled after the kind of cross-fertilization that might occur between \\nphysically separated subpopulations of biological species. One benefit of such approaches is that it \\nreduces the crowding problem often encountered in nonparallel GAS, in which the system falls into a \\nlocal optimum due to the early appearance of a genotype that comes to dominate the entire \\npopulation. Examples of coarse-grained parallel GAS are described by Tanese (1989) and by Cohoon et \\nal. (1987). \\nIn contrast to coarse-grained parallel implementations of GAS, fine-grained implementations \\ntypically assign one processor per individual in the population. Recombination then takes place among \\nneighboring individuals. Several different types of neighborhoods have been proposed, ranging from \\nplanar grid to torus. Examples of such systems are described by Spiessens and Manderick (1991). An \\nedited collection of papers on parallel GAS is available in Stender (1993).'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 0}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n1\\nChapter 2 \\nSimple Linear Regression Analysis \\n \\nThe simple linear regression model \\nWe consider the modelling between the dependent and one independent variable. When there is only one \\nindependent variable in the linear regression model, the model is generally termed as a simple linear \\nregression model.  When there are more than one independent variable in the model, then the linear model is \\ntermed as the multiple linear regression model. \\n \\nThe linear model \\nConsider a simple linear regression model \\n \\n0\\n1\\ny\\nX\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n \\nwhere y  is termed as the dependent or study variable and  X  is termed as the independent or explanatory \\nvariable. The terms \\n0\\n\\uf062 and \\n1\\n\\uf062 are the parameters of the model. The parameter \\n0\\n\\uf062 is termed as an intercept \\nterm, and the parameter \\n1\\n\\uf062 is termed as the slope parameter. These parameters are usually called as \\nregression coefficients. The unobservable error component \\uf065 accounts for the failure of data to lie on a \\nstraight line and represents the difference between the true and observed realization of y .  There can be \\nseveral reasons for such difference, e.g., the effect of all deleted variables in the model, variables may be \\nqualitative, inherent randomness in the observations etc. We assume that  \\uf065 is observed as an independent \\nand identically distributed random variable with mean zero and constant variance \\n2\\n\\uf073. Later, we will \\nadditionally assume that \\uf065 is normally distributed. \\n \\nThe independent variables are viewed as controlled by the experimenter, so it is considered as non-stochastic \\nwhereas y  is viewed as random variable with \\n0\\n1\\n( )\\nE y\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\nand \\n \\n2\\n( )\\n.\\nVar y\\n\\uf073\\n\\uf03d\\n \\nSometimes  X  can also be a random variable. In such a case, instead of the sample mean and sample \\nvariance of  y , we consider the conditional mean of y  given X\\nx\\n\\uf03d\\n as \\n \\n0\\n1\\n( | )\\nE y x\\nx\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 1}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n2\\nand the conditional variance of  y  given X\\nx\\n\\uf03d\\n as \\n \\n2\\n( | )\\nVar y x\\n\\uf073\\n\\uf03d\\n. \\n \\nWhen the values of  \\n2\\n0\\n1\\n,\\nand\\n\\uf062\\uf062\\n\\uf073 are known, the model is completely described. The parameters \\n0\\n1\\n,\\n\\uf062\\n\\uf062 and  \\n2\\n\\uf073 are generally unknown in practice and  \\uf065 is unobserved. The determination of the statistical model \\n0\\n1\\ny\\nX\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n depends on the determination (i.e., estimation ) of  \\n0\\n1\\n,\\n\\uf062\\n\\uf062 and  \\n2\\n\\uf073. In order to know the \\nvalues of these parameters, n  pairs of observations ( ,\\n)(\\n1,..., ) on  (\\n, )\\ni\\ni\\nx y\\ni\\nn\\nX y\\n\\uf03d\\n are observed/collected and \\nare used to determine these unknown parameters. \\n \\nVarious methods of estimation can be used to determine the estimates of the parameters. Among them, the \\nmethods of least squares and maximum likelihood are the popular methods of estimation. \\n \\nLeast squares estimation \\nSuppose a sample of  n   sets of paired observations ( ,\\n)  (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n is available. These observations \\nare assumed to satisfy the simple linear regression model, and so we can write \\n \\n0\\n1\\n(\\n1,2,..., ).\\ni\\ni\\ni\\ny\\nx\\ni\\nn\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n \\nThe principle of least squares estimates the parameters \\n0\\n1\\nand\\n\\uf062\\n\\uf062 by minimizing the sum of squares of the \\ndifference between the observations and the line in the scatter diagram. Such an idea is viewed from different \\nperspectives. When the vertical difference between the observations and the line in the scatter diagram is \\nconsidered, and its sum of squares is minimized to obtain the estimates of  \\n0\\n1\\nand\\n\\uf062\\n\\uf062, the method is known \\nas direct regression. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n(xi, \\n(Xi, \\nyi\\nxi  \\nDirect regression'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 2}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n3\\nAlternatively,  the sum of squares of the difference between the observations and the line in the horizontal \\ndirection in the scatter diagram can be minimized to obtain the estimates of \\n0\\n1\\nand\\n\\uf062\\n\\uf062. This is known as a \\nreverse  (or inverse) regression method. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nInstead of horizontal or vertical errors, if the sum of squares of perpendicular distances between the \\nobservations and the line in the scatter diagram is minimized to obtain the estimates of \\n0\\n1\\nand\\n\\uf062\\n\\uf062, the \\nmethod is known as orthogonal regression or major axis regression method. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n(Xi, Yi)\\n(xi, yi)\\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\nyi \\nxi,\\n    Reverse regression method \\n(xi \\n(Xi \\n)\\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\nyi \\nxi\\n    Major axis regression method'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 3}, page_content=\"Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n4\\nInstead of minimizing the distance, the area can also be minimized. The reduced major axis regression \\nmethod minimizes the sum of the areas of rectangles defined between the observed data points and the \\nnearest point on the line in the scatter diagram to obtain the estimates of regression coefficients. This is \\nshown in the following figure: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe method of least absolute deviation regression considers the sum of the absolute deviation of the \\nobservations from the line in the vertical direction in the scatter diagram as in the case of direct regression to \\nobtain the estimates of \\n0\\n1\\nand\\n\\uf062\\n\\uf062. \\n \\nNo assumption is required about the form of the probability distribution of \\ni\\uf065 in deriving the least squares \\nestimates. For the purpose of deriving the statistical inferences only,  we assume that \\n'\\ni s\\n\\uf065\\n are random \\nvariable with  \\n2\\n( )\\n0,\\n( )\\nand\\n( ,\\n)\\n0 for all  \\n( ,\\n1,2,..., ).\\ni\\ni\\ni\\nj\\nE\\nVar\\nCov\\ni\\nj i j\\nn\\n\\uf065\\n\\uf065\\n\\uf073\\n\\uf065\\uf065\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b9\\n\\uf03d\\n  This assumption is \\nneeded to find the mean, variance and other properties of the least-squares estimates. The assumption that  \\n'\\ni s\\n\\uf065\\n are normally distributed is utilized while constructing the tests of hypotheses and confidence intervals \\nof the parameters. \\n \\nBased on these approaches, different estimates of \\n0\\n1\\nand\\n\\uf062\\n\\uf062 are obtained which have different statistical \\nproperties. Among them, the direct regression approach is more popular. Generally, the direct regression \\nestimates are referred to as the least-squares estimates or ordinary least squares estimates. \\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\n(xi  yi)\\n(Xi, Yi)\\nyi \\nxi\\nReduced major axis method\"),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 4}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n5\\nDirect regression method \\nThis method is also known as the ordinary least squares estimation.  Assuming that a set of n  paired \\nobservations on ( ,\\n),\\n1,2,...,\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n are available which satisfy the linear regression model \\n0\\n1\\ny\\nX\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n. \\nSo we can write the model for each observation as \\n0\\n1\\ni\\ni\\ni\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n, (\\n1,2,..., )\\ni\\nn\\n\\uf03d\\n. \\n \\nThe direct regression approach minimizes the sum of squares \\n \\n2\\n2\\n0\\n1\\n0\\n1\\n1\\n1\\n(\\n,\\n)\\n(\\n)\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\nS\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n \\nwith respect to \\n0\\n1\\nand  \\n\\uf062\\n\\uf062. \\n \\nThe partial derivatives of  \\n0\\n1\\n(\\n,\\n)\\nS \\uf062\\n\\uf062\\n with respect to \\n0\\n\\uf062\\n is \\n \\n0\\n1\\n0\\n1\\n1\\n0\\n(\\n,\\n)\\n2\\n(\\n)\\nn\\nt\\ni\\ni\\nS\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf0b6\\n\\uf03d\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0b6\\n\\uf0e5\\n \\nand the partial derivative of  \\n0\\n1\\n(\\n,\\n)\\nS \\uf062\\n\\uf062\\n with respect to \\n1\\n\\uf062 is  \\n \\n0\\n1\\n0\\n1\\n1\\n1\\n(\\n,\\n)\\n2\\n(\\n)\\nn\\ni\\ni\\ni\\ni\\nS\\ny\\nx x\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf0b6\\n\\uf03d\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0b6\\n\\uf0e5\\n. \\nThe solutions of \\n0\\n1\\nand  \\n\\uf062\\n\\uf062 are obtained by setting \\n \\n0\\n1\\n0\\n0\\n1\\n1\\n(\\n,\\n)\\n0\\n(\\n,\\n)\\n0.\\nS\\nS\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf0b6\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf0b6\\n \\nThe solutions of these two equations are called the direct regression estimators, or usually called as the \\nordinary least squares (OLS) estimators of  \\n0\\n1\\nand  \\n\\uf062\\n\\uf062. \\n \\nThis gives the ordinary least squares estimates \\n0\\n0\\n1\\n1\\nof\\nand  of \\nb\\nb\\n\\uf062\\n\\uf062 as \\n \\n0\\n1\\n1\\nxy\\nxx\\nb\\ny\\nb x\\ns\\nb\\ns\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n \\nwhere \\n \\n2\\n1\\n1\\n1\\n1\\n1\\n1\\n(\\n)(\\n),\\n(\\n) ,\\n,\\n.\\nn\\nn\\nn\\nn\\nxy\\ni\\ni\\nxx\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ns\\nx\\nx\\ny\\ny\\ns\\nx\\nx\\nx\\nx\\ny\\ny\\nn\\nn\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 5}, page_content=\"Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n6\\nFurther, we have  \\n \\n2\\n0\\n1\\n2\\n1\\n0\\n2\\n2\\n0\\n1\\n2\\n1\\n1\\n2\\n0\\n1\\n1\\n0\\n1\\n(\\n,\\n)\\n2\\n( 1)\\n2 ,\\n(\\n,\\n)\\n2\\n(\\n,\\n)\\n2\\n2\\n.\\nn\\ni\\nn\\ni\\ni\\nn\\nt\\ni\\nS\\nn\\nS\\nx\\nS\\nx\\nnx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf03d\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\n \\nThe  Hessian matrix which is the matrix of second-order partial derivatives, in this case, is given as  \\n \\n\\uf028\\n\\uf029\\n2\\n2\\n0\\n1\\n0\\n1\\n2\\n0\\n0\\n1\\n2\\n2\\n0\\n1\\n0\\n1\\n2\\n0\\n1\\n1\\n2\\n1\\n(\\n,\\n)\\n(\\n,\\n)\\n*\\n(\\n,\\n)\\n(\\n,\\n)\\n2\\n'\\n2\\n,\\n'\\nn\\ni\\ni\\nS\\nS\\nH\\nS\\nS\\nn\\nnx\\nnx\\nx\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf0b6\\n\\uf0b6\\n\\uf0e7\\n\\uf0f7\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0e7\\n\\uf0f7\\n\\uf03d\\uf0e7\\n\\uf0f7\\n\\uf0b6\\n\\uf0b6\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0e8\\n\\uf0f8\\n\\uf0e6\\n\\uf0f6\\n\\uf0e7\\n\\uf0f7\\n\\uf03d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf0e6\\n\\uf0f6\\n\\uf03d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf0e5\\n\\uf06c\\n\\uf06c\\n \\nwhere  \\n(1,1,...,1)'\\n\\uf03d\\n\\uf06c\\n is a n -vector of elements unity and \\n1\\n( ,...,\\n)'\\nn\\nx\\nx\\nx\\n\\uf03d\\n is a n -vector of observations on X .  \\nThe matrix \\n*\\nH\\n is positive definite if its determinant and the element in the first row and column of  \\n*\\nH\\n are \\npositive. The determinant of  \\n*\\nH\\n is given by  \\n \\n \\n2\\n2\\n2\\n1\\n2\\n1\\n*\\n4\\n4\\n(\\n)\\n0.\\nn\\ni\\ni\\nn\\ni\\ni\\nH\\nn\\nx\\nn x\\nn\\nx\\nx\\n\\uf03d\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf03d\\n\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf03d\\n\\uf02d\\n\\uf0b3\\n\\uf0e5\\n\\uf0e5\\n \\nThe case when  \\n2\\n1\\n(\\n)\\n0\\nn\\ni\\ni\\nx\\nx\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n is not interesting because all the observations, in this case, are identical, i.e. \\nix\\nc\\n\\uf03d\\n (some constant).  In such a case, there is no relationship between x  and y  in the context of regression \\nanalysis.  Since  \\n2\\n1\\n(\\n)\\n0,\\nn\\ni\\ni\\nx\\nx\\n\\uf03d\\n\\uf02d\\n\\uf03e\\n\\uf0e5\\n therefore  \\n0.\\nH \\uf03e\\n So H  is positive definite for  any  \\n0\\n1\\n(\\n,\\n)\\n\\uf062\\n\\uf062\\n , therefore, \\n0\\n1\\n(\\n,\\n)\\nS \\uf062\\n\\uf062\\n has a global minimum at  \\n0\\n1\\n(\\n,\\n).\\nb b\\n \\n \\nThe fitted line or the fitted linear regression model is\"),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 6}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n7\\n \\n0\\n1 .\\ny\\nb\\nb x\\n\\uf03d\\n\\uf02b\\n \\nThe predicted  values are \\n \\n0\\n1\\nÀÜ\\n(\\n1,2,..., ).\\ni\\ni\\ny\\nb\\nb x\\ni\\nn\\n\\uf03d\\n\\uf02b\\n\\uf03d\\n \\nThe difference between the observed value \\niy  and the fitted (or predicted) value  ÀÜiy  is called a residual. The \\nthi  residual is defined as  \\n \\n0\\n1\\nÀÜ\\n~\\n(\\n1,2,..., )\\nÀÜ\\n(\\n).\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ne\\ny\\ny i\\nn\\ny\\ny\\ny\\nb\\nb x\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n \\n \\nProperties of the direct regression estimators: \\n \\nUnbiased property: \\nNote that \\n1\\n0\\n1\\nand\\nxy\\nxx\\ns\\nb\\nb\\ny\\nb x\\ns\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n are the linear combinations of  \\n(\\n1,..., ).\\niy i\\nn\\n\\uf03d\\n \\nTherefore \\n \\n \\n1\\n1\\nn\\ni\\ni\\ni\\nb\\nk y\\n\\uf03d\\n\\uf03d\\uf0e5\\n \\n \\n1\\n1\\nwhere\\n(\\n)/\\n. Note that\\n0 and\\n1,\\nn\\nn\\ni\\ni\\nxx\\ni\\ni\\ni\\ni\\ni\\nk\\nx\\nx\\ns\\nk\\nk x\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n so \\n \\n1\\n1\\n0\\n1\\n1\\n1\\n( )\\n(\\n)\\n         \\n(\\n)\\n         \\n.\\nn\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\nE b\\nk E y\\nk\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02b\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n. \\nThis \\n1b  is an unbiased estimator of \\n1\\n\\uf062. Next   \\n \\n\\uf05b\\n\\uf05d\\n\\uf05b\\n\\uf05d\\n0\\n1\\n0\\n1\\n1\\n0\\n1\\n1\\n0\\n(\\n)\\n         \\n         \\n         \\n.\\nE b\\nE y\\nb x\\nE\\nx\\nb x\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n \\nThus  \\n0b\\n is an unbiased estimator of  \\n0\\n\\uf062.  \\n \\nVariances:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 7}, page_content=\"Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n8\\nUsing the assumption that \\n'\\niy s are independently distributed, the variance of  \\n1b  is \\n \\n2\\n1\\n1\\n2\\n2\\n1\\n2\\n2\\n2\\n2\\n( )\\n(\\n)\\n(\\n,\\n)\\n(\\n)\\n   (\\n(\\n,\\n)\\n0 as\\n,...,\\nare independent)\\n           =\\n           =\\n.\\nn\\ni\\ni\\ni\\nj\\ni\\nj\\ni\\ni\\nj i\\ni\\ni\\ni\\nj\\nn\\nxx\\nxx\\nxx\\nxx\\nVar b\\nk Var y\\nk k Cov y y\\nx\\nx\\nCov y y\\ny\\ny\\ns\\ns\\ns\\ns\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf0b9\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\uf0e5\\n\\uf0e5\\n \\nThe variance of  \\n0b  is \\n \\n2\\n0\\n1\\n1\\n(\\n)\\n( )\\n( )\\n2\\n( ,\\n).\\nVar b\\nVar y\\nx Var b\\nxCov y b\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n \\nFirst, we find that \\n\\uf07b\\n\\uf07d\\uf07b\\n\\uf07d\\n\\uf05b\\n\\uf05d\\n1\\n1\\n1\\n1\\n0\\n1\\n1\\n( ,\\n)\\n( )\\n( )\\n(\\n)\\n1\\n(\\n)(\\n)\\n1 0\\n0\\n0\\n0\\n                         \\n0\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nCov y b\\nE\\ny\\nE y\\nb\\nE b\\nE\\nc y\\nE\\nc\\nc x\\nc\\nn\\nn\\n\\uf065\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf03d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nSo   \\n2\\n2\\n0\\n1\\n(\\n)\\nxx\\nx\\nVar b\\nn\\ns\\n\\uf073\\uf0e6\\n\\uf0f6\\n\\uf03d\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n. \\n \\nCovariance: \\nThe covariance between  \\n0b  and  \\n1b  is \\n \\n0\\n1\\n1\\n1\\n2\\n(\\n,\\n)\\n( ,\\n)\\n( )\\n.\\nxx\\nCov b b\\nCov y b\\nxVar b\\nx\\ns \\uf073\\n\\uf03d\\n\\uf02d\\n\\uf03d\\uf02d\\n \\nIt can further be shown that the ordinary least squares estimators  \\n0b  and  \\n1b  possess the minimum variance \\nin the class of linear and unbiased estimators.  So they are termed as the Best Linear Unbiased Estimators \\n(BLUE).  Such a property is known as the Gauss-Markov theorem, which is discussed later in multiple \\nlinear regression model. \\nResidual sum of squares:\"),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 8}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n9\\nThe residual sum of squares is given as \\n \\n\\uf05b\\n\\uf05d\\n\\uf05b\\n\\uf05d\\n2\\n2\\n1\\n1\\n2\\n0\\n1\\n1\\n2\\n1\\n1\\n1\\n2\\n1\\n1\\n2\\n2\\n2\\n1\\n1\\n1\\n1\\n1\\n2\\n2\\n1\\n1\\n2\\n1\\n2\\nÀÜ\\n(\\n)\\n      \\n(\\n)\\n(\\n)\\n(\\n)\\n(\\n)\\n(\\n)\\n2\\n(\\n)(\\n)\\n2\\nn\\nn\\nres\\ni\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\nn\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nyy\\nxx\\nxx\\nyy\\nxx\\nxy\\nyy\\nxx\\nxx\\ny\\nSS\\ne\\ny\\ny\\ny\\nb\\nb x\\ny\\ny\\nb x\\nb x\\ny\\ny\\nb x\\nx\\ny\\ny\\nb\\nx\\nx\\nb\\nx\\nx\\ny\\ny\\ns\\nb s\\nb s\\ns\\nb s\\ns\\ns\\ns\\ns\\ns\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf0e6\\n\\uf0f6\\n\\uf03d\\n\\uf02d\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n2\\n1\\n      \\n.\\nxy\\ny\\nxx\\nyy\\nxy\\ns\\ns\\ns\\nb s\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n \\nwhere \\n2\\n1\\n1\\n1\\n(\\n) ,   \\n.\\nn\\nn\\nyy\\ni\\ni\\ni\\ni\\ns\\ny\\ny\\ny\\ny\\nn\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n \\n \\nEstimation of  \\n2\\n\\uf073 \\nThe estimator of  \\n2\\n\\uf073 is obtained from the residual sum of squares as follows. Assuming that \\niy  is normally \\ndistributed,  it follows that  \\nres\\nSS\\n  has a \\n2\\n\\uf063 distribution with (\\n2)\\nn \\uf02d\\n degrees  of freedom, so \\n                \\n2\\n2 ~\\n(\\n2).\\nres\\nSS\\nn\\n\\uf063\\n\\uf073\\n\\uf02d\\n \\nThus using the result about the expectation of a chi-square random variable, we have \\n2\\n(\\n)\\n(\\n2)\\n.\\nres\\nE SS\\nn\\n\\uf073\\n\\uf03d\\n\\uf02d\\n \\nThus an unbiased estimator of  \\n2\\n\\uf073 is \\n \\n2\\n.\\n2\\nres\\nSS\\ns\\nn\\n\\uf03d\\n\\uf02d\\n \\nNote that \\nres\\nSS\\n  has only (\\n2)\\nn \\uf02d\\n degrees of freedom. The two degrees of freedom are lost due to estimation \\nof  \\n0b  and  \\n1b .  Since  \\n2s  depends on the estimates \\n0b  and \\n1b , so it is a model-dependent estimate of  \\n2\\n\\uf073. \\n \\nEstimates of variances of \\n0b  and  \\n1b :'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 9}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n10\\n10\\n10\\nThe estimators of variances of  \\n0b  and \\n1b  are obtained  by    replacing \\n2\\n\\uf073 by  its estimate \\n2\\n2\\nÀÜ\\ns\\n\\uf073\\uf03d\\n as follows: \\n \\n\\uf0b6\\n2\\n2\\n0\\n1\\n(\\n)\\nxx\\nx\\nVar b\\ns\\nn\\ns\\n\\uf0e6\\n\\uf0f6\\n\\uf03d\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n \\nand \\n \\n\\uf0b6\\n2\\n1\\n( )\\nxx\\ns\\nVar b\\ns\\n\\uf03d\\n. \\nIt is observed that since \\n1\\nÀÜ\\n(\\n)\\n0,\\nn\\ni\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n  so \\n1\\n0.\\nn\\ni\\ni\\ne\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n  In the light of this property, \\nie  can be regarded as an \\nestimate of unknown \\n (\\n1,..., )\\ni i\\nn\\n\\uf065\\n\\uf03d\\n.  This helps in verifying the different model assumptions on the basis of  \\nthe given sample ( ,\\n), \\n1,2,..., .\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n \\n \\nFurther, note that  \\n (i)  \\n1\\n0,\\nn\\ni i\\ni\\nx e\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n \\n (ii)  \\n1\\nÀÜ\\n0,\\nn\\ni i\\ni\\ny e\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n  \\n(iii)   \\n1\\n1\\nÀÜ\\nn\\nn\\ni\\ni\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n and  \\n(iv)   the fitted line always passes through ( , ).\\nx y  \\n \\nCentered Model: \\nSometimes it is useful to measure the independent variable around its mean. In such a case, the model \\n0\\n1\\ni\\ni\\ni\\ny\\nX\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n has a centred version as follows: \\n0\\n1\\n1\\n*\\n0\\n1\\n(\\n)\\n(\\n1,2,..., )\\n(\\n)\\ni\\ni\\ni\\ni\\ny\\nx\\nx\\nx\\ni\\nn\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n \\nwhere \\n*\\n0\\n0\\n1x\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n. The sum of squares due to error is given by  \\n \\n2\\n*\\n2\\n*\\n0\\n1\\n0\\n1\\n1\\n1\\n(\\n,\\n)\\n(\\n)\\n.\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\nS\\ny\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf0e9\\n\\uf0f9\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0eb\\n\\uf0fb\\n\\uf0e5\\n\\uf0e5\\n \\nNow solving  \\n \\n*\\n0\\n1\\n*\\n0\\n*\\n0\\n1\\n*\\n1\\n(\\n,\\n)\\n0\\n(\\n,\\n)\\n0,\\nS\\nS\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf0b6\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf0b6\\n \\nwe get the direct regression least squares estimates of \\n*\\n0\\n1\\nand\\n\\uf062\\n\\uf062 as'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 10}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n11\\n11\\n11\\n \\n*\\n0b\\ny\\n\\uf03d\\n \\nand \\n \\n1\\nxy\\nxx\\ns\\nb\\ns\\n\\uf03d\\n, \\nrespectively. \\n \\nThus the form of the estimate of slope parameter \\n1\\n\\uf062 remains the same in the usual and centered model \\nwhereas the form of the estimate of intercept term changes in the usual and centered models. \\n \\nFurther, the Hessian matrix of the second order partial derivatives of   \\n*\\n0\\n1\\n(\\n,\\n)\\nS \\uf062\\n\\uf062 with respect to  \\n*\\n0\\n1\\nand\\n\\uf062\\n\\uf062 \\nis positive definite at  \\n*\\n*\\n0\\n0b\\n\\uf062\\uf03d\\n and  \\n1\\n1b\\n\\uf062\\uf03d\\n which ensures that  \\n*\\n0\\n1\\n(\\n,\\n)\\nS \\uf062\\n\\uf062 is minimized at \\n*\\n*\\n0\\n0b\\n\\uf062\\uf03d\\n and  \\n1\\n1b\\n\\uf062\\uf03d\\n. \\n \\n Under the assumption that \\n2\\n( )\\n0,\\n( )\\nand\\n(\\n)\\n0  for all \\n1,2,...,\\ni\\ni\\ni\\nj\\nE\\nVar\\nCov\\ni\\nj\\nn\\n\\uf065\\n\\uf065\\n\\uf073\\n\\uf065\\uf065\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b9\\n\\uf03d\\n, it follows that \\n \\n*\\n*\\n0\\n0\\n1\\n1\\n2\\n2\\n*\\n0\\n1\\n(\\n)\\n,\\n( )\\n,\\n(\\n)\\n,\\n( )\\n.\\nxx\\nE b\\nE b\\nVar b\\nVar b\\nn\\ns\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n \\nIn this case,  the fitted model of   \\n*\\n0\\n1(\\n)\\ni\\ni\\ni\\ny\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n is \\n \\n1(\\n),\\ny\\ny\\nb x\\nx\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n \\nand the predicted values are \\n \\n1\\nÀÜ\\n(\\n)\\n(\\n1,..., ).\\ni\\ni\\ny\\ny\\nb x\\nx\\ni\\nn\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n \\nNote that  in the centered model  \\n \\n \\n*\\n0\\n1\\n(\\n,\\n)\\n0.\\nCov b b \\uf03d\\n \\n \\n \\n \\n \\n \\n \\nNo intercept term model:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 11}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n12\\n12\\n12\\nSometimes in practice, a model without an intercept term is used in those situations when \\n0\\n0\\ni\\ni\\nx\\ny\\n\\uf03d\\n\\uf0de\\n\\uf03d\\n for \\nall \\n1,2,...,\\ni\\nn\\n\\uf03d\\n.  A no-intercept model is  \\n \\n \\n1\\n  (\\n1,2,.., ).\\ni\\ni\\ni\\ny\\nx\\ni\\nn\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf03d\\n \\nFor example, in analyzing the relationship between the velocity ( )\\ny  of a car and its acceleration (\\n)\\nX , the \\nvelocity is zero when acceleration is zero. \\n \\nUsing the data ( ,\\n),\\n1,2,..., ,\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n the direct regression least-squares  estimate of  \\n1\\n\\uf062 is obtained by \\nminimizing  \\n2\\n2\\n1\\n1\\n1\\n1\\n(\\n)\\n(\\n)\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\nS\\ny\\nx\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n and solving  \\n            \\n1\\n1\\n(\\n)\\n0\\nS \\uf062\\n\\uf062\\n\\uf0b6\\n\\uf03d\\n\\uf0b6\\n \\ngives the estimator of \\n1\\n\\uf062 as  \\n \\n*\\n1\\n1\\n2\\n1\\nn\\ni\\ni\\ni\\nn\\ni\\ni\\ny x\\nb\\nx\\n\\uf03d\\n\\uf03d\\n\\uf03d\\uf0e5\\n\\uf0e5\\n. \\nThe second-order partial derivative of  \\n1\\n(\\n)\\nS \\uf062\\n with respect to \\n1\\n\\uf062 at \\n1\\n1b\\n\\uf062\\uf03d\\n is positive which insures that  \\n1b  \\nminimizes  \\n1\\n(\\n).\\nS \\uf062\\n \\n \\nUsing the assumption that  \\n2\\n( )\\n0,\\n( )\\nand\\n(\\n)\\n0  for all \\n1,2,...,\\ni\\ni\\ni\\nj\\nE\\nVar\\nCov\\ni\\nj\\nn\\n\\uf065\\n\\uf065\\n\\uf073\\n\\uf065\\uf065\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b9\\n\\uf03d\\n,  the properties \\nof  \\n*\\n1b  can be derived as follows: \\n  \\n*\\n1\\n1\\n2\\n1\\n2\\n1\\n1\\n2\\n1\\n1\\n(\\n)\\n(\\n)\\n         \\n         \\nn\\ni\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\nx E y\\nE b\\nx\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nThis  \\n*\\n1b  is an unbiased estimator of  \\n1\\n\\uf062.  The variance of  \\n*\\n1b  is obtained as follows:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 12}, page_content=\"Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n13\\n13\\n13\\n \\n2\\n*\\n1\\n1\\n2\\n2\\n1\\n2\\n2\\n1\\n2\\n2\\n1\\n2\\n2\\n1\\n(\\n)\\n(\\n)\\n            \\n            \\ni\\nn\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\nx Var y\\nVar b\\nx\\nx\\nx\\nx\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nand an unbiased estimator of  \\n2\\n\\uf073 is obtained as  \\n \\n2\\n1\\n1\\n1\\n.\\n1\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ny\\nb\\ny x\\nn\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n \\n \\nMaximum likelihood estimation  \\nWe assume that \\n'\\n(\\n1,2,..., )\\ni s i\\nn\\n\\uf065\\n\\uf03d\\n are independent and identically distributed  following a normal \\ndistribution  \\n2\\n(0,\\n).\\nN\\n\\uf073\\n  Now we use the method of maximum likelihood to estimate the parameters of the \\nlinear regression model \\n \\n0\\n1\\n(\\n1,2,..., ),\\ni\\ni\\ni\\ny\\nx\\ni\\nn\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n \\nthe observations \\n(\\n1,2,..., )\\niy\\ni\\nn\\n\\uf03d\\n are independently distributed with  \\n2\\n0\\n1\\n(\\n,\\n)\\ni\\nN\\nx\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf02b\\n for all  \\n1,2,..., .\\ni\\nn\\n\\uf03d\\n   \\n \\n \\nThe likelihood function of the given observations ( ,\\n)\\ni\\ni\\nx y  and unknown parameters  \\n0\\n1\\n,\\n\\uf062\\n\\uf062 and  \\n2\\n\\uf073 is \\n \\n1/2\\n2\\n2\\n0\\n1\\n0\\n1\\n2\\n2\\n1\\n1\\n1\\n( ,\\n;\\n,\\n,\\n)\\nexp\\n(\\n)\\n.\\n2\\n2\\nn\\ni\\ni\\ni\\ni\\ni\\nL x y\\ny\\nx\\n\\uf062\\n\\uf062\\uf073\\n\\uf062\\n\\uf062\\n\\uf070\\uf073\\n\\uf073\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf0e9\\n\\uf0f9\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n\\uf0d5\\n \\nThe maximum likelihood estimates of  \\n0\\n1\\n,\\n\\uf062\\n\\uf062 and  \\n2\\n\\uf073  can be obtained by maximizing \\n2\\n0\\n1\\n( ,\\n;\\n,\\n,\\n)\\ni\\ni\\nL x y \\uf062\\uf062\\uf073\\n or \\nequivalently in \\n2\\n0\\n1\\nln ( ,\\n;\\n,\\n,\\n)\\ni\\ni\\nL x y \\uf062\\n\\uf062\\uf073\\n where \\n \\n2\\n2\\n2\\n0\\n1\\n0\\n1\\n2\\n1\\n1\\nln\\n( ,\\n;\\n,\\n,\\n)\\nln 2\\nln\\n(\\n) .\\n2\\n2\\n2\\nn\\ni\\ni\\ni\\ni\\ni\\nn\\nn\\nL x y\\ny\\nx\\n\\uf062\\n\\uf062\\uf073\\n\\uf070\\n\\uf073\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf03d\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\uf0e5\"),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 13}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n14\\n14\\n14\\nThe normal equations are obtained by partial differentiation of log-likelihood with respect to \\n2\\n0\\n1\\n,\\nand\\n\\uf062\\uf062\\n\\uf073 \\nand equating them to zero as follows: \\n2\\n0\\n1\\n0\\n1\\n2\\n1\\n0\\n2\\n0\\n1\\n0\\n1\\n2\\n1\\n1\\n2\\n2\\n0\\n1\\n0\\n1\\n2\\n2\\n4\\n1\\nln ( ,\\n;\\n,\\n,\\n)\\n1\\n          \\n(\\n)\\n0\\nln ( ,\\n;\\n,\\n,\\n)\\n1\\n          \\n(\\n)\\n0\\nand\\nln ( ,\\n;\\n,\\n,\\n)\\n1\\n          \\n(\\n)\\n0.\\n2\\n2\\nn\\ni\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\ni\\ni\\nL x y\\ny\\nx\\nL x y\\ny\\nx x\\nL x y\\nn\\ny\\nx\\n\\uf062\\n\\uf062\\uf073\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf062\\n\\uf062\\uf073\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf062\\n\\uf062\\uf073\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf03d\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0b6\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nThe solution of these normal equations give the maximum likelihood estimates of  \\n0\\n1\\n,\\n\\uf062\\n\\uf062 and  \\n2\\n\\uf073 as \\n0\\n1\\n1\\n1\\n2\\n1\\n2\\n0\\n1\\n2\\n1\\n          \\n(\\n)(\\n)\\n          \\n(\\n)\\nand\\n(\\n)\\n          \\nn\\ni\\ni\\nxy\\ni\\nn\\nxx\\ni\\ni\\nn\\ni\\ni\\ni\\nb\\ny\\nb x\\nx\\nx\\ny\\ny\\ns\\nb\\ns\\nx\\nx\\ny\\nb\\nb x\\ns\\nn\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf025\\n\\uf025\\n\\uf025\\n\\uf025\\n\\uf025\\n\\uf025\\n \\nrespectively. \\n \\nIt can be verified that the Hessian matrix of second-order partial derivation of  ln L  with respect to  \\n0\\n1\\n,\\n\\uf062\\n\\uf062, \\nand  \\n2\\n\\uf073 is negative definite at  \\n0\\n0\\n1\\n1\\n,\\n,\\nb\\nb\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf025\\n\\uf025 and  \\n2\\n2s\\n\\uf073\\uf03d\\uf025 which ensures that the likelihood function is \\nmaximized at these values. \\n \\nNote that the least-squares and maximum likelihood estimates of  \\n0\\n\\uf062 and  \\n1\\n\\uf062 are identical. The least-squares \\nand maximum likelihood estimates of  \\n2\\n\\uf073  are different. In fact, the least-squares estimate of  \\n2\\n\\uf073 is \\n \\n2\\n2\\n1\\n1\\n(\\n)\\n2\\nn\\ni\\ni\\ns\\ny\\ny\\nn\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\uf0e5\\n \\nso that it is related to the maximum likelihood estimate as  \\n2\\n2\\n2\\n.\\nn\\ns\\ns\\nn\\n\\uf02d\\n\\uf03d\\n\\uf025\\n \\nThus  \\n0b\\uf025 and \\n1b\\uf025 are unbiased estimators of \\n0\\n\\uf062 and  \\n1\\n\\uf062 whereas \\n2s\\uf025 is a biased estimate of  \\n2\\n\\uf073, but it is \\nasymptotically unbiased. The variances of  \\n0b\\uf025 and  \\n1b\\uf025 are same as of  \\n0 and\\nb\\n1b  respectively but \\n2\\n2\\n(\\n)\\n(\\n).\\nVar s\\nVar s\\n\\uf03c\\n\\uf025\\n \\nTesting of hypotheses and confidence interval estimation for slope parameter:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 14}, page_content=\"Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n15\\n15\\n15\\nNow we consider the tests of hypothesis and confidence interval estimation for the slope parameter of the \\nmodel under two cases, viz., when \\n2\\n\\uf073 is known and when  \\n2\\n\\uf073 is unknown. \\n \\nCase 1: When \\n2\\n\\uf073 is known: \\nConsider the simple linear regression model  \\n0\\n1\\n(\\n1,2,..., )\\ni\\ni\\ni\\ny\\nx\\ni\\nn\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n. It is assumed that \\n'\\ni s\\n\\uf065\\n are \\nindependent and identically distributed and follow \\n2\\n(0,\\n).\\nN\\n\\uf073\\n \\n \\nFirst, we develop a test for the null hypothesis related to the slope parameter \\n \\n0\\n1\\n10\\n:\\nH\\n\\uf062\\n\\uf062\\n\\uf03d\\n \\nwhere  \\n10\\n\\uf062 is some given constant. \\n \\nAssuming  \\n2\\n\\uf073 to be known, we know that \\n2\\n1\\n1\\n1\\n1\\n( )\\n,\\n( )\\nand\\nxx\\nE b\\nVar b\\nb\\ns\\n\\uf073\\n\\uf062\\n\\uf03d\\n\\uf03d\\n is a linear combination of \\nnormally distributed  \\n'\\niy s.  So \\n \\n2\\n1\\n1\\n~\\n,\\nxx\\nb\\nN\\ns\\n\\uf073\\n\\uf062\\n\\uf0e6\\n\\uf0f6\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n \\nand so the following statistic can be constructed \\n \\n1\\n10\\n1\\n2\\nxx\\nb\\nZ\\ns\\n\\uf062\\n\\uf073\\n\\uf02d\\n\\uf03d\\n \\nwhich is distributed as \\n(0,1)\\nN\\n when  \\n0\\nH  is true. \\n \\nA decision rule to test  \\n1\\n1\\n10\\n:\\nH\\n\\uf062\\n\\uf062\\n\\uf0b9\\n can be framed  as follows:   \\nReject  \\n0\\nH  if \\n1\\n/2\\nZ\\nZ\\uf061\\n\\uf03e\\n \\nwhere \\n/2\\nZ\\uf061\\n is the \\n/ 2\\n\\uf061\\n percent points on the normal distribution.   \\n \\nSimilarly, the decision rule for one-sided alternative hypothesis can also be framed. \\n \\n \\nThe 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval for  \\n1\\n\\uf062 can  be obtained  using the \\n1\\nZ  statistic as follows:\"),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 15}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n16\\n16\\n16\\n \\n\\uf05b\\n\\uf05d\\n/2\\n1\\n/2\\n1\\n1\\n/2\\n/2\\n2\\n2\\n2\\n1\\n/2\\n1\\n1\\n/2\\n1\\n1\\n1\\n.\\nxx\\nxx\\nxx\\nP\\nz\\nZ\\nz\\nb\\nP\\nz\\nz\\ns\\nP b\\nz\\nb\\nz\\ns\\ns\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf062\\n\\uf061\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf062\\n\\uf061\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf02b\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nSo 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval for  \\n1\\n\\uf062 is  \\n \\n2\\n2\\n1\\n/2\\n1\\n/2\\n,\\nxx\\nxx\\nb\\nz\\nb\\nz\\ns\\ns\\n\\uf061\\n\\uf061\\n\\uf073\\n\\uf073\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nwhere  \\n/ 2\\nz\\uf061\\n is the \\n/ 2\\n\\uf061\\n percentage point of the \\n(0,1)\\nN\\n distribution. \\n \\nCase 2: When \\n2\\n\\uf073 is unknown: \\nWhen  \\n2\\n\\uf073 is unknown then we proceed as follows.  We know that  \\n2\\n2 ~\\n(\\n2)\\nres\\nSS\\nn\\n\\uf063\\n\\uf073\\n\\uf02d\\n \\n \\nand \\n \\n2.\\n2\\nres\\nSS\\nE n\\n\\uf073\\n\\uf0e6\\n\\uf0f6\\uf03d\\n\\uf0e7\\n\\uf0f7\\n\\uf02d\\n\\uf0e8\\n\\uf0f8\\n \\nFurther,  \\n2\\n/\\nres\\nSS\\n\\uf073 and  \\n1b  are independently distributed.  This result will be proved formally later in the next \\nmodule on multiple linear regression. This result also follows from the result that under normal distribution, \\nthe maximum likelihood estimates, viz., the sample mean (estimator of population mean) and the sample \\nvariance (estimator of population variance) are independently distributed, so \\n1b  and \\n2s  are also \\nindependently distributed. \\nThus the  following statistic can be constructed: \\n \\n1\\n1\\n0\\n2\\n1\\n1\\nÀÜ\\n(\\n2)\\nxx\\nres\\nxx\\nb\\nt\\ns\\nb\\nSS\\nn\\ns\\n\\uf062\\n\\uf073\\n\\uf062\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n \\nwhich follows a t -distribution with (\\n2)\\nn \\uf02d\\n degrees of freedom, denoted as \\n2\\nnt \\uf02d,  when   \\n0\\nH  is true. \\nA decision rule to test  \\n1\\n1\\n10\\n:\\nH\\n\\uf062\\n\\uf062\\n\\uf0b9\\n is to'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 16}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n17\\n17\\n17\\n reject  \\n0\\nH  if  \\n0\\n2,\\n/2\\nn\\nt\\nt\\n\\uf061\\n\\uf02d\\n\\uf03e\\n \\nwhere \\n2,\\n/2\\nnt\\n\\uf061\\n\\uf02d\\n is the \\n/ 2\\n\\uf061\\n percent point of the t -distribution with (\\n2)\\nn \\uf02d\\n degrees of freedom. Similarly, the \\ndecision rule for the one-sided alternative hypothesis can also be framed. \\n \\nThe 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval of  \\n1\\n\\uf062 can be obtained  using the 0t   statistic as follows: \\nConsider \\n\\uf05b\\n\\uf05d\\n/2\\n0\\n/2\\n1\\n1\\n/2\\n/2\\n2\\n2\\n2\\n1\\n/2\\n1\\n1\\n1\\n1\\nÀÜ\\nÀÜ\\nÀÜ\\n/ 2\\n1\\n.\\nxx\\nxx\\nxx\\nP\\nt\\nt\\nt\\nb\\nP\\nt\\nt\\ns\\nP b\\nt\\nb\\nt\\ns\\ns\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf062\\n\\uf061\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf062\\n\\uf061\\n\\uf061\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf02b\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nSo the 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval \\n1\\n\\uf062 is  \\n1\\n2, /2\\n1\\n2, /2\\n,\\n.\\n(\\n2)\\n(\\n2)\\nres\\nres\\nn\\nn\\nxx\\nxx\\nSS\\nSS\\nb\\nt\\nb\\nt\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02d\\n\\uf0eb\\n\\uf0fb\\n \\n \\nTesting of hypotheses and confidence interval estimation for intercept term: \\nNow, we consider the tests of hypothesis and confidence interval estimation for intercept term under two \\ncases, viz., when \\n2\\n\\uf073 is known and when \\n2\\n\\uf073 is unknown. \\n \\nCase 1: When \\n2\\n\\uf073 is known: \\nSuppose the null hypothesis under consideration is  \\n \\n0\\n0\\n00\\n:\\n,\\nH\\n\\uf062\\n\\uf062\\n\\uf03d\\n \\nwhere \\n2\\n\\uf073 is known, then  using the result that \\n2\\n2\\n0\\n0\\n0\\n0\\n1\\n(\\n)\\n,\\n(\\n)\\nand\\nx\\nx\\nE b\\nVar b\\nb\\nn\\ns\\n\\uf062\\n\\uf073\\uf0e6\\n\\uf0f6\\n\\uf03d\\n\\uf03d\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n is a linear \\ncombination of normally distributed random variables, the following statistic  \\n \\n0\\n00\\n0\\n2\\n2 1\\nxx\\nb\\nZ\\nx\\nn\\ns\\n\\uf062\\n\\uf073\\n\\uf02d\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n \\nhas a  \\n(0,1)\\nN\\n distribution when  \\n0\\nH  is true. \\nA decision rule to test  \\n1\\n0\\n00\\n:\\nH\\n\\uf062\\n\\uf062\\n\\uf0b9\\n can be framed  as follows:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 17}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n18\\n18\\n18\\nReject  \\n0\\nH  if \\n0\\n/2\\nZ\\nZ\\uf061\\n\\uf03e\\n \\nwhere \\n/2\\nZ\\uf061\\n is the \\n/ 2\\n\\uf061\\n percentage points on the normal distribution.  Similarly, the decision rule for one-\\nsided alternative hypothesis can also be framed. \\nThe 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence intervals for  \\n0\\n\\uf062 when  \\n2\\n\\uf073 is known can be derived using the \\n0\\nZ  statistic  as \\nfollows: \\n\\uf05b\\n\\uf05d\\n/2\\n0\\n/2\\n0\\n0\\n/2\\n/2\\n2\\n2\\n2\\n2\\n2\\n2\\n0\\n/2\\n0\\n0\\n/2\\n1\\n1\\n1\\n1\\n1\\n1\\n.\\nxx\\nxx\\nxx\\nP\\nz\\nZ\\nz\\nb\\nP\\nz\\nz\\nx\\nn\\ns\\nx\\nx\\nP b\\nz\\nb\\nz\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf062\\n\\uf061\\n\\uf073\\n\\uf073\\n\\uf062\\n\\uf073\\n\\uf061\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf0a3\\n\\uf0a3\\n\\uf02b\\n\\uf02b\\n\\uf03d\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n \\nSo the 100(1\\n)%\\n\\uf061\\n\\uf02d\\n of confidential interval of  \\n0\\n\\uf062 is  \\n  \\n   \\n2\\n2\\n2\\n2\\n0\\n/ 2\\n0\\n/2\\n1\\n1\\n,\\n.\\nxx\\nxx\\nx\\nx\\nb\\nz\\nb\\nz\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf073\\n\\uf073\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n \\n \\nCase 2: When \\n2\\n\\uf073 is unknown: \\nWhen  \\n2\\n\\uf073 is unknown, then the following statistic is constructed \\n \\n0\\n00\\n0\\n2\\n1\\n2\\nres\\nxx\\nb\\nt\\nSS\\nx\\nn\\nn\\ns\\n\\uf062\\n\\uf02d\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf02d\\n\\uf0e8\\n\\uf0f8\\n \\nwhich follows a t -distribution with (\\n2)\\nn \\uf02d\\n degrees of freedom, i.e., \\n2\\nnt \\uf02d  when  \\n0\\nH  is true. \\nA decision rule to test  \\n1\\n0\\n00\\n:\\nH\\n\\uf062\\n\\uf062\\n\\uf0b9\\n is as follows: \\nReject  \\n0\\nH  whenever  \\n0\\n2,\\n/2\\nn\\nt\\nt\\n\\uf061\\n\\uf02d\\n\\uf03e\\n \\nwhere \\n2,\\n/2\\nnt\\n\\uf061\\n\\uf02d\\n is the \\n/ 2\\n\\uf061\\n percentage point of the t -distribution with (\\n2)\\nn \\uf02d\\n degrees of freedom. Similarly, \\nthe decision rule for one-sided alternative hypothesis can also be framed. \\n \\n \\nThe 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval of  \\n0\\n\\uf062 can be obtained as follows: \\nConsider'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 18}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n19\\n19\\n19\\n2, /2\\n0\\n2, /2\\n0\\n0\\n2, /2\\n2, /2\\n2\\n2\\n2\\n0\\n2, /2\\n0\\n0\\n2, /2\\n1\\n1\\n1\\n2\\n1\\n1\\n1\\n.\\n2\\n2\\nn\\nn\\nn\\nn\\nres\\nxx\\nres\\nres\\nn\\nn\\nxx\\nxx\\nP t\\nt\\nt\\nb\\nP t\\nt\\nSS\\nx\\nn\\nn\\ns\\nSS\\nSS\\nx\\nx\\nP b\\nt\\nb\\nt\\nn\\nn\\ns\\nn\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf062\\n\\uf061\\n\\uf062\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf0a3\\n\\uf0a3\\n\\uf02b\\n\\uf02b\\n\\uf03d\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf02d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n \\n \\nSo 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval for \\n0\\n\\uf062 is  \\n2\\n2\\n0\\n2,\\n/2\\n0\\n2,\\n/ 2\\n1\\n1\\n,\\n.\\n2\\n2\\nres\\nres\\nn\\nn\\nxx\\nxx\\nSS\\nSS\\nx\\nx\\nb\\nt\\nb\\nt\\nn\\nn\\ns\\nn\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf02d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n \\n \\n \\nTest of hypothesis for  \\n2\\n\\uf073 \\nWe have considered two types of test statistics for testing the hypothesis about the intercept term and slope \\nparameter- when \\n2\\n\\uf073 is known and when \\n2\\n\\uf073 is unknown. While dealing with the case of known \\n2\\n\\uf073, the \\nvalue of \\n2\\n\\uf073 is known from some external sources like past experience, long association of the experimenter \\nwith the experiment, past studies etc. In such situations, the experimenter would like to test the hypothesis \\nlike \\n2\\n2\\n0\\n0\\n:\\nH\\n\\uf073\\n\\uf073\\n\\uf03d\\n against \\n2\\n2\\n0\\n0\\n:\\nH\\n\\uf073\\n\\uf073\\n\\uf0b9\\n where \\n2\\n0\\n\\uf073 is specified. The test statistic is based on the result  \\n2\\nes\\n2\\n2\\n~\\nr\\nn\\nSS\\n\\uf063\\n\\uf073\\n\\uf02d. So the test statistic is  \\n \\n2\\nes\\n0\\n2\\n2\\n0\\n~\\nr\\nn\\nSS\\nC\\n\\uf063\\n\\uf073\\n\\uf02d\\n\\uf03d\\n under \\n0\\nH .  \\nThe decision rule is to reject \\n0\\nH  if \\n2\\n0\\n2, /2\\nn\\nC\\n\\uf061\\n\\uf063\\uf02d\\n\\uf03c\\n or \\n2\\n0\\n2,1\\n/2\\nn\\nC\\n\\uf061\\n\\uf063\\uf02d\\n\\uf02d\\n\\uf03e\\n.  \\n \\n \\n \\n \\n \\nConfidence interval for  \\n2\\n\\uf073 \\nA confidence interval for  \\n2\\n\\uf073 can also be derived as follows. Since \\n2\\n2\\n2\\n/\\n~\\n,\\nres\\nn\\nSS\\n\\uf073\\n\\uf063\\uf02d\\n thus consider'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 19}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n20\\n20\\n20\\n \\n2\\n2\\n2, /2\\n2,1\\n/2\\n2\\n1\\nres\\nn\\nn\\nSS\\nP\\n\\uf061\\n\\uf061\\n\\uf063\\n\\uf063\\n\\uf061\\n\\uf073\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\n \\n2\\n2\\n2\\n2,1\\n/2\\n2,\\n/ 2\\n1\\nres\\nres\\nn\\nn\\nSS\\nSS\\nP\\n\\uf061\\n\\uf061\\n\\uf073\\n\\uf061\\n\\uf063\\n\\uf063\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n. \\nThe corresponding 100(1\\n)%\\n\\uf061\\n\\uf02d\\n confidence interval for  \\n2\\n\\uf073 is \\n \\n2\\n2\\n2,1\\n/2\\n2,\\n/2\\n,\\n.\\nres\\nres\\nn\\nn\\nSS\\nSS\\n\\uf061\\n\\uf061\\n\\uf063\\n\\uf063\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\n \\nJoint confidence region for  \\n0\\n\\uf062 and \\n1\\n\\uf062: \\nA joint confidence region for  \\n0\\n\\uf062 and  \\n1\\n\\uf062 can also be found.  Such a region will provide a 100(1\\n)%\\n\\uf061\\n\\uf02d\\n \\nconfidence that both the estimates of  \\n0\\n\\uf062 and  \\n1\\n\\uf062 are correct. Consider the centered version of the linear \\nregression model \\n \\n*\\n0\\n1(\\n)\\ni\\ni\\ni\\ny\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n \\nwhere  \\n*\\n0\\n0\\n1x\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n.  The least squares estimators of  \\n*\\n0\\n\\uf062 and  \\n1\\n\\uf062 are \\n*\\n0\\n1\\nand\\n,\\nxy\\nxx\\ns\\nb\\ny\\nb\\ns\\n\\uf03d\\n\\uf03d\\n \\nrespectively.   \\nUsing the results that  \\n \\n*\\n*\\n0\\n0\\n1\\n1\\n2\\n*\\n0\\n2\\n1\\n(\\n)\\n,\\n( )\\n,\\n(\\n)\\n,\\n( )\\n.\\nxx\\nE b\\nE b\\nVar b\\nn\\nVar b\\ns\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n \\nWhen  \\n2\\n\\uf073 is known, then the statistic \\n \\n*\\n*\\n0\\n0\\n2\\n~\\n(0,1)\\nb\\nN\\nn\\n\\uf062\\n\\uf073\\n\\uf02d\\n    and    \\n1\\n1\\n2 ~\\n(0,1).\\nxx\\nb\\nN\\ns\\n\\uf062\\n\\uf073\\n\\uf02d\\n \\n \\nMoreover, both statistics are independently distributed. Thus'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 20}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n21\\n21\\n21\\n \\n2\\n*\\n*\\n2\\n0\\n0\\n1\\n2\\n~\\nb\\nn\\n\\uf062\\n\\uf063\\n\\uf073\\n\\uf0e6\\n\\uf0f6\\n\\uf0e7\\n\\uf0f7\\n\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n     and        \\n2\\n2\\n1\\n1\\n1\\n2\\n~\\nxx\\nb\\ns\\n\\uf062\\n\\uf063\\n\\uf073\\n\\uf0e6\\n\\uf0f6\\n\\uf0e7\\n\\uf0f7\\n\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n \\nare also independently distributed because  \\n*\\n0\\n1\\nand\\nb\\nb  are independently distributed.  Consequently, the sum \\nof these two \\n \\n*\\n* 2\\n2\\n2\\n0\\n1\\n1\\n2\\n2\\n2\\n(\\n)\\n(\\n) ~\\n.\\no\\nxx\\nn b\\ns\\nb\\n\\uf062\\n\\uf062\\n\\uf063\\n\\uf073\\n\\uf073\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n \\nSince \\n \\n2\\n2\\n2 ~\\nres\\nn\\nSS\\n\\uf063\\n\\uf073\\n\\uf02d \\nand \\nres\\nSS\\n is independently distributed of  \\n*\\n0b  and  \\n1b , so the ratio \\n*\\n* 2\\n2\\n0\\n0\\n1\\n1\\n2\\n2\\n2,\\n2\\n2\\n(\\n)\\n(\\n)\\n2\\n~\\n.\\n(\\n2)\\nxx\\nn\\nres\\nn b\\ns\\nb\\nF\\nSS\\nn\\n\\uf062\\n\\uf062\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf02d\\n\\uf0e6\\n\\uf0f6\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf0e6\\n\\uf0f6\\n\\uf02d\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n \\nSubstituting  \\n*\\n0\\n0\\n1\\nb\\nb\\nb x\\n\\uf03d\\n\\uf02b\\n and  \\n*\\n0\\n0\\n1x\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n, we get \\n \\n2\\n2\\nf\\nres\\nQ\\nn\\nSS\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0e6\\n\\uf0f6\\n\\uf0ea\\n\\uf0fa\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\uf0eb\\n\\uf0fb\\n \\nwhere \\n \\n2\\n2\\n2\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n(\\n)\\n2\\n(\\n)(\\n)\\n(\\n) .\\nn\\nn\\nf\\nt\\ni\\ni\\ni\\nQ\\nn b\\nx b\\nb\\nx b\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n \\nSince \\n \\n2,\\n2\\n2\\n1\\n2\\nf\\nn\\nres\\nQ\\nn\\nP\\nF\\nSS\\n\\uf061\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0e6\\n\\uf0f6\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n \\nholds true for all values of  \\n0\\n\\uf062 and \\n1\\n\\uf062, so the 100(1\\n)\\n\\uf061\\n\\uf02d\\n% confidence region  for \\n0\\n\\uf062 and \\n1\\n\\uf062 is \\n \\n2,\\n2;1\\n.\\n2 .\\n2\\nf\\nn\\nres\\nQ\\nn\\nF\\nSS\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e6\\n\\uf0f6\\n\\uf0a3\\n\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\n. \\nThis confidence region is an ellipse which gives the 100(1\\n)%\\n\\uf061\\n\\uf02d\\n probability that  \\n0\\n\\uf062 and  \\n1\\n\\uf062 are contained \\nsimultaneously in this ellipse. \\n \\nAnalysis of variance:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 21}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n22\\n22\\n22\\nThe technique of analysis of variance is usually used for testing the  hypothesis related to equality of more \\nthan one parameters, like population means or slope parameters. It is more meaningful in case of multiple \\nregression model when there are more than one slope parameters. This technique is discussed and illustrated \\nhere to understand the related basic concepts and fundamentals which will be used in developing the analysis \\nof variance in the next module in multiple linear regression model where the explanatory variables are more \\nthan two. \\n \\nA test statistic for testing \\n0\\n1\\n:\\n0\\nH\\n\\uf062\\uf03d\\n can also be formulated using the analysis of variance technique as \\nfollows. \\n \\nOn the basis of the identity \\n \\nÀÜ\\nÀÜ\\n(\\n)\\n(\\n),\\ni\\ni\\ni\\ni\\ny\\ny\\ny\\ny\\ny\\ny\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n \\nthe sum of squared residuals is \\n \\n2\\n1\\n2\\n2\\n1\\n1\\n1\\nÀÜ\\n( )\\n(\\n)\\nÀÜ\\nÀÜ\\n(\\n)\\n(\\n)\\n2\\n(\\n)(\\n).\\nn\\ni\\ni\\ni\\nn\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nS b\\ny\\ny\\ny\\ny\\ny\\ny\\ny\\ny\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nFurther, consider \\n \\n1\\n1\\n1\\n2\\n2\\n1\\n1\\n2\\n1\\nÀÜ\\n(\\n)(\\n)\\n(\\n) (\\n)\\n(\\n)\\nÀÜ\\n(\\n) .\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\ny\\ny\\ny\\ny\\ny\\ny b x\\nx\\nb\\nx\\nx\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\n \\n \\nThus we have \\n \\n2\\n2\\n2\\n1\\n1\\n1\\nÀÜ\\nÀÜ\\n(\\n)\\n(\\n)\\n(\\n) .\\nn\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ny\\ny\\ny\\ny\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\n The term \\n2\\n1\\n(\\n)\\nn\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n is called the sum of squares about the mean, corrected sum of squares of  y  (i.e., \\nSScorrected), total sum of squares, or \\n.\\nyy\\ns\\n  \\nThe term \\n2\\n1\\nÀÜ\\n(\\n)\\nn\\ni\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\ndescribes the deviation: observation minus predicted value, viz., the residual sum   of  \\nsquares, i.e., \\n2\\n1\\nÀÜ\\n(\\n)\\nn\\nres\\ni\\ni\\ni\\nSS\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf0e5'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 22}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n23\\n23\\n23\\nwhereas the term  \\n2\\n1\\nÀÜ\\n(\\n)\\nn\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n describes the proportion of variability explained by the regression, \\n2\\ne\\n1\\nÀÜ\\n(\\n) .\\nn\\nr g\\ni\\ni\\nSS\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n \\n \\nIf all observations  \\niy  are located on a straight line, then in this case    \\n2\\n1\\nÀÜ\\n(\\n)\\n0\\nn\\ni\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n and thus \\ne\\ncorrected\\nr g\\nSS\\nSS\\n\\uf03d\\n. \\n \\nNote that \\ne\\nr g\\nSS\\n is completely determined by \\n1b  and so has only one degree of freedom. The total sum of \\nsquares  \\n2\\n1\\n(\\n)\\nn\\nyy\\ni\\ni\\ns\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n has (\\n1)\\nn \\uf02d\\n degrees of freedom due to constraint \\n1\\n(\\n)\\n0\\nn\\ni\\ni\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n and \\nres\\nSS\\n has \\n(\\n2)\\nn \\uf02d\\n degrees of freedom as it depends on the determination of  \\n0b  and  \\n1b . \\n \\nAll sums of squares are mutually independent and distributed as  \\n2\\ndf\\n\\uf063\\n with df  degrees of freedom if the \\nerrors are normally distributed. \\n \\nThe mean square due to regression is \\n \\ne\\ne\\n1\\nr g\\nr g\\nSS\\nMS\\n\\uf03d\\n \\nand mean square due to residuals is  \\n2\\nres\\nSS\\nMSE\\nn\\n\\uf03d\\n\\uf02d\\n. \\nThe test statistic for testing  \\n0\\n1\\n:\\n0\\nH\\n\\uf062\\uf03d\\n is \\n \\ne\\n0\\n.\\nr g\\nMS\\nF\\nMSE\\n\\uf03d\\n \\nIf  \\n0\\n1\\n:\\n0\\nH\\n\\uf062\\uf03d\\n is true, then  \\ne\\nr g\\nMS\\n and  MSE  are independently distributed and thus \\n \\n0\\n1,\\n2\\n~\\n.\\nn\\nF\\nF\\n\\uf02d \\n \\nThe decision rule for  \\n1\\n1\\n:\\n0\\nH\\n\\uf062\\uf0b9\\n is to reject \\n0\\nH  if \\n \\n0\\n1,\\n2;1\\nn\\nF\\nF\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf03e\\n \\nat \\uf061 level of significance.  The test procedure can be described in an  Analysis of variance table.'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 23}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n24\\n24\\n24\\n \\nAnalysis of variance for testing \\n0\\n1\\n:\\n0\\nH\\n\\uf062\\uf03d\\n \\nSource of variation \\nSum of squares \\nDegrees of freedom \\nMean square             F \\nRegression \\n \\ne\\nr g\\nSS\\n  \\n \\n \\n1 \\n \\n    \\ne\\nr g\\nMS\\n             \\ne /\\nr g\\nMS\\nMSE  \\nResidual \\n \\nres\\nSS\\n  \\n \\n         \\n2\\nn \\uf02d \\n \\n    MSE  \\nTotal  \\n \\nyy\\ns  \\n \\n \\n         \\n1\\nn \\uf02d \\n \\n \\nSome other forms of \\n,\\nreg\\nres\\nSS\\nSS\\nand \\nyy\\ns  can be derived as follows: \\nThe sample correlation coefficient then may be written as \\n.\\nxy\\nxy\\nxx\\nyy\\ns\\nr\\ns\\ns\\n\\uf03d\\n \\nMoreover,  we have \\n \\n1\\nxy\\nyy\\nxy\\nxx\\nxx\\ns\\ns\\nb\\nr\\ns\\ns\\n\\uf03d\\n\\uf03d\\n. \\nThe estimator of  \\n2\\n\\uf073 in this case may be expressed as \\n \\n2\\n2\\n1\\n1\\n2\\n1\\n   \\n.\\n2\\nn\\ni\\ni\\nres\\ns\\ne\\nn\\nSS\\nn\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n \\nVarious alternative formulations for  \\nres\\nSS\\n are in use as well: \\n \\n2\\n0\\n1\\n1\\n2\\n1\\n1\\n2\\n1\\n1\\n2\\n1\\n2\\n[\\n(\\n)]\\n[(\\n)\\n(\\n)]\\n2\\n \\n(\\n)\\n  \\n.\\nn\\nres\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\nyy\\nxx\\nxy\\nyy\\nxx\\nxy\\nyy\\nxx\\nSS\\ny\\nb\\nb x\\ny\\ny\\nb x\\nx\\ns\\nb s\\nb s\\ns\\nb s\\ns\\ns\\ns\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n \\nUsing this result, we find that \\n \\ncorrected\\nyy\\nSS\\ns\\n\\uf03d\\n \\nand'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 24}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n25\\n25\\n25\\n \\ne\\n2\\n2\\n1\\n1\\n(\\n)\\n \\n.\\nr g\\nyy\\nres\\nxy\\nxx\\nxx\\nxy\\nSS\\ns\\nSS\\ns\\ns\\nb s\\nb s\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n \\n \\nGoodness of fit of regression \\nIt can be noted that a fitted model can be said to be good when residuals are small. Since \\nres\\nSS\\n is based on \\nresiduals, so a measure of the quality of a fitted model can be based on \\nres\\nSS\\n. When the intercept term is \\npresent in the model, a measure of goodness of fit  of the model is given by \\n \\ne\\n2\\n1\\n.\\nr g\\nres\\nyy\\nyy\\nSS\\nSS\\nR\\ns\\ns\\n\\uf03d\\uf02d\\n\\uf03d\\n \\nThis is known as the coefficient of determination. This measure is based on the concept that how much \\nvariation in y ‚Äôs  stated by \\nyy\\ns  is explainable by \\nreg\\nSS\\n and how much unexplainable part is contained in \\nres\\nSS\\n.  The ratio \\ne /\\nr g\\nyy\\nSS\\ns  describes the proportion of variability that is explained by regression in relation \\nto the total variability of  y .  The ratio \\n/\\nres\\nyy\\nSS\\ns\\n describes the proportion of variability that is not covered \\nby the regression. \\nIt can be seen that \\n \\n2\\n2\\nxy\\nR\\nr\\n\\uf03d\\n \\nwhere  \\nxy\\nr  is the simple correlation coefficient between x and y. Clearly  \\n2\\n0\\n1\\nR\\n\\uf0a3\\n\\uf0a3, so a value of  \\n2\\nR  closer \\nto one indicates the better fit and value of  \\n2\\nR  closer to zero indicates the poor fit. \\n \\nPrediction of values of study variable \\nAn important use of linear regression modeling is to predict the average and actual values of the study \\nvariable. The term prediction of the value of study variable corresponds to knowing the value of  \\n( )\\nE y  (in \\ncase of average value) and value of y  (in case of actual value) for a given value of the explanatory variable. \\nWe consider both cases. \\nCase 1: Prediction of average value \\nUnder the linear regression model, \\n0\\n1\\n,\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n the fitted model is \\n0\\n1\\ny\\nb\\nb x\\n\\uf03d\\n\\uf02b\\n where \\n0\\n1\\nand\\nb\\nb  are  the \\nOLS estimators of  \\n0\\n1\\nand\\n\\uf062\\n\\uf062 respectively.'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 25}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n26\\n26\\n26\\nSuppose we want to predict the value of  \\n( )\\nE y  for a given value of  \\n0\\nx\\nx\\n\\uf03d\\n.  Then the predictor is given by \\n \\n\\uf0b7\\n0\\n0\\n/\\n0\\n1\\n0\\nÀÜ\\n( |\\n)\\ny x\\nE y x\\nb\\nb x\\n\\uf06d\\n\\uf03d\\n\\uf03d\\n\\uf02b\\n. \\nPredictive bias \\nThen the prediction error is given as \\n \\n0\\n|\\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n0\\n1\\n1\\n0\\nÀÜ\\n( )\\n(\\n)\\n(\\n)\\n(\\n)\\n(\\n)\\n.\\ny x\\nE y\\nb\\nb x\\nE\\nx\\nb\\nb x\\nx\\nb\\nb\\nx\\n\\uf06d\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n \\nThen \\n0\\n|\\n0\\n0\\n1\\n1\\n0\\nÀÜ\\n( )\\n(\\n)\\n(\\n)\\n0\\n0\\n0\\ny x\\nE\\nE y\\nE b\\nE b\\nx\\n\\uf06d\\n\\uf062\\n\\uf062\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf0eb\\n\\uf0fb\\n\\uf03d\\n\\uf02b\\n\\uf03d\\n \\nThus the predictor \\n0\\n/\\ny x\\n\\uf06d\\n is an unbiased predictor of  \\n( ).\\nE y  \\n \\nPredictive variance:   \\nThe predictive variance of  \\n0\\n|\\nÀÜ y x\\n\\uf06d\\n is \\n\\uf05b\\n\\uf05d\\n0\\n|\\n0\\n1\\n0\\n1\\n0\\n2\\n0\\n1\\n0\\n1\\n2\\n2\\n2\\n0\\n2\\n2\\n0\\nÀÜ\\n(\\n)\\n(\\n)\\n(\\n)\\n( )\\n(\\n)\\n( )\\n2(\\n)\\n( ,\\n)\\n(\\n)\\n0\\n(\\n)\\n1\\n.\\ny x\\nxx\\nxx\\nPV\\nVar b\\nb x\\nVar y\\nb x\\nx\\nVar y\\nx\\nx Var b\\nx\\nx Cov y b\\nx\\nx\\nn\\ns\\nx\\nx\\nn\\ns\\n\\uf06d\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf02b\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nEstimate of predictive variance \\nThe predictive variance can be estimated by substituting \\n2\\n2ÀÜ\\nby\\nMSE\\n\\uf073\\n\\uf073\\n\\uf03d\\n as \\n \\n\\uf0b6\\n0\\n2\\n2\\n0\\n|\\n2\\n0\\n(\\n)\\n1\\nÀÜ\\nÀÜ\\n(\\n)\\n(\\n)\\n1\\n.\\ny x\\nxx\\nxx\\nx\\nx\\nPV\\nn\\ns\\nx\\nx\\nMSE n\\ns\\n\\uf06d\\n\\uf073\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nPrediction interval estimation: \\nThe 100(1-\\n)%\\n\\uf061\\n prediction interval for \\n0\\n( /\\n)\\nE y x\\n is obtained as follows:'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 26}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n27\\n27\\n27\\nThe predictor \\n0\\n|\\nÀÜ y x\\n\\uf06d\\n is a linear combination of normally distributed random variables, so  it is also normally \\ndistributed as \\n \\n\\uf028\\n\\uf029\\n\\uf028\\n\\uf029\\n0\\n0\\n|\\n0\\n1\\n0\\n|\\nÀÜ\\nÀÜ\\n~\\n,\\ny x\\ny x\\nN\\nx PV\\n\\uf06d\\n\\uf062\\n\\uf062\\n\\uf06d\\n\\uf02b\\n. \\nSo if  \\n2\\n\\uf073 is known, then the distribution of \\n \\n0\\n0\\n|\\n0\\n|\\nÀÜ\\n( |\\n)\\nÀÜ\\n(\\n)\\ny x\\ny x\\nE y x\\nPV\\n\\uf06d\\n\\uf06d\\n\\uf02d\\n \\nis \\n(0,1).\\nN\\n  So  the 100(1-\\n)%\\n\\uf061\\n prediction interval is obtained as \\n0\\n0\\n|\\n0\\n/2\\n/2\\n|\\nÀÜ\\n( |\\n)\\n1\\nÀÜ\\n(\\n)\\ny x\\ny x\\nE y x\\nP\\nz\\nz\\nPV\\n\\uf061\\n\\uf061\\n\\uf06d\\n\\uf061\\n\\uf06d\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nwhich gives the prediction interval for \\n0\\n( /\\n)\\nE y x\\n as \\n0\\n0\\n2\\n2\\n2\\n2\\n0\\n0\\n|\\n/2\\n|\\n/2\\n(\\n)\\n(\\n)\\n1\\n1\\nÀÜ\\nÀÜ\\n,\\n.\\ny x\\ny x\\nxx\\nxx\\nx\\nx\\nx\\nx\\nz\\nz\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf06d\\n\\uf073\\n\\uf06d\\n\\uf073\\n\\uf0e9\\n\\uf0f9\\n\\uf0e9\\n\\uf0f9\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0eb\\n\\uf0fb\\n\\uf0eb\\n\\uf0fb\\n \\n \\nWhen  \\n2\\n\\uf073 is unknown, it is replaced by \\n2ÀÜ\\nMSE\\n\\uf073\\uf03d\\n and in this case the sampling distribution of  \\n \\n0\\n|\\n0\\n2\\n0\\nÀÜ\\n( |\\n)\\n(\\n)\\n1\\ny x\\nxx\\nE y x\\nx\\nx\\nMSE n\\ns\\n\\uf06d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nis t -distribution with (\\n2)\\nn \\uf02d\\n degrees of freedom, i.e., \\n2\\nnt \\uf02d. \\n \\nThe 100(1-\\uf061)% prediction interval in this  case is \\n \\n0\\n|\\n0\\n/2,\\n2\\n,\\n2\\n2\\n2\\n0\\nÀÜ\\n( |\\n)\\n1\\n.\\n(\\n)\\n1\\ny x\\nn\\nn\\nxx\\nE y x\\nP\\nt\\nt\\nx\\nx\\nMSE n\\ns\\n\\uf061\\n\\uf061\\n\\uf06d\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0eb\\n\\uf0fb\\n \\nwhich gives the prediction interval as \\n \\n0\\n0\\n2\\n2\\n0\\n0\\n|\\n/2,\\n2\\n|\\n/2,\\n2\\n(\\n)\\n(\\n)\\n1\\n1\\nÀÜ\\nÀÜ\\n,\\ny x\\nn\\ny x\\nn\\nxx\\nxx\\nx\\nx\\nx\\nx\\nt\\nMSE\\nt\\nMSE\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf06d\\n\\uf06d\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf02d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n.'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 27}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n28\\n28\\n28\\nNote that the width of the prediction interval  \\n0\\n( |\\n)\\nE y x\\n is a function of  \\n0x .  The interval width is minimum \\nfor  \\n0x\\nx\\n\\uf03d\\n and widens as \\n0x\\nx\\n\\uf02d\\n increases. This is also expected as the best estimates of  y  to be made at \\nx -values lie near the center of the data and the precision of estimation to deteriorate as we move to the \\nboundary of the x -space. \\n \\nCase 2: Prediction of actual value \\nIf  \\n0x  is the value of the explanatory variable, then the actual value predictor for y  is  \\n \\n0\\n0\\n1\\n0\\nÀÜy\\nb\\nb x\\n\\uf03d\\n\\uf02b\\n. \\nThe true value of y  in the prediction period is given by \\n0\\n0\\n1\\n0\\n0\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n where \\n0\\n\\uf065 indicates the value that \\nwould be drawn from the distribution of random error in the prediction period. Note that the form of \\npredictor is the same as of average value predictor, but its predictive error and other properties are different. \\nThis is the dual nature of predictor. \\n \\nPredictive bias:  \\nThe predictive error of  \\n0ÀÜy  is given by \\n \\n0\\n0\\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n0\\n0\\n1\\n1\\n0\\n0\\nÀÜ\\n(\\n)\\n(\\n)\\n(\\n)\\n.\\ny\\ny\\nb\\nb x\\nx\\nb\\nb\\nx\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n \\nThus, we find that \\n \\n0\\n0\\n0\\n0\\n1\\n1\\n0\\n0\\nÀÜ\\n(\\n)\\n(\\n)\\n(\\n)\\n(\\n)\\n0\\n0\\n0\\n0\\nE y\\ny\\nE b\\nE b\\nx\\nE\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n \\nwhich implies that \\n0ÀÜy  is an unbiased  predictor of  \\n0y . \\n \\n \\n \\n \\n \\n \\n \\nPredictive variance \\nBecause the future observation \\n0y  is independent of  \\n0ÀÜy , the predictive variance of  \\n0ÀÜy  is'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 28}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n29\\n29\\n29\\n2\\n0\\n0\\n0\\n2\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n0\\n2\\n2\\n0\\n0\\n1\\n1\\n0\\n0\\n0\\n1\\n0\\n1\\n0\\n1\\nÀÜ\\nÀÜ\\n(\\n)\\n(\\n)\\n  \\n[(\\n)\\n(\\n)(\\n)\\n(\\n)\\n]\\n  \\n(\\n)\\n(\\n)\\n( )\\n( )\\n(\\n)\\n2(\\n)\\n(\\n,\\n)\\n2\\n(\\n,\\n)\\n2(\\n)\\n( )   \\n  \\n  \\n  [rest of the terms are 0 assuming the indepe\\nPV y\\nE y\\ny\\nE b\\nx\\nx b\\nb\\nx\\nVar b\\nx\\nx Var b\\nx Var b\\nVar\\nx\\nx Cov b b\\nxCov b b\\nx\\nx Var b\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf065\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n0\\n1\\n2\\n2\\n2\\n0\\n0\\n0\\n1\\n0\\n0\\n1\\n2\\n0\\n0\\n1\\n0\\n0\\n0\\n1\\n2\\n2\\n2\\n2\\n2\\n2\\n0\\n0\\n2\\n2\\n0\\nndence of \\n with \\n,\\n,...,\\n]\\n  \\n(\\n)\\n[(\\n)\\n2(\\n)]\\n( )\\n( )\\n2[(\\n)\\n2 ]\\n(\\n,\\n)\\n  \\n(\\n)\\n( )\\n(\\n)\\n2\\n(\\n,\\n)\\n1\\n  \\n2\\n(\\n)\\n1\\n  \\n1\\nn\\nxx\\nxx\\nxx\\nVar b\\nx\\nx\\nx\\nx\\nx Var b\\nVar\\nx\\nx\\nx Cov b b\\nVar b\\nx Var b\\nVar\\nx Cov b b\\nx\\nx\\nx\\nx\\nn\\ns\\ns\\ns\\nx\\nx\\nn\\n\\uf065\\n\\uf065\\uf065\\n\\uf065\\n\\uf065\\n\\uf065\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0e9\\n\\uf0f9\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n.\\nxx\\ns\\n\\uf0e9\\n\\uf0f9\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nEstimate of predictive variance \\nThe estimate of predictive variance can be obtained by replacing \\n2\\n\\uf073 by its estimate \\n2ÀÜ\\nMSE\\n\\uf073\\uf03d\\n as \\n\\uf0b7\\n2\\n2\\n0\\n0\\n2\\n0\\n(\\n)\\n1\\nÀÜ\\nÀÜ\\n(\\n)\\n1\\n(\\n)\\n1\\n1\\n.\\nxx\\nxx\\nx\\nx\\nPV y\\nn\\ns\\nx\\nx\\nMSE\\nn\\ns\\n\\uf073\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nPrediction interval: \\nIf  \\n2\\n\\uf073 is known,  then the distribution of \\n \\n0\\n0\\n0\\nÀÜ\\nÀÜ\\n(\\n)\\ny\\ny\\nPV y\\n\\uf02d\\n \\nis \\n(0,1).\\nN\\n So  the 100(1-\\uf061)% prediction interval is obtained as  \\n \\n0\\n0\\n/2\\n/2\\n0\\nÀÜ\\n1\\nÀÜ\\n(\\n)\\ny\\ny\\nP\\nz\\nz\\nPV y\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nwhich gives the prediction interval for \\n0y  as \\n \\n2\\n2\\n2\\n2\\n0\\n0\\n0\\n/2\\n0\\n/2\\n(\\n)\\n(\\n)\\n1\\n1\\nÀÜ\\nÀÜ\\n1\\n,\\n1\\n.\\nxx\\nxx\\nx\\nx\\nx\\nx\\ny\\nz\\ny\\nz\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf073\\n\\uf073\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf02d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n \\n \\n \\nWhen  \\n2\\n\\uf073 is unknown, then'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 29}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n30\\n30\\n30\\n \\n\\uf0b6\\n0\\n0\\n0\\nÀÜ\\nÀÜ\\n(\\n)\\ny\\ny\\nPV y\\n\\uf02d\\n \\nfollows a t -distribution with (\\n2)\\nn \\uf02d\\n degrees of freedom. The 100(1-\\n)%\\n\\uf061\\n prediction interval for  \\n0ÀÜy  in this \\ncase is obtained as \\n \\n\\uf0b6\\n0\\n0\\n/2,\\n2\\n/2,\\n2\\n0\\nÀÜ\\n1\\nÀÜ\\n(\\n)\\nn\\nn\\ny\\ny\\nP\\nt\\nt\\nPV y\\n\\uf061\\n\\uf061\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf0a3\\n\\uf0a3\\n\\uf03d\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf0eb\\n\\uf0fb\\n \\nwhich gives the prediction interval \\n2\\n2\\n0\\n0\\n0\\n/2,\\n2\\n0\\n/2,\\n2\\n(\\n)\\n(\\n)\\n1\\n1\\nÀÜ\\nÀÜ\\n1\\n,\\n1\\nn\\nn\\nxx\\nxx\\nx\\nx\\nx\\nx\\ny\\nt\\nMSE\\ny\\nt\\nMSE\\nn\\ns\\nn\\ns\\n\\uf061\\n\\uf061\\n\\uf02d\\n\\uf02d\\n\\uf0e9\\n\\uf0f9\\n\\uf0e6\\n\\uf0f6\\n\\uf0e6\\n\\uf0f6\\n\\uf02d\\n\\uf02d\\n\\uf0ea\\n\\uf0fa\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf02b\\n\\uf0e7\\n\\uf0f7\\n\\uf0e7\\n\\uf0f7\\n\\uf0ea\\n\\uf0fa\\n\\uf0e8\\n\\uf0f8\\n\\uf0e8\\n\\uf0f8\\n\\uf0eb\\n\\uf0fb\\n. \\nThe prediction interval is of minimum width at \\n0x\\nx\\n\\uf03d\\n and widens as  \\n0x\\nx\\n\\uf02d\\n increases. \\n \\nThe prediction interval for  \\n0ÀÜy  is wider than the prediction interval for \\n0\\n/\\nÀÜ y x\\n\\uf06d\\n because the prediction interval \\nfor   \\n0ÀÜy   depends on both the error from the fitted model as well as the error associated with the future \\nobservations. \\n \\nReverse regression method  \\nThe reverse (or inverse) regression approach minimizes the sum of squares of horizontal distances between \\nthe observed data points and the line in the following scatter diagram to obtain the estimates of regression \\nparameters. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n(Xi, \\n)\\n(xi, \\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\nyi \\nx,\\n    Reverse regression'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 30}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n31\\n31\\n31\\nThe reverse regression has been advocated in the analysis of gender (or race) discrimination in salaries. For \\nexample, if y denotes salary and x denotes qualifications, and we are interested in determining if there is \\ngender discrimination in salaries, we can ask: \\n‚ÄúWhether men and women with the same qualifications (value of x) are getting the same salaries \\n(value of y). This question is answered by the direct regression.‚Äù \\n \\nAlternatively, we can ask: \\n‚ÄúWhether men and women with the same salaries (value of y) have the same qualifications (value of \\nx). This question is answered by the reverse regression, i.e., regression of x on y.‚Äù \\n \\nThe regression equation in case of reverse regression can be written as  \\n*\\n*\\n0\\n1\\n   (\\n1,2,..., )\\ni\\ni\\ni\\nx\\ny\\ni\\nn\\n\\uf062\\n\\uf062\\n\\uf064\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n \\nwhere \\ni\\uf064‚Äôs are the associated random error components and satisfy the assumptions as in the case of the \\nusual simple linear regression model.  The reverse regression estimates  \\n0\\n1\\n*\\n*\\n1\\nÀÜ\\nÀÜ\\nof\\nand\\nof\\nOR\\nR\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062 for the \\nmodel are obtained by interchanging the x and  y in the direct regression estimators of \\n0\\n1\\nand\\n\\uf062\\n\\uf062. The \\nestimates are obtained as  \\n \\n1\\nÀÜ\\nÀÜ\\nOR\\nR\\nx\\ny\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n \\nand \\n \\n \\n1ÀÜ\\nyy\\nR\\nxy\\ns\\ns\\n\\uf062\\n\\uf03d\\n \\nfor \\n0\\n1\\nand\\n\\uf062\\n\\uf062 respectively.  The residual sum of squares in this case is \\n2\\n*\\n.\\nres\\nxy\\nxx\\nyy\\ns\\nSS\\ns\\ns\\n\\uf03d\\n\\uf02d\\n \\nNote that  \\n2\\n2\\n1\\n1\\nÀÜ\\nxy\\nR\\nxy\\nxx\\nyy\\ns\\nb\\nr\\ns s\\n\\uf062\\n\\uf03d\\n\\uf03d\\n \\nwhere \\n1b is the direct regression estimator of the slope parameter and \\nxy\\nr  is the correlation coefficient \\nbetween x and y. Hence if \\n2\\nxy\\nr  is close to 1, the two regression lines will be close to each other.  \\n \\nAn important application of the reverse regression method is in solving the calibration problem.'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 31}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n32\\n32\\n32\\nOrthogonal regression method (or major axis regression method)  \\nThe direct and reverse regression methods of estimation assume that the errors in the observations are either \\nin x -direction or y -direction. In other words, the errors can be either in the dependent variable or \\nindependent variable. There can be situations when uncertainties are involved in dependent and independent \\nvariables both. In such situations, the orthogonal regression is more appropriate. In order to take care of \\nerrors in both the directions, the least-squares principle in orthogonal regression minimizes the squared \\nperpendicular distance between the observed data points and the line in the following scatter diagram to \\nobtain the estimates of regression coefficients. This is also known as the major axis regression method. \\nThe estimates obtained are called orthogonal regression estimates or major axis regression estimates of \\nregression coefficients. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we assume that the regression line to be fitted is \\n0\\n1\\ni\\ni\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n, then it is expected that all the observations \\n( ,\\n),\\n1,2,...,\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n lie on this line.  But these points deviate from the line, and in such a case, the  squared \\nperpendicular distance of observed data ( ,\\n)  (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n from the line is given by  \\n \\n2\\n2\\n2\\n(\\n)\\n(\\n)\\ni\\ni\\ni\\ni\\ni\\nd\\nX\\nx\\nY\\ny\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n \\nwhere  (\\n,\\n)\\ni\\ni\\nX Y  denotes the thi  pair of observation without any error which lies on the line. \\n \\n(xi, yi)\\n(Xi, Yi)\\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\nyi \\nxi\\n    Orthogonal or major axis regression'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 32}, page_content=\"Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n33\\n33\\n33\\nThe objective is to minimize the sum of squared perpendicular distances given by \\n2\\n1\\nn\\ni\\ni\\nd\\n\\uf03d\\uf0e5\\n to obtain the \\nestimates of  \\n0\\n\\uf062 and  \\n1\\n\\uf062. The observations   ( ,\\n)  (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n are expected to lie on the line \\n \\n0\\n1\\ni\\ni\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n, \\nso let \\n \\n0\\n1\\n0.\\ni\\ni\\ni\\nE\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n \\nThe regression coefficients are obtained by minimizing  \\n2\\n1\\nn\\ni\\ni\\nd\\n\\uf03d\\uf0e5\\n under the constraints \\n'\\niE s  using the \\nLagrangian‚Äôs multiplier method. The  Lagrangian function is \\n \\n2\\n0\\n1\\n1\\n2\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\nL\\nd\\nE\\n\\uf06c\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n \\nwhere \\n1,...,\\nn\\n\\uf06c\\n\\uf06c are the Lagrangian multipliers.  The set of equations  are obtained by setting \\n \\n0\\n0\\n0\\n0\\n0\\n1\\n0,\\n0,\\n0 and\\n0 (\\n1,2,..., ).\\ni\\ni\\nL\\nL\\nL\\nL\\ni\\nn\\nX\\nY\\n\\uf062\\n\\uf062\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n \\nThus we find \\n \\n0\\n1\\n0\\n0\\n1\\n0\\n0\\n1\\n1\\n(\\n)\\n0\\n(\\n)\\n0\\n0\\n0.\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\nn\\ni\\ni\\ni\\nL\\nX\\nx\\nX\\nL\\nY\\ny\\nY\\nL\\nL\\nX\\n\\uf06c\\uf062\\n\\uf06c\\n\\uf06c\\n\\uf062\\n\\uf06c\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0e5\\n\\uf0e5\\n \\nSince \\n \\n1\\n,\\ni\\ni\\ni\\ni\\ni\\ni\\nX\\nx\\nY\\ny\\n\\uf06c\\uf062\\n\\uf06c\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n \\nso substituting these values is \\niE , we obtain \\n \\n0\\n1\\n1\\n0\\n1\\n2\\n1\\n    \\n(\\n)\\n(\\n)\\n0\\n.\\n1\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nE\\ny\\nx\\nx\\ny\\n\\uf06c\\n\\uf062\\n\\uf062\\n\\uf06c\\uf062\\n\\uf062\\n\\uf062\\n\\uf06c\\n\\uf062\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf0de\\n\\uf03d\\n\\uf02b\"),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 33}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n34\\n34\\n34\\nAlso using this \\ni\\uf06c in the equation \\n1\\n0\\nn\\ni\\ni\\n\\uf06c\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n, we get \\n0\\n1\\n1\\n2\\n1\\n(\\n)\\n0\\n1\\nn\\ni\\ni\\ni\\nx\\ny\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf0e5\\n \\nand  using \\n1\\n1\\n(\\n)\\n0 and\\n0\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\nX\\nx\\nX\\n\\uf06c\\uf062\\n\\uf06c\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n,  we get \\n \\n1\\n1\\n(\\n)\\n0.\\nn\\ni\\ni\\ni\\ni\\nx\\n\\uf06c\\n\\uf06c\\uf062\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n \\nSubstituting \\ni\\uf06c in this equation, we get  \\n \\n2\\n2\\n0\\n1\\n1\\n1\\n0\\n1\\n2\\n2\\n2\\n1\\n(\\n)\\n(\\n)\\n0.                     (1)\\n(1\\n)\\n(1\\n)\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nx\\nx\\ny x\\nx\\ny\\n\\uf062\\n\\uf062\\n\\uf062\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf0e5\\n \\nUsing \\ni\\uf06c in the equation  and using  the equation \\n1\\n0\\nn\\ni\\ni\\n\\uf06c\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n, we solve \\n0\\n1\\n1\\n2\\n1\\n(\\n)\\n0.\\n1\\nn\\ni\\ni\\ni\\nx\\ny\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf0e5\\n   \\n The solution provides  an orthogonal regression estimate of  \\n0\\n\\uf062 as \\n \\n0\\n1\\nÀÜ\\nÀÜ\\nOR\\nOR\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n \\nwhere  \\n1ÀÜ\\nOR\\n\\uf062\\n  is an orthogonal regression estimate of  \\n1.\\n\\uf062 \\nNow, substituting \\n0OR\\n\\uf062\\n in equation (1),  we get \\n\\uf028\\n\\uf029\\n\\uf05b\\n\\uf05d\\n\\uf05b\\n\\uf05d\\n2\\n2\\n2\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n2\\n2\\n1\\n1\\n1\\n1\\n1\\n1\\n2\\n2\\n1\\n1\\n1\\n1\\n1\\n             \\n(1\\n)\\n0\\nor\\n             (1\\n)\\n(\\n)\\n(\\n)\\n(\\n)\\n0\\nor\\n             (1\\n)\\n(\\n)(\\n)\\n(\\n)\\n0\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\nyx\\nxx\\nx\\nx y\\ny\\nx\\nx\\ny\\nx\\ny\\ny\\nx\\nx\\ny\\ny\\nx\\nx\\nu\\nx v\\nu\\nv\\nu\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e9\\n\\uf0f9\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf0eb\\n\\uf0fb\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n1\\nwhere\\n             \\n,\\n             \\n.\\nn\\ni\\ni\\ni\\ni\\ni\\nu\\nx\\nx\\nv\\ny\\ny\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf0e5'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 34}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n35\\n35\\n35\\n1\\n1\\n2\\n2\\n2\\n1\\n1\\n1\\n2\\n1\\n1\\nSince  \\n0, so \\n             \\n(\\n)\\n0\\nor\\n             \\n(\\n)\\n0.\\nn\\nn\\ni\\ni\\ni\\ni\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nxy\\nxx\\nyy\\nxy\\nu\\nu\\nu v\\nu\\nv\\nu v\\ns\\ns\\ns\\ns\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e9\\n\\uf0f9\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0eb\\n\\uf0fb\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nSolving this  quadratic equation provides  the orthogonal regression estimate of  \\n1\\n\\uf062 as \\n\\uf028\\n\\uf029\\n\\uf028\\n\\uf029\\n2\\n2\\n1\\n(\\n)\\n4\\nÀÜ\\n2\\nxy\\nyy\\nxx\\nxy\\nxx\\nyy\\nOR\\nxy\\ns\\ns\\nsign s\\ns\\ns\\ns\\ns\\n\\uf062\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n \\nwhere  \\n(\\n)\\nxy\\nsign s\\n denotes the sign of  \\nxy\\ns  which can be positive or negative. So  \\n1    if\\n0\\n(\\n)\\n1 if\\n0.\\nxy\\nxy\\nxy\\ns\\nsign s\\ns\\n\\uf03e\\n\\uf0ec\\uf0ef\\n\\uf03d\\uf0ed\\uf02d\\n\\uf03c\\n\\uf0ef\\uf0ee\\n.   \\nNotice that this gives two solutions for   \\n1ÀÜ\\nOR\\n\\uf062\\n. We choose the solution which minimizes \\n2\\n1\\nn\\ni\\ni\\nd\\n\\uf03d\\uf0e5\\n. The other \\nsolution maximizes \\n2\\n1\\nn\\ni\\ni\\nd\\n\\uf03d\\uf0e5\\n  and is in the direction perpendicular to the optimal solution. The optimal solution \\ncan be chosen with the sign of  \\nxy\\ns .'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 35}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n36\\n36\\n36\\nReduced major axis regression method: \\nThe direct, reverse and orthogonal methods of estimation minimize the errors in a particular direction which \\nis usually the distance between the observed data points and the line in the scatter diagram. Alternatively, \\none can consider the area extended by the data points in a certain neighbourhood and instead of distances, the \\narea of rectangles defined between the corresponding  observed data point and the nearest point on the line in \\nthe following scatter diagram can also be minimized. Such an approach is more appropriate when the \\nuncertainties are present in the study and explanatory variables both. This approach is termed as reduced \\nmajor axis regression. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSuppose the regression line is \\n0\\n1\\ni\\ni\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n on which all the observed points are expected to lie. Suppose \\nthe points ( ,\\n),\\n1,2,...,\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n are observed which lie away from the line. The area of rectangle extended \\nbetween the  thi  observed data point and the line  is \\n \\n(\\n~\\n)(\\n~\\n) (\\n1,2,..., )\\ni\\ni\\ni\\ni\\ni\\nA\\nX\\nx\\nY\\ny\\ni\\nn\\n\\uf03d\\n\\uf03d\\n \\nwhere  (\\n,\\n)\\ni\\ni\\nX Y  denotes the thi  pair of observation without any error which lies on the line. \\n \\nThe total area extended by n  data points is  \\n \\n1\\n1\\n(\\n~\\n)(\\n~\\n).\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nA\\nX\\nx\\nY\\ny\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n \\n \\n \\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\n(xi  yi)\\n(Xi, Yi)\\nyi \\nxi\\nReduced major axis method'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 36}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n37\\n37\\n37\\nAll observed data points ( ,\\n), (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\nare expected to lie on the line \\n \\n0\\n1\\ni\\ni\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\nand let \\n \\n*\\n0\\n1\\n0.\\ni\\ni\\ni\\nE\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n \\n \\nSo now the objective is to minimize the sum of areas under the constraints  \\n*\\niE  to obtain the reduced major \\naxis estimates of regression coefficients. Using the Lagrangian multiplier method, the Lagrangian function is \\n \\n*\\n1\\n1\\n*\\n1\\n1\\n(\\n)(\\n)\\nn\\nn\\nR\\ni\\ni\\ni\\ni\\ni\\nn\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nL\\nA\\nE\\nX\\nx\\nY\\ny\\nE\\n\\uf06d\\n\\uf06d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n \\nwhere \\n1,...,\\nn\\n\\uf06d\\n\\uf06d are the Lagrangian multipliers.  The set of equations are obtained by setting \\n0\\n1\\n0,\\n0,\\n0,\\n0\\n(\\n1,2,..., ).\\nR\\nR\\nR\\nR\\ni\\ni\\nL\\nL\\nL\\nL\\ni\\nn\\nX\\nY\\n\\uf062\\n\\uf062\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n \\n \\nThus \\n \\n1\\n1\\n0\\n1\\n1\\n(\\n)\\n0\\n(\\n)\\n0\\n0\\n0.\\nR\\ni\\ni\\ni\\ni\\nR\\ni\\ni\\ni\\ni\\nn\\nR\\ni\\ni\\nn\\nR\\ni\\ni\\ni\\nL\\nY\\ny\\nX\\nL\\nX\\nx\\nY\\nL\\nL\\nX\\n\\uf062\\uf06d\\n\\uf06d\\n\\uf06d\\n\\uf062\\n\\uf06d\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0b6\\n\\uf03d\\n\\uf03d\\n\\uf0b6\\n\\uf0e5\\n\\uf0e5\\n \\n \\nNow \\n \\n1\\n0\\n1\\n1\\n0\\n1\\n1\\n0\\n1\\n1\\n     \\n     \\n     \\n     \\n(\\n)\\n.\\n2\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\ni\\nX\\nx\\nY\\ny\\nX\\ny\\nx\\ny\\ny\\nx\\n\\uf06d\\n\\uf062\\uf06d\\n\\uf062\\n\\uf062\\n\\uf062\\uf06d\\n\\uf062\\n\\uf062\\n\\uf06d\\n\\uf062\\uf06d\\n\\uf062\\n\\uf062\\n\\uf06d\\n\\uf062\\n\\uf03d\\n\\uf02b\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf02d\\n\\uf0de\\n\\uf03d'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 37}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n38\\n38\\n38\\nSubstituting  \\ni\\uf06d in \\n1\\n0\\nn\\ni\\ni\\n\\uf06d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n,  the reduced major axis regression estimate of  \\n0\\n\\uf062 is obtained as\\n \\n0\\n1\\nÀÜ\\nÀÜ\\nRM\\nRM\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n \\nwhere \\n1ÀÜ\\nRM\\n\\uf062\\n is the reduced major axis regression estimate of  \\n1\\n\\uf062.  Using \\n,\\ni\\ni\\ni\\ni\\nX\\nx\\n\\uf06d\\n\\uf06d\\n\\uf03d\\n\\uf02b\\n and  \\n0ÀÜ\\nRM\\n\\uf062\\n in \\n1\\n0\\nn\\ni\\ni\\ni\\nX\\n\\uf06d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n, we get \\n \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0.\\n2\\n2\\nn\\ni\\ni\\ni\\ni\\ni\\ni\\ny\\ny\\nx\\nx\\ny\\ny\\nx\\nx\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf0e6\\n\\uf0f6\\uf0e6\\n\\uf0f6\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf02b\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf0e7\\n\\uf0f7\\uf0e7\\n\\uf0f7\\n\\uf0e8\\n\\uf0f8\\uf0e8\\n\\uf0f8\\n\\uf0e5\\n \\nLet  \\nand\\n,\\ni\\ni\\ni\\ni\\nu\\nx\\nx\\nv\\ny\\ny\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n  then this equation can be re-expressed as \\n \\n1\\n1\\n1\\n1\\n(\\n)(\\n2\\n)\\n0.\\nn\\ni\\ni\\ni\\ni\\ni\\nv\\nu\\nv\\nu\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n\\uf0e5\\n \\nUsing  \\n1\\n1\\n0,\\nn\\nn\\ni\\ni\\ni\\ni\\nu\\nu\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n we get \\n \\n2\\n2\\n2\\n1\\n1\\n1\\n0.\\nn\\nn\\ni\\ni\\ni\\ni\\nv\\nu\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n \\nSolving this equation,  the reduced major axis regression estimate of  \\n1\\n\\uf062 is obtained as \\n \\n1ÀÜ\\n(\\n)\\nyy\\nRM\\nxy\\nxx\\ns\\nsign s\\ns\\n\\uf062\\n\\uf03d\\n \\nwhere \\n1\\nif\\n0\\n(\\n)\\n1 if\\n0.\\nxy\\nxy\\nxy\\ns\\nsign s\\ns\\n\\uf03e\\n\\uf0ec\\uf0ef\\n\\uf03d\\uf0ed\\uf02d\\n\\uf03c\\n\\uf0ef\\uf0ee\\n \\nWe choose the regression estimator which has same sign as of  \\nxy\\ns . \\n \\nLeast absolute deviation regression method \\nThe least-squares principle advocates the minimization of the sum of squared errors. The idea of squaring the \\nerrors is useful in place of simple errors because random errors can be positive as well as negative. So \\nconsequently their sum can be close to zero indicating that there is no error in the model and which can be \\nmisleading.  Instead of the sum of random errors, the sum of absolute random errors can be considered which \\navoids the problem due to positive and negative random errors.'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 38}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n39\\n39\\n39\\nIn the method of least squares, the estimates of the parameters \\n0\\n\\uf062 and  \\n1\\n\\uf062 in the model \\n0\\n1\\n. (\\n1,2,..., )\\ni\\ni\\ni\\ny\\nx\\ni\\nn\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n\\uf03d\\n are chosen such that the sum of squares of deviations \\n2\\n1\\nn\\ni\\ni\\n\\uf065\\n\\uf03d\\uf0e5\\n is minimum. In \\nthe method of least absolute deviation (LAD)  regression, the parameters \\n0\\n\\uf062 and \\n1\\n\\uf062 are estimated such that \\nthe sum of absolute deviations \\n1\\nn\\ni\\ni\\n\\uf065\\n\\uf03d\\uf0e5\\n is minimum. It minimizes the absolute vertical sum of errors as in the \\nfollowing scatter diagram: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe LAD estimates  \\n0ÀÜ\\nL\\n\\uf062\\n and  \\n1ÀÜ\\nL\\n\\uf062  are the estimates of \\n0\\n\\uf062 and \\n1\\n\\uf062, respectively which minimize \\n \\n0\\n1\\n0\\n1\\n1\\n(\\n,\\n)\\nn\\ni\\ni\\ni\\nLAD\\ny\\nx\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf0e5\\n \\nfor  the given observations ( ,\\n)(\\n1,2,..., ).\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n \\n \\nConceptually, LAD procedure is more straightforward than OLS procedure because e  (absolute residuals) \\nis a more straightforward measure of the size of the residual than \\n2e  (squared residuals).  The LAD  \\nregression estimates of  \\n0\\n\\uf062 and \\n1\\n\\uf062  are not available in closed form. Instead, they can be obtained \\nnumerically based on algorithms. Moreover, this creates the problems of non-uniqueness and degeneracy in \\nthe estimates. The concept of non-uniqueness relates to that more than one best line pass through a data \\npoint. The degeneracy concept describes that the best line through a data point also passes through more than \\none other data points.  The non-uniqueness and degeneracy concepts are used in algorithms to judge the \\n0\\n1\\nY\\nX\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf02b\\n \\n(xi, yi)\\n(Xi, Yi)\\nyi \\nxi\\nLeast absolute deviation regression'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 39}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n40\\n40\\n40\\nquality of the estimates. The algorithm for finding the estimators generally proceeds in steps. At each step, \\nthe best line is found that passes through a given data point.  The best line always passes through another \\ndata point, and this data point is used in the next step. When there is non-uniqueness,  then there is more than \\none best line.  When there is degeneracy, then the best line passes through more than one other data point. \\nWhen either of the problems is present, then there is more than one choice for the data point to be used in the \\nnext step and the algorithm may go around in circles or make a  wrong choice of the LAD regression line.  \\nThe exact tests of hypothesis and confidence intervals for the LAD regression estimates can not be derived \\nanalytically.  Instead, they are derived analogously to the tests of hypothesis and confidence intervals related \\nto ordinary least squares estimates.  \\n \\nEstimation of parameters when X  is stochastic    \\nIn a usual linear regression model, the study variable is supped to be random and explanatory variables are \\nassumed to be fixed. In practice, there may be situations in which the explanatory variable also becomes \\nrandom. \\n \\nSuppose both dependent and independent variables are stochastic in the simple linear regression model \\n \\n0\\n1\\ny\\nX\\n\\uf062\\n\\uf062\\n\\uf065\\n\\uf03d\\n\\uf02b\\n\\uf02b\\n \\nwhere \\uf065 is the associated random error component.  The observations ( ,\\n),\\n1,2,...,\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n are assumed to be \\njointly distributed. Then the statistical inferences can be drawn in such cases which are conditional on  X . \\n \\nAssume the joint distribution of  X  and  y  to be bivariate normal \\n2\\n2\\n(\\n,\\n,\\n,\\n,\\n)\\nx\\ny\\nx\\ny\\nN \\uf06d\\n\\uf06d\\uf073\\n\\uf073\\n\\uf072 where \\nx\\n\\uf06d and  \\ny\\n\\uf06d \\nare the means of X  and  \\n2\\n;\\nx\\ny \\uf073 and  \\n2\\ny\\n\\uf073 are the variances of  X  and ;y  and   \\uf072 is the correlation coefficient \\nbetween X  and  y .  Then the conditional distribution of  y  given X\\nx\\n\\uf03d\\n is the univariate normal \\nconditional mean \\n \\n|\\n0\\n1\\n( |\\n)\\ny x\\nE y X\\nx\\nx\\n\\uf06d\\n\\uf062\\n\\uf062\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02b\\n \\nand the conditional variance of y given X\\nx\\n\\uf03d\\n is \\n \\n2\\n2\\n2\\n|\\n( |\\n)\\n(1\\n)\\ny x\\ny\\nVar y X\\nx\\n\\uf073\\n\\uf073\\n\\uf072\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n \\nwhere \\n \\n0\\n1\\ny\\nx\\n\\uf062\\n\\uf06d\\n\\uf06d\\uf062\\n\\uf03d\\n\\uf02d\\n \\nand \\n \\n1\\n.\\ny\\nx\\n\\uf073\\n\\uf062\\n\\uf072\\n\\uf073\\n\\uf03d'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 10.0.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2023-01-22T12:57:20+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'total_pages': 41, 'format': 'PDF 1.5', 'title': 'Microsoft Word - Chapter2-Regression-SimpleLinearRegressionAnalysis', 'author': 'shala', 'subject': '', 'keywords': '', 'moddate': '2023-01-22T12:57:20+05:30', 'trapped': '', 'modDate': \"D:20230122125720+05'30'\", 'creationDate': \"D:20230122125720+05'30'\", 'page': 40}, page_content='Regression Analysis    |  Chapter 2  |  Simple Linear Regression Analysis  |  Shalabh, IIT Kanpur \\n \\n41\\n41\\n41\\nWhen both X  and  y  are stochastic, then the problem of estimation of parameters can be reformulated as \\nfollows. Consider a conditional random variable \\n|\\ny X\\nx\\n\\uf03d\\n having a normal distribution with mean as \\nconditional mean \\n|y x\\n\\uf06d\\n and variance as conditional variance \\n2\\n|\\n( |\\n)\\ny x\\nVar y X\\nx\\n\\uf073\\n\\uf03d\\n\\uf03d\\n. Obtain n  independently \\ndistributed observation \\n|\\n,\\n1,2,...,\\ni\\ni\\ny\\nx i\\nn\\n\\uf03d\\n from \\n2\\n|\\n|\\n(\\n,\\n)\\ny x\\ny x\\nN \\uf06d\\n\\uf073\\n with nonstochastic X . Now the  method of \\nmaximum  likelihood can be used to estimate the parameters which yield the estimates of  \\n0\\n\\uf062 and \\n1\\n\\uf062 as \\nearlier in the case of nonstochastic X  as \\n \\n1\\nb\\ny\\nb x\\n\\uf03d\\n\\uf02d\\n\\uf025\\n\\uf025\\n \\nand \\n \\n1\\nxy\\nxx\\ns\\nb\\ns\\n\\uf03d\\n\\uf025\\n,  \\nrespectively. \\nMoreover, the correlation coefficient \\n \\n(\\n)(\\n)\\ny\\nx\\ny\\nx\\nE y\\nX\\n\\uf06d\\n\\uf06d\\n\\uf072\\n\\uf073\\uf073\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n \\ncan be estimated by the sample correlation coefficient \\n \\n1\\n2\\n2\\n1\\n1\\n1\\n(\\n)(\\n)\\nÀÜ\\n(\\n)\\n(\\n)\\n.\\nn\\ni\\ni\\ni\\nn\\nn\\ni\\ni\\ni\\ni\\nxy\\nxx\\nyy\\nxx\\nyy\\ny\\ny\\nx\\nx\\nx\\nx\\ny\\ny\\ns\\ns\\ns\\ns\\nb\\ns\\n\\uf072\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf02d\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf025\\n \\nThus  \\n2\\n2\\n1\\n1\\n2\\n1\\n2\\nÀÜ\\nÀÜ\\nxx\\nyy\\nxy\\nyy\\nn\\nyy\\ni\\ni\\nyy\\ns\\nb s\\ns\\nb s\\ns\\ns\\nR\\n\\uf072\\n\\uf065\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf02d\\n\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf025\\n\\uf025\\n \\nwhich is same as the coefficient of determination.  Thus  \\n2\\nR  has the same expression as in the case when  X  \\nis fixed.  Thus  \\n2\\nR  again measures the goodness of the fitted model even when  X  is stochastic.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 0}, page_content='Chapter 12\\nLogistic Regression\\n12.1\\nModeling Conditional Probabilities\\nSo far, we either looked at estimating the conditional expectations of continuous\\nvariables (as in regression), or at estimating distributions. There are many situations\\nwhere however we are interested in input-output relationships, as in regression, but\\nthe output variable is discrete rather than continuous. In particular there are many\\nsituations where we have binary outcomes (it snows in Pittsburgh on a given day, or\\nit doesn‚Äôt; this squirrel carries plague, or it doesn‚Äôt; this loan will be paid back, or\\nit won‚Äôt; this person will get heart disease in the next Ô¨Åve years, or they won‚Äôt). In\\naddition to the binary outcome, we have some input variables, which may or may\\nnot be continuous. How could we model and analyze such data?\\nWe could try to come up with a rule which guesses the binary output from the\\ninput variables. This is called classiÔ¨Åcation, and is an important topic in statistics\\nand machine learning. However, simply guessing ‚Äúyes‚Äù or ‚Äúno‚Äù is pretty crude ‚Äî\\nespecially if there is no perfect rule. (Why should there be?) Something which takes\\nnoise into account, and doesn‚Äôt just give a binary answer, will often be useful. In\\nshort, we want probabilities ‚Äî which means we need to Ô¨Åt a stochastic model.\\nWhat would be nice, in fact, would be to have conditional distribution of the\\nresponse Y , given the input variables, Pr(Y |X). This would tell us about how pre-\\ncise our predictions are. If our model says that there‚Äôs a 51% chance of snow and it\\ndoesn‚Äôt snow, that‚Äôs better than if it had said there was a 99% chance of snow (though\\neven a 99% chance is not a sure thing). We have seen how to estimate conditional\\nprobabilities non-parametrically, and could do this using the kernels for discrete vari-\\nables from lecture 6. While there are a lot of merits to this approach, it does involve\\ncoming up with a model for the joint distribution of outputs Y and inputs X, which\\ncan be quite time-consuming.\\nLet‚Äôs pick one of the classes and call it ‚Äú1‚Äù and the other ‚Äú0‚Äù. (It doesn‚Äôt mat-\\nter which is which. Then Y becomes an indicator variable, and you can convince\\nyourself that Pr(Y = 1) = E[Y ]. Similarly, Pr(Y = 1|X = x) = E[Y |X = x]. (In\\na phrase, ‚Äúconditional probability is the conditional expectation of the indicator‚Äù.)\\n223'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 1}, page_content='224\\nCHAPTER 12. LOGISTIC REGRESSION\\nThis helps us because by this point we know all about estimating conditional ex-\\npectations. The most straightforward thing for us to do at this point would be to\\npick out our favorite smoother and estimate the regression function for the indicator\\nvariable; this will be an estimate of the conditional probability function.\\nThere are two reasons not to just plunge ahead with that idea. One is that proba-\\nbilities must be between 0 and 1, but our smoothers will not necessarily respect that,\\neven if all the observed yi they get are either 0 or 1. The other is that we might be\\nbetter off making more use of the fact that we are trying to estimate probabilities, by\\nmore explicitly modeling the probability.\\nAssume that Pr(Y = 1|X = x) = p(x;Œ∏), for some function p parameterized by\\nŒ∏. parameterized function Œ∏, and further assume that observations are independent\\nof each other. The the (conditional) likelihood function is\\nn\\n\\uffff\\ni=1\\nPr\\uffffY = yi|X = xi\\n\\uffff=\\nn\\n\\uffff\\ni=1\\np(xi;Œ∏)yi (1 ‚àíp(xi;Œ∏)1‚àíyi )\\n(12.1)\\nRecall that in a sequence of Bernoulli trials y1,...yn, where there is a constant\\nprobability of success p, the likelihood is\\nn\\n\\uffff\\ni=1\\npyi (1 ‚àíp)1‚àíyi\\n(12.2)\\nAs you learned in intro. stats, this likelihood is maximized when p = ÀÜp = n‚àí1 \\uffffn\\ni=1 yi.\\nIf each trial had its own success probability pi, this likelihood becomes\\nn\\n\\uffff\\ni=1\\npyi\\ni (1 ‚àípi)1‚àíyi\\n(12.3)\\nWithout some constraints, estimating the ‚Äúinhomogeneous Bernoulli‚Äù model by max-\\nimum likelihood doesn‚Äôt work; we‚Äôd get ÀÜpi = 1 when yi = 1, ÀÜpi = 0 when yi = 0, and\\nlearn nothing. If on the other hand we assume that the pi aren‚Äôt just arbitrary num-\\nbers but are linked together, those constraints give non-trivial parameter estimates,\\nand let us generalize. In the kind of model we are talking about, the constraint,\\npi = p(xi;Œ∏), tells us that pi must be the same whenever xi is the same, and if p is a\\ncontinuous function, then similar values of xi must lead to similar values of pi. As-\\nsuming p is known (up to parameters), the likelihood is a function of Œ∏, and we can\\nestimate Œ∏ by maximizing the likelihood. This lecture will be about this approach.\\n12.2\\nLogistic Regression\\nTo sum up: we have a binary output variable Y , and we want to model the condi-\\ntional probability Pr(Y = 1|X = x) as a function of x; any unknown parameters in\\nthe function are to be estimated by maximum likelihood. By now, it will not surprise\\nyou to learn that statisticians have approach this problem by asking themselves ‚Äúhow\\ncan we use linear regression to solve this?‚Äù'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 2}, page_content='12.2. LOGISTIC REGRESSION\\n225\\n1. The most obvious idea is to let p(x) be a linear function of x. Every increment\\nof a component of x would add or subtract so much to the probability. The\\nconceptual problem here is that p must be between 0 and 1, and linear func-\\ntions are unbounded. Moreover, in many situations we empirically see ‚Äúdimin-\\nishing returns‚Äù ‚Äî changing p by the same amount requires a bigger change in\\nx when p is already large (or small) than when p is close to 1/2. Linear models\\ncan‚Äôt do this.\\n2. The next most obvious idea is to let log p(x) be a linear function of x, so that\\nchanging an input variable multiplies the probability by a Ô¨Åxed amount. The\\nproblem is that logarithms are unbounded in only one direction, and linear\\nfunctions are not.\\n3. Finally, the easiest modiÔ¨Åcation of log p which has an unbounded range is the\\nlogistic (or logit) transformation, log\\np\\n1‚àíp . We can make this a linear func-\\ntion of x without fear of nonsensical results. (Of course the results could still\\nhappen to be wrong, but they‚Äôre not guaranteed to be wrong.)\\nThis last alternative is logistic regression.\\nFormally, the model logistic regression model is that\\nlog\\np(x)\\n1 ‚àíp(x) = Œ≤0 + x ¬∑ Œ≤\\n(12.4)\\nSolving for p, this gives\\np(x; b,w) =\\neŒ≤0+x¬∑Œ≤\\n1 + eŒ≤0+x¬∑Œ≤ =\\n1\\n1 + e‚àí(Œ≤0+x¬∑Œ≤)\\n(12.5)\\nNotice that the over-all speciÔ¨Åcation is a lot easier to grasp in terms of the transformed\\nprobability that in terms of the untransformed probability.1\\nTo minimize the mis-classiÔ¨Åcation rate, we should predict Y = 1 when p ‚â•0.5\\nand Y = 0 when p < 0.5. This means guessing 1 whenever Œ≤0 + x ¬∑Œ≤ is non-negative,\\nand 0 otherwise. So logistic regression gives us a linear classiÔ¨Åer. The decision\\nboundary separating the two predicted classes is the solution of Œ≤0 + x ¬∑ Œ≤ = 0,\\nwhich is a point if x is one dimensional, a line if it is two dimensional, etc. One can\\nshow (exercise!) that the distance from the decision boundary is Œ≤0/\\uffffŒ≤\\uffff+x¬∑Œ≤/\\uffffŒ≤\\uffff.\\nLogistic regression not only says where the boundary between the classes is, but also\\nsays (via Eq. 12.5) that the class probabilities depend on distance from the boundary,\\nin a particular way, and that they go towards the extremes (0 and 1) more rapidly\\nwhen \\uffffŒ≤\\uffffis larger. It‚Äôs these statements about probabilities which make logistic\\nregression more than just a classiÔ¨Åer. It makes stronger, more detailed predictions,\\nand can be Ô¨Åt in a different way; but those strong predictions could be wrong.\\nUsing logistic regression to predict class probabilities is a modeling choice, just\\nlike it‚Äôs a modeling choice to predict quantitative variables with linear regression.\\n1Unless you‚Äôve taken statistical mechanics, in which case you recognize that this is the Boltzmann\\ndistribution for a system with two states, which differ in energy by Œ≤0 + x ¬∑ Œ≤.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 3}, page_content='226\\nCHAPTER 12. LOGISTIC REGRESSION\\n-\\n+\\n-\\n+ +\\n+\\n-\\n+\\n-\\n+\\n+\\n+\\n+\\n-\\n-\\n-\\n-\\n+\\n+\\n-\\n+\\n+\\n+\\n-\\n+\\n-\\n+\\n+\\n-\\n-\\n+\\n+\\n-\\n+\\n+\\n-\\n-\\n+\\n+\\n-\\n+\\n+\\n-\\n+\\n-\\n+\\n-\\n+\\n-\\n+\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\nLogistic regression with b=-0.1, w=(-.2,.2)\\nx[,1]\\nx[,2]\\n-\\n+\\n+\\n+ +\\n+\\n+\\n-\\n+\\n+\\n-\\n-\\n-\\n-\\n-\\n+\\n-\\n-\\n-\\n+\\n-\\n-\\n-\\n-\\n-\\n-\\n+\\n-\\n-\\n+\\n+\\n+\\n-\\n-\\n+\\n+\\n-\\n+\\n-\\n-\\n+\\n+\\n-\\n-\\n+\\n-\\n+\\n+\\n-\\n-\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\nLogistic regression with b=-0.5, w=(-1,1)\\nx[,1]\\nx[,2]\\n-\\n-\\n-\\n-\\n-\\n+\\n-\\n-\\n+\\n+\\n-\\n-\\n-\\n+\\n-\\n-\\n+\\n+\\n-\\n+\\n-\\n-\\n-\\n-\\n-\\n-\\n+\\n+\\n-\\n-\\n-\\n-\\n-\\n-\\n+\\n+\\n-\\n-\\n-\\n-\\n+\\n+\\n+\\n-\\n+\\n-\\n+\\n+\\n-\\n-\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\nLogistic regression with b=-2.5, w=(-5,5)\\nx[,1]\\nx[,2]\\n-\\n-\\n-\\n-\\n-\\n+\\n-\\n-\\n+\\n+\\n-\\n-\\n-\\n+\\n-\\n-\\n+\\n+\\n-\\n-\\n+\\n-\\n-\\n-\\n-\\n-\\n+\\n+\\n-\\n-\\n-\\n+\\n-\\n-\\n+\\n+\\n-\\n-\\n-\\n-\\n-\\n+\\n+\\n-\\n+\\n-\\n+\\n+\\n-\\n-\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\n-1.0\\n-0.5\\n0.0\\n0.5\\n1.0\\nLinear classifier with b=\\n1\\n2 2\\n,w=\\n!\\n!\\n!\\n!1\\n2\\n, \\n1\\n2\\n!\\n!\\n!\\nx[,1]\\nx[,2]\\nFigure 12.1: Effects of scaling logistic regression parameters. Values of x1 and x2 are\\nthe same in all plots (‚àºUnif(‚àí1,1) for both coordinates), but labels were generated\\nrandomly from logistic regressions with Œ≤0 = ‚àí0.1, Œ≤ = (‚àí0.2,0.2) (top left); from\\nŒ≤0 = ‚àí0.5, Œ≤ = (‚àí1,1) (top right); from Œ≤0 = ‚àí2.5, Œ≤ = (‚àí5,5) (bottom left); and\\nfrom a perfect linear classiÔ¨Åer with the same boundary. The large black dot is the\\norigin.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 4}, page_content='12.2. LOGISTIC REGRESSION\\n227\\nIn neither case is the appropriateness of the model guaranteed by the gods, nature,\\nmathematical necessity, etc. We begin by positing the model, to get something to\\nwork with, and we end (if we know what we‚Äôre doing) by checking whether it really\\ndoes match the data, or whether it has systematic Ô¨Çaws.\\nLogistic regression is one of the most commonly used tools for applied statistics\\nand discrete data analysis. There are basically four reasons for this.\\n1. Tradition.\\n2. In addition to the heuristic approach above, the quantity log p/(1 ‚àíp) plays\\nan important role in the analysis of contingency tables (the ‚Äúlog odds‚Äù). Classi-\\nÔ¨Åcation is a bit like having a contingency table with two columns (classes) and\\ninÔ¨Ånitely many rows (values of x). With a Ô¨Ånite contingency table, we can es-\\ntimate the log-odds for each row empirically, by just taking counts in the table.\\nWith inÔ¨Ånitely many rows, we need some sort of interpolation scheme; logistic\\nregression is linear interpolation for the log-odds.\\n3. It‚Äôs closely related to ‚Äúexponential family‚Äù distributions, where the probabil-\\nity of some vector v is proportional to expŒ≤0 + \\uffffm\\nj=1 fj(v)Œ≤j. If one of the\\ncomponents of v is binary, and the functions fj are all the identity function,\\nthen we get a logistic regression. Exponential families arise in many contexts\\nin statistical theory (and in physics!), so there are lots of problems which can\\nbe turned into logistic regression.\\n4. It often works surprisingly well as a classiÔ¨Åer. But, many simple techniques of-\\nten work surprisingly well as classiÔ¨Åers, and this doesn‚Äôt really testify to logistic\\nregression getting the probabilities right.\\n12.2.1\\nLikelihood Function for Logistic Regression\\nBecause logistic regression predicts probabilities, rather than just classes, we can Ô¨Åt it\\nusing likelihood. For each training data-point, we have a vector of features, xi, and\\nan observed class, yi. The probability of that class was either p, if yi = 1, or 1 ‚àíp, if\\nyi = 0. The likelihood is then\\nL(Œ≤0,Œ≤) =\\nn\\n\\uffff\\ni=1\\np(xi)yi (1 ‚àíp(xi)1‚àíyi\\n(12.6)'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 5}, page_content='228\\nCHAPTER 12. LOGISTIC REGRESSION\\n(I could substitute in the actual equation for p, but things will be clearer in a moment\\nif I don‚Äôt.) The log-likelihood turns products into sums:\\n\\uffff(Œ≤0,Œ≤)\\n=\\nn\\n\\uffff\\ni=1\\nyi log p(xi) + (1 ‚àíyi)log1 ‚àíp(xi)\\n(12.7)\\n=\\nn\\n\\uffff\\ni=1\\nlog1 ‚àíp(xi) +\\nn\\n\\uffff\\ni=1\\nyi log\\np(xi)\\n1 ‚àíp(xi)\\n(12.8)\\n=\\nn\\n\\uffff\\ni=1\\nlog1 ‚àíp(xi) +\\nn\\n\\uffff\\ni=1\\nyi(Œ≤0 + xi ¬∑ Œ≤)\\n(12.9)\\n=\\nn\\n\\uffff\\ni=1\\n‚àílog1 + eŒ≤0+xi¬∑Œ≤ +\\nn\\n\\uffff\\ni=1\\nyi(Œ≤0 + xi ¬∑ Œ≤)\\n(12.10)\\nwhere in the next-to-last step we Ô¨Ånally use equation 12.4.\\nTypically, to Ô¨Ånd the maximum likelihood estimates we‚Äôd differentiate the log\\nlikelihood with respect to the parameters, set the derivatives equal to zero, and solve.\\nTo start that, take the derivative with respect to one component of Œ≤, say Œ≤j.\\n‚àÇ\\uffff\\n‚àÇŒ≤j\\n=\\n‚àí\\nn\\n\\uffff\\ni=1\\n1\\n1 + eŒ≤0+xi¬∑Œ≤ eŒ≤0+xi¬∑Œ≤xi j +\\nn\\n\\uffff\\ni=1\\nyi xi j\\n(12.11)\\n=\\nn\\n\\uffff\\ni=1\\n\\uffffyi ‚àíp(xi;Œ≤0,Œ≤)\\uffffxi j\\n(12.12)\\nWe are not going to be able to set this to zero and solve exactly. (That‚Äôs a transcenden-\\ntal equation, and there is no closed-form solution.) We can however approximately\\nsolve it numerically.\\n12.2.2\\nLogistic Regression with More Than Two Classes\\nIf Y can take on more than two values, say k of them, we can still use logistic regres-\\nsion. Instead of having one set of parameters Œ≤0,Œ≤, each class c in 0 : (k ‚àí1) will have\\nits own offset Œ≤(c)\\n0 and vector Œ≤(c), and the predicted conditional probabilities will be\\nPr\\n\\uffff\\nY = c| \\uffffX = x\\n\\uffff\\n=\\neŒ≤(c)\\n0 +x¬∑Œ≤(c)\\n\\uffff\\nc eŒ≤(c)\\n0 +x¬∑Œ≤(c)\\n(12.13)\\nYou can check that when there are only two classes (say, 0 and 1), equation 12.13\\nreduces to equation 12.5, with Œ≤0 = Œ≤(1)\\n0 ‚àíŒ≤(0)\\n0 and Œ≤ = Œ≤(1)‚àíŒ≤(0). In fact, no matter\\nhow many classes there are, we can always pick one of them, say c = 0, and Ô¨Åx its\\nparameters at exactly zero, without any loss of generality2.\\n2Since we can arbitrarily chose which class‚Äôs parameters to ‚Äúzero out‚Äù without affecting the predicted\\nprobabilities, strictly speaking the model in Eq. 12.13 is unidentiÔ¨Åed. That is, different parameter settings\\nlead to exactly the same outcome, so we can‚Äôt use the data to tell which one is right. The usual response\\nhere is to deal with this by a convention: we decide to zero out the parameters of the Ô¨Årst class, and then\\nestimate the contrasting parameters for the others.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 6}, page_content='12.3. NEWTON‚ÄôS METHOD FOR NUMERICAL OPTIMIZATION\\n229\\nCalculation of the likelihood now proceeds as before (only with more book-\\nkeeping), and so does maximum likelihood estimation.\\n12.3\\nNewton‚Äôs Method for Numerical Optimization\\nThere are a huge number of methods for numerical optimization; we can‚Äôt cover all\\nbases, and there is no magical method which will always work better than anything\\nelse. However, there are some methods which work very well on an awful lot of the\\nproblems which keep coming up, and it‚Äôs worth spending a moment to sketch how\\nthey work. One of the most ancient yet important of them is Newton‚Äôs method (alias\\n‚ÄúNewton-Raphson‚Äù).\\nLet‚Äôs start with the simplest case of minimizing a function of one scalar variable,\\nsay f (Œ≤). We want to Ô¨Ånd the location of the global minimum, Œ≤‚àó. We suppose that\\nf is smooth, and that Œ≤‚àóis a regular interior minimum, meaning that the derivative\\nat Œ≤‚àóis zero and the second derivative is positive. Near the minimum we could make\\na Taylor expansion:\\nf (Œ≤) ‚âàf (Œ≤‚àó) +\\n1\\n2(Œ≤ ‚àíŒ≤‚àó)2 d 2 f\\ndŒ≤2\\n\\uffff\\uffff\\uffff\\uffff\\uffff\\nŒ≤=Œ≤‚àó\\n(12.14)\\n(We can see here that the second derivative has to be positive to ensure that f (Œ≤) >\\nf (Œ≤‚àó).) In words, f (Œ≤) is close to quadratic near the minimum.\\nNewton‚Äôs method uses this fact, and minimizes a quadratic approximation to the\\nfunction we are really interested in. (In other words, Newton‚Äôs method is to replace\\nthe problem we want to solve, with a problem which we can solve.) Guess an ini-\\ntial point Œ≤(0). If this is close to the minimum, we can take a second order Taylor\\nexpansion around Œ≤(0) and it will still be accurate:\\nf (Œ≤) ‚âàf (Œ≤(0)) + (Œ≤ ‚àíŒ≤(0))\\nd f\\ndw\\n\\uffff\\uffff\\uffff\\uffff\\uffff\\nŒ≤=Œ≤(0)\\n+\\n1\\n2\\n\\uffff\\nŒ≤ ‚àíŒ≤(0)\\uffff2 d 2 f\\ndw2\\n\\uffff\\uffff\\uffff\\uffff\\uffff\\nŒ≤=Œ≤(0)\\n(12.15)\\nNow it‚Äôs easy to minimize the right-hand side of equation 12.15. Let‚Äôs abbreviate\\nthe derivatives, because they get tiresome to keep writing out:\\nd f\\ndw\\n\\uffff\\uffff\\uffff\\nŒ≤=Œ≤(0) = f \\uffff(Œ≤(0)),\\nd 2 f\\ndw2\\n\\uffff\\uffff\\uffff\\nŒ≤=Œ≤(0) = f \\uffff\\uffff(Œ≤(0)). We just take the derivative with respect to Œ≤, and set it equal\\nto zero at a point we‚Äôll call Œ≤(1):\\n0\\n=\\nf \\uffff(Œ≤(0)) +\\n1\\n2 f \\uffff\\uffff(Œ≤(0))2(Œ≤(1) ‚àíŒ≤(0))\\n(12.16)\\nŒ≤(1)\\n=\\nŒ≤(0) ‚àí\\nf \\uffff(Œ≤(0))\\nf \\uffff\\uffff(Œ≤(0))\\n(12.17)\\nThe value Œ≤(1) should be a better guess at the minimum Œ≤‚àóthan the initial one Œ≤(0)\\nwas. So if we use it to make a quadratic approximation to f , we‚Äôll get a better ap-\\nproximation, and so we can iterate this procedure, minimizing one approximation'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 7}, page_content='230\\nCHAPTER 12. LOGISTIC REGRESSION\\nand then using that to get a new approximation:\\nŒ≤(n+1) = Œ≤(n) ‚àí\\nf \\uffff(Œ≤(n))\\nf \\uffff\\uffff(Œ≤(n))\\n(12.18)\\nNotice that the true minimum Œ≤‚àóis a Ô¨Åxed point of equation 12.18: if we happen to\\nland on it, we‚Äôll stay there (since f \\uffff(Œ≤‚àó) = 0). We won‚Äôt show it, but it can be proved\\nthat if Œ≤(0) is close enough to Œ≤‚àó, then Œ≤(n) ‚ÜíŒ≤‚àó, and that in general |Œ≤(n) ‚àíŒ≤‚àó| =\\nO(n‚àí2), a very rapid rate of convergence. (Doubling the number of iterations we use\\ndoesn‚Äôt reduce the error by a factor of two, but by a factor of four.)\\nLet‚Äôs put this together in an algorithm.\\nmy.newton = function(f,f.prime,f.prime2,beta0,tolerance=1e-3,max.iter=50) {\\nbeta = beta0\\nold.f = f(beta)\\niterations = 0\\nmade.changes = TRUE\\nwhile(made.changes & (iterations < max.iter)) {\\niterations <- iterations +1\\nmade.changes <- FALSE\\nnew.beta = beta - f.prime(beta)/f.prime2(beta)\\nnew.f = f(new.beta)\\nrelative.change = abs(new.f - old.f)/old.f -1\\nmade.changes = (relative.changes > tolerance)\\nbeta = new.beta\\nold.f = new.f\\n}\\nif (made.changes) {\\nwarning(\"Newton‚Äôs method terminated before convergence\")\\n}\\nreturn(list(minimum=beta,value=f(beta),deriv=f.prime(beta),\\nderiv2=f.prime2(beta),iterations=iterations,\\nconverged=!made.changes))\\n}\\nThe Ô¨Årst three arguments here have to all be functions. The fourth argument is our\\ninitial guess for the minimum, Œ≤(0). The last arguments keep Newton‚Äôs method from\\ncycling forever: tolerance tells it to stop when the function stops changing very\\nmuch (the relative difference between f (Œ≤(n)) and f (Œ≤(n+1)) is small), and max.iter\\ntells it to never do more than a certain number of steps no matter what. The return\\nvalue includes the estmated minimum, the value of the function there, and some\\ndiagnostics ‚Äî the derivative should be very small, the second derivative should be\\npositive, etc.\\nYou may have noticed some potential problems ‚Äî what if we land on a point\\nwhere f \\uffff\\uffffis zero? What if f (Œ≤(n+1)) > f (Œ≤(n))? Etc. There are ways of handling\\nthese issues, and more, which are incorporated into real optimization algorithms\\nfrom numerical analysis ‚Äî such as the optim function in R; I strongly recommend'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 8}, page_content='12.3. NEWTON‚ÄôS METHOD FOR NUMERICAL OPTIMIZATION\\n231\\nyou use that, or something like that, rather than trying to roll your own optimization\\ncode.3\\n12.3.1\\nNewton‚Äôs Method in More than One Dimension\\nSuppose that the objective f is a function of multiple arguments, f (Œ≤1,Œ≤2,...Œ≤p).\\nLet‚Äôs bundle the parameters into a single vector, w. Then the Newton update is\\nŒ≤(n+1) = Œ≤(n) ‚àíH ‚àí1(Œ≤(n))‚àáf (Œ≤(n))\\n(12.19)\\nwhere ‚àáf is the gradient of f , its vector of partial derivatives [‚àÇf /‚àÇŒ≤1,‚àÇf /‚àÇŒ≤2,...‚àÇf /‚àÇŒ≤p],\\nand H is the Hessian of f , its matrix of second partial derivatives, Hi j = ‚àÇ2 f /‚àÇŒ≤i‚àÇŒ≤j.\\nCalculating H and ‚àáf isn‚Äôt usually very time-consuming, but taking the inverse\\nof H is, unless it happens to be a diagonal matrix. This leads to various quasi-Newton\\nmethods, which either approximate H by a diagonal matrix, or take a proper inverse\\nof H only rarely (maybe just once), and then try to update an estimate of H ‚àí1(Œ≤(n))\\nas Œ≤(n) changes.\\n12.3.2\\nIteratively Re-Weighted Least Squares\\nThis discussion of Newton‚Äôs method is quite general, and therefore abstract. In the\\nparticular case of logistic regression, we can make everything look much more ‚Äústa-\\ntistical‚Äù.\\nLogistic regression, after all, is a linear model for a transformation of the proba-\\nbility. Let‚Äôs call this transformation g:\\ng(p) ‚â°log\\np\\n1 ‚àíp\\n(12.20)\\nSo the model is\\ng(p) = Œ≤0 + x ¬∑ Œ≤\\n(12.21)\\nand Y |X = x ‚àºBinom(1, g ‚àí1(Œ≤0 + x ¬∑ Œ≤)). It seems that what we should want to\\ndo is take g(y) and regress it linearly on x. Of course, the variance of Y , according\\nto the model, is going to chance depending on x ‚Äî it will be (g ‚àí1(Œ≤0 + x ¬∑ Œ≤))(1 ‚àí\\ng ‚àí1(Œ≤0+x ¬∑Œ≤)) ‚Äî so we really ought to do a weighted linear regression, with weights\\ninversely proportional to that variance. Since writing Œ≤0 + x ¬∑ Œ≤ is getting annoying,\\nlet‚Äôs abbreviate it by ¬µ (for ‚Äúmean‚Äù), and let‚Äôs abbreviate that variance as V (¬µ).\\nThe problem is that y is either 0 or 1, so g(y) is either ‚àí‚àûor +‚àû. We will evade\\nthis by using Taylor expansion.\\ng(y) ‚âàg(¬µ) + (y ‚àí¬µ)g \\uffff(¬µ) ‚â°z\\n(12.22)\\nThe right hand side, z will be our effective response variable. To regress it, we need\\nits variance, which by propagation of error will be (g \\uffff(¬µ))2V (¬µ).\\n3optim actually is a wrapper for several different optimization methods; method=BFGS selects a\\nNewtonian method; BFGS is an acronym for the names of the algorithm‚Äôs inventors.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 9}, page_content='232\\nCHAPTER 12. LOGISTIC REGRESSION\\nNotice that both the weights and z depend on the parameters of our logistic\\nregression, through ¬µ. So having done this once, we should really use the new pa-\\nrameters to update z and the weights, and do it again. Eventually, we come to a Ô¨Åxed\\npoint, where the parameter estimates no longer change.\\nThe treatment above is rather heuristic4, but it turns out to be equivalent to using\\nNewton‚Äôs method, with the expected second derivative of the log likelihood, instead\\nof its actual value.5 Since, with a large number of observations, the observed sec-\\nond derivative should be close to the expected second derivative, this is only a small\\napproximation.\\n12.4\\nGeneralized Linear Models and Generalized Ad-\\nditive Models\\nLogistic regression is part of a broader family of generalized linear models (GLMs),\\nwhere the conditional distribution of the response falls in some parametric family,\\nand the parameters are set by the linear predictor. Ordinary, least-squares regression\\nis the case where response is Gaussian, with mean equal to the linear predictor, and\\nconstant variance. Logistic regression is the case where the response is binomial, with\\nn equal to the number of data-points with the given x (often but not always 1), and p\\nis given by Equation 12.5. Changing the relationship between the parameters and the\\nlinear predictor is called changing the link function. For computational reasons, the\\nlink function is actually the function you apply to the mean response to get back the\\nlinear predictor, rather than the other way around ‚Äî (12.4) rather than (12.5). There\\nare thus other forms of binomial regression besides logistic regression.6 There is also\\nPoisson regression (appropriate when the data are counts without any upper limit),\\ngamma regression, etc.; we will say more about these in Chapter 13.\\nIn R, any standard GLM can be Ô¨Åt using the (base) glm function, whose syn-\\ntax is very similar to that of lm. The major wrinkle is that, of course, you need\\nto specify the family of probability distributions to use, by the family option ‚Äî\\nfamily=binomial defaults to logistic regression. (See help(glm) for the gory\\ndetails on how to do, say, probit regression.) All of these are Ô¨Åt by the same sort of\\nnumerical likelihood maximization.\\nOne caution about using maximum likelihood to Ô¨Åt logistic regression is that it\\ncan seem to work badly when the training data can be linearly separated. The reason\\nis that, to make the likelihood large, p(xi) should be large when yi = 1, and p should\\nbe small when yi = 0. If Œ≤0,Œ≤0 is a set of parameters which perfectly classiÔ¨Åes the\\ntraining data, then cŒ≤0,cŒ≤ is too, for any c > 1, but in a logistic regression the second\\n4That is, mathematically incorrect.\\n5This takes a reasonable amount of algebra to show, so we‚Äôll skip it. The key point however is the\\nfollowing. Take a single Bernoulli observation with success probability p. The log-likelihood is Y log p +\\n(1‚àíY )log1 ‚àíp. The Ô¨Årst derivative with respect to p is Y /p ‚àí(1‚àíY )/(1‚àíp), and the second derivative\\nis ‚àíY /p2 ‚àí(1 ‚àíY )/(1 ‚àíp)2. Taking expectations of the second derivative gives ‚àí1/p ‚àí1/(1 ‚àíp) =\\n‚àí1/p(1 ‚àíp). In other words, V (p) = ‚àí1/E\\uffff\\uffff\\uffff\\uffff\\uffff. Using weights inversely proportional to the variance\\nthus turns out to be equivalent to dividing by the expected second derivative.\\n6My experience is that these tend to give similar error rates as classiÔ¨Åers, but have rather different\\nguesses about the underlying probabilities.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 10}, page_content='12.4. GENERALIZED LINEAR MODELS AND GENERALIZED ADDITIVE MODELS233\\nset of parameters will have more extreme probabilities, and so a higher likelihood.\\nFor linearly separable data, then, there is no parameter vector which maximizes the\\nlikelihood, since \\uffffcan always be increased by making the vector larger but keeping\\nit pointed in the same direction.\\nYou should, of course, be so lucky as to have this problem.\\n12.4.1\\nGeneralized Additive Models\\nA natural step beyond generalized linear models is generalized additive models\\n(GAMs), where instead of making the transformed mean response a linear function\\nof the inputs, we make it an additive function of the inputs. This means combining\\na function for Ô¨Åtting additive models with likelihood maximization. The R function\\nhere is gam, from the CRAN package of the same name. (Alternately, use the func-\\ntion gam in the package mgcv, which is part of the default R installation.) We will\\nlook at how this works in some detail in Chapter 13.\\nGAMs can be used to check GLMs in much the same way that smoothers can be\\nused to check parametric regressions: Ô¨Åt a GAM and a GLM to the same data, then\\nsimulate from the GLM, and re-Ô¨Åt both models to the simulated data. Repeated many\\ntimes, this gives a distribution for how much better the GAM will seem to Ô¨Åt than\\nthe GLM does, even when the GLM is true. You can then read a p-value off of this\\ndistribution.\\n12.4.2\\nAn Example (Including Model Checking)\\nHere‚Äôs a worked R example, using the data from the upper right panel of Figure 12.1.\\nThe 50√ó2 matrix x holds the input variables (the coordinates are independently and\\nuniformly distributed on [‚àí1,1]), and y.1 the corresponding class labels, themselves\\ngenerated from a logistic regression with Œ≤0 = ‚àí0.5, Œ≤ = (‚àí1,1).\\n> logr = glm(y.1 ~ x[,1] + x[,2], family=binomial)\\n> logr\\nCall:\\nglm(formula = y.1 ~ x[, 1] + x[, 2], family = binomial)\\nCoefficients:\\n(Intercept)\\nx[, 1]\\nx[, 2]\\n-0.410\\n-1.050\\n1.366\\nDegrees of Freedom: 49 Total (i.e. Null);\\n47 Residual\\nNull Deviance:\\n68.59\\nResidual Deviance: 58.81\\nAIC: 64.81\\n> sum(ifelse(logr$fitted.values<0.5,0,1) != y.1)/length(y.1)\\n[1] 0.32\\nThe deviance of a model Ô¨Åtted by maximum likelihood is (twice) the difference\\nbetween its log likelihood and the maximum log likelihood for a saturated model,\\ni.e., a model with one parameter per observation. Hopefully, the saturated model'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 11}, page_content='234\\nCHAPTER 12. LOGISTIC REGRESSION\\ncan give a perfect Ô¨Åt.7 Here the saturated model would assign probability 1 to the\\nobserved outcomes8, and the logarithm of 1 is zero, so D = 2\\uffff(\\uffff\\nŒ≤0, \\uffff\\nŒ≤). The null\\ndeviance is what‚Äôs achievable by using just a constant bias b and setting w = 0. The\\nÔ¨Åtted model deÔ¨Ånitely improves on that.9\\nThe Ô¨Åtted values of the logistic regression are the class probabilities; this shows\\nthat the error rate of the logistic regression, if you force it to predict actual classes, is\\n32%. This sounds bad, but notice from the contour lines in the Ô¨Ågure that lots of the\\nprobabilities are near 0.5, meaning that the classes are just genuinely hard to predict.\\nTo see how well the logistic regression assumption holds up, let‚Äôs compare this to\\na GAM.10\\n> library(gam)\\n> gam.1 = gam(y.1~lo(x[,1])+lo(x[,2]),family=\"binomial\")\\n> gam.1\\nCall:\\ngam(formula = y.1 ~ lo(x[, 1]) + lo(x[, 2]), family = \"binomial\")\\nDegrees of Freedom: 49 total; 41.39957 Residual\\nResidual Deviance: 49.17522\\nThis Ô¨Åts a GAM to the same data, using lowess smoothing of both input variables.\\nNotice that the residual deviance is lower. That is, the GAM Ô¨Åts better. We expect\\nthis; the question is whether the difference is signiÔ¨Åcant, or within the range of what\\nwe should expect when logistic regression is valid. To test this, we need to simulate\\nfrom the logistic regression model.\\nsimulate.from.logr = function(x, coefs) {\\nrequire(faraway) # For accessible logit and inverse-logit functions\\nn = nrow(x)\\nlinear.part = coefs[1] + x %*% coefs[-1]\\nprobs = ilogit(linear.part) # Inverse logit\\ny = rbinom(n,size=1,prob=probs)\\nreturn(y)\\n}\\nNow we simulate from our Ô¨Åtted model, and re-Ô¨Åt both the logistic regression\\nand the GAM.\\n7The factor of two is so that the deviance will have a œá 2 distribution. SpeciÔ¨Åcally, if the model with p\\nparameters is right, the deviance will have a œá 2 distribution with n ‚àíp degrees of freedom.\\n8This is not possible when there are multiple observations with the same input features, but different\\nclasses.\\n9AIC is of course the Akaike information criterion, ‚àí2\\uffff+2q, with q being the number of parameters\\n(here, q = 3). AIC has some truly devoted adherents, especially among non-statisticians, but I have been\\ndeliberately ignoring it and will continue to do so. Basically, to the extent AIC succeeds, it works as\\nfast, large-sample approximation to doing leave-one-out cross-validation. Claeskens and Hjort (2008) is a\\nthorough, modern treatment of AIC and related model-selection criteria from a statistical viewpoint.\\n10Previous examples of using GAMs have mostly used the mgcv package and spline smoothing. There\\nis no particular reason to switch to the gam library and lowess smoothing here, but there‚Äôs also no real\\nreason not to.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 12}, page_content='12.4. GENERALIZED LINEAR MODELS AND GENERALIZED ADDITIVE MODELS235\\ndelta.deviance.sim = function (x,logistic.model) {\\ny.new = simulate.from.logr(x,logistic.model$coefficients)\\nGLM.dev = glm(y.new ~ x[,1] + x[,2], family=\"binomial\")$deviance\\nGAM.dev = gam(y.new ~ lo(x[,1]) + lo(x[,2]), family=\"binomial\")$deviance\\nreturn(GLM.dev - GAM.dev)\\n}\\nNotice that in this simulation we are not generating new \\uffffX values. The logistic re-\\ngression and the GAM are both models for the response conditional on the inputs,\\nand are agnostic about how the inputs are distributed, or even whether it‚Äôs meaning-\\nful to talk about their distribution.\\nFinally, we repeat the simulation a bunch of times, and see where the observed\\ndifference in deviances falls in the sampling distribution.\\n> delta.dev = replicate(1000,delta.deviance.sim(x,logr))\\n> delta.dev.observed = logr$deviance - gam.1$deviance # 9.64\\n> sum(delta.dev.observed > delta.dev)/1000\\n[1] 0.685\\nIn other words, the amount by which a GAM Ô¨Åts the data better than logistic regres-\\nsion is pretty near the middle of the null distribution. Since the example data really\\ndid come from a logistic regression, this is a relief.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 13}, page_content='236\\nCHAPTER 12. LOGISTIC REGRESSION\\n0\\n10\\n20\\n30\\n0.00\\n0.02\\n0.04\\n0.06\\n0.08\\n0.10\\nAmount by which GAM fits better than logistic regression\\nSampling distribution under logistic regression\\nN = 1000   Bandwidth = 0.8386\\nDensity\\nFigure 12.2: Sampling distribution for the difference in deviance between a GAM\\nand a logistic regression, on data generated from a logistic regression. The observed\\ndifference in deviances is shown by the dashed horizontal line.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.6.8 Quartz PDFContext', 'creator': 'Preview', 'creationdate': \"D:20120228012218Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'ADAfaEPoV', 'author': 'Cosma Shalizi', 'subject': '', 'keywords': '', 'moddate': \"D:20120228012218Z00'00'\", 'trapped': '', 'modDate': \"D:20120228012218Z00'00'\", 'creationDate': \"D:20120228012218Z00'00'\", 'page': 14}, page_content='12.5. EXERCISES\\n237\\n12.5\\nExercises\\nTo think through, not to hand in.\\n1. A multiclass logistic regression, as in Eq. 12.13, has parameters Œ≤(c)\\n0\\nand Œ≤(c)\\nfor each class c. Show that we can always get the same predicted probabilities\\nby setting Œ≤(c)\\n0 = 0, Œ≤(c) = 0 for any one class c, and adjusting the parameters\\nfor the other classes appropriately.\\n2. Find the Ô¨Årst and second derivatives of the log-likelihood for logistic regression\\nwith one predictor variable. Explicitly write out the formula for doing one step\\nof Newton‚Äôs method. Explain how this relates to re-weighted least squares.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 0}, page_content='Lecture 7\\nDecision Trees\\nAlice Gao\\nNovember 2, 2021\\nContents\\n1\\nLearning Goals\\n3\\n2\\nExamples of Decision Trees\\n3\\n3\\nDeÔ¨Ånition and Classifying an Example\\n7\\n3.1\\nWhat is a decision tree?\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\n3.2\\nClassifying an example using a decision tree\\n. . . . . . . . . . . . . . . . . .\\n7\\n4\\nThe Decision Tree Learning Algorithm\\n8\\n4.1\\nIssues in learning a decision tree . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\n4.2\\nGrow a full tree given an order of testing features . . . . . . . . . . . . . . .\\n8\\n4.3\\nWhen do we stop?\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n11\\n4.4\\nBase case 2: no features left . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n11\\n4.5\\nBase case 3: no examples left\\n. . . . . . . . . . . . . . . . . . . . . . . . . .\\n13\\n4.6\\nPseudo-code for the decision tree learner algorithm\\n. . . . . . . . . . . . . .\\n15\\n5\\nDetermine the Order of Testing Features\\n16\\n5.1\\nWhich feature should we test at each step? . . . . . . . . . . . . . . . . . . .\\n16\\n5.2\\nIdentifying the most important feature . . . . . . . . . . . . . . . . . . . . .\\n16\\n5.3\\nEntropy of a distribution over two outcomes . . . . . . . . . . . . . . . . . .\\n17\\n5.4\\nExpected information gain of testing a feature . . . . . . . . . . . . . . . . .\\n19\\n5.5\\nA full example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n20\\n6\\nReal-Valued Features\\n26\\n6.1\\nJeeves dataset with real-valued temperatures . . . . . . . . . . . . . . . . . .\\n26\\n6.2\\nHandling a discrete feature . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n27\\n6.3\\nHandling a real-valued feature . . . . . . . . . . . . . . . . . . . . . . . . . .\\n28\\n6.4\\nChoosing a split point for a real-valued feature . . . . . . . . . . . . . . . . .\\n28\\n7\\nOver-Ô¨Åtting\\n31\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 1}, page_content='CS 486/686\\nLecture 7\\n7.1\\nCorrupted data in the Jeeves dataset . . . . . . . . . . . . . . . . . . . . . .\\n31\\n7.2\\nDealing with over-Ô¨Åtting with pruning\\n. . . . . . . . . . . . . . . . . . . . .\\n33\\n8\\nPractice Problems\\n36\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 2 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 2}, page_content='CS 486/686\\nLecture 7\\n1\\nLearning Goals\\nBy the end of the lecture, you should be able to\\n‚Ä¢ Describe the components of a decision tree.\\n‚Ä¢ Construct a decision tree given an order of testing the features.\\n‚Ä¢ Determine the prediction accuracy of a decision tree on a test set.\\n‚Ä¢ Compute the entropy of a probability distribution.\\n‚Ä¢ Compute the expected information gain for selecting a feature.\\n‚Ä¢ Trace the execution of and implement the ID3 algorithm.\\n2\\nExamples of Decision Trees\\nOur Ô¨Årst machine learning algorithm will be decision trees. A decision tree is a very common\\nalgorithm that we humans use to make many diÔ¨Äerent decisions. You may be using one\\nwithout realizing it. Here are some examples of decision trees.\\nExample:\\nWhich language should you learn?\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 3 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 3}, page_content='CS 486/686\\nLecture 7\\nExample:\\nWhat kind of pet is right for you?\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 4 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 4}, page_content='CS 486/686\\nLecture 7\\nExample:\\nShould you use emoji in a conversation?\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 5 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 5}, page_content='CS 486/686\\nLecture 7\\nWe will use the following example as a running example in this unit.\\nExample:\\nJeeves is a valet to Bertie Wooster. On some days, Bertie likes to play\\ntennis and asks Jeeves to lay out his tennis things and book the court. Jeeves would\\nlike to predict whether Bertie will play tennis (and so be a better valet). Each morning\\nover the last two weeks, Jeeves has recorded whether Bertie played tennis on that day\\nand various attributes of the weather (training set).\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nYes\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\nJeeves would like to evaluate the classiÔ¨Åer he has come up with for predicting whether\\nBertie will play tennis. Each morning over the next two weeks, Jeeves records the\\nfollowing data (test set).\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\nMild\\nHigh\\nStrong\\nNo\\n2\\nRain\\nHot\\nNormal\\nStrong\\nNo\\n3\\nRain\\nCool\\nHigh\\nStrong\\nNo\\n4\\nOvercast\\nHot\\nHigh\\nStrong\\nYes\\n5\\nOvercast\\nCool\\nNormal\\nWeak\\nYes\\n6\\nRain\\nHot\\nHigh\\nWeak\\nYes\\n7\\nOvercast\\nMild\\nNormal\\nWeak\\nYes\\n8\\nOvercast\\nCool\\nHigh\\nWeak\\nYes\\n9\\nRain\\nCool\\nHigh\\nWeak\\nYes\\n10\\nRain\\nMild\\nNormal\\nStrong\\nNo\\n11\\nOvercast\\nMild\\nHigh\\nWeak\\nYes\\n12\\nSunny\\nMild\\nNormal\\nWeak\\nYes\\n13\\nSunny\\nCool\\nHigh\\nStrong\\nNo\\n14\\nSunny\\nCool\\nHigh\\nWeak\\nNo\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 6 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 6}, page_content='CS 486/686\\nLecture 7\\n3\\nDeÔ¨Ånition and Classifying an Example\\n3.1\\nWhat is a decision tree?\\nA decision tree is a simple model for supervised classiÔ¨Åcation. It is used for classifying a\\nsingle discrete target feature.\\nEach internal node performs a Boolean test on an input feature (in general, a test may have\\nmore than two options, but these can be converted to a series of Boolean tests). The edges\\nare labeled with the values of that input feature.\\nEach leaf node speciÔ¨Åes a value for the target feature.\\n3.2\\nClassifying an example using a decision tree\\nClassifying an example using a decision tree is very intuitive. We traverse down the tree,\\nevaluating each test and following the corresponding edge. When a leaf is reached, we return\\nthe classiÔ¨Åcation on that leaf.\\nExample:\\nHere is an example of using the emoji decision tree. Assume:\\n‚Ä¢ I am 30 years old.\\n‚Ä¢ This is work related.\\n‚Ä¢ I am an accountant.\\n‚Ä¢ I am not trying to get Ô¨Åred.\\nFollowing the tree, we answer no (not under 20 years old), no (not over 65 years old),\\nyes (work related), no (not working in tech), and no (not trying to get Ô¨Åred). The leaf\\nwe reach is a thumb down, meaning we should not use emoji.\\nProblem:\\nIf we convert a decision tree to a program, what does it look like?\\nSolution:\\nA decision tree corresponds to a program with a big nested if-then-else\\nstructure.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 7 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 7}, page_content='CS 486/686\\nLecture 7\\n4\\nThe Decision Tree Learning Algorithm\\n4.1\\nIssues in learning a decision tree\\nHow can we build a decision tree given a data set? First, we need to decide on an order of\\ntesting the input features. Next, given an order of testing the input features, we can build\\na decision tree by splitting the examples whenever we test an input feature.\\nLet‚Äôs take a look at the Jeeves training set again.\\nEach row is an example.\\nThere are\\n14 examples. For each example, we have Ô¨Åve feature values: day, outlook, temperature,\\nhumidity, and wind. In fact, Day is not a useful feature since it‚Äôs diÔ¨Äerent for every example.\\nSo, we will focus on the other four input features. We have one target feature or label, which\\nis whether Bertie decided to play tennis or not.\\nThe decision tree is a powerful and Ô¨Çexible model. Given a data set, we can generate many\\ndiÔ¨Äerent decision trees. Therefore, there are a few questions we need to think about when\\ndeciding which tree we should build.\\nFirst, diÔ¨Äerent orders of testing the input features will lead to diÔ¨Äerent decision trees. So,\\nwhich order should we use? The number of possible orders is quite large, so it is challenging\\nto Ô¨Ånd the optimal order in the search space. Given this, we will use a greedy or myopic\\napproach. Instead of Ô¨Ånding the optimal order of testing the features, we will make the\\nmyopic best choice at each step.\\nYou might be wondering, what is the diÔ¨Äerence between making the optimal choice versus\\nmaking the myopic best choice at each step? The main diÔ¨Äerence is that the optimal strategy\\nconsiders the future, whereas the myopic strategy only cares about the current step. To\\ngenerate an optimal tree, at each step, we need to think about how our feature choice at\\nthis step might aÔ¨Äect our choices in the future. On the contrary, the myopic strategy does\\nnot think about the future at all and only cares about Ô¨Ånding the best feature to test at the\\ncurrent step.\\nNow, suppose that we have chosen an order of testing the features using the myopic strategy.\\nWe have another choice. Should we grow a full tree or should we stop growing the tree earlier?\\nRecall that I discussed over-Ô¨Åtting previously. The full tree may over-Ô¨Åt the training data,\\nso a smaller tree might be better since it might generalize better to unseen test data.\\nTo answer this question, we need a bias or an assumption that we make about which tree we\\nprefer. One possible assumption could be based on Occam‚Äôs razor principle, which says that\\nthe simplest model or hypothesis is probably the best. Based on Occam‚Äôs razor, we would\\nprefer a tree that is smaller than the full tree. This still leaves lots of options for us. For\\nexample, we can grow the tree until a certain depth, or we can grow the tree until it has a\\ncertain number of nodes.\\n4.2\\nGrow a full tree given an order of testing features\\nLet‚Äôs go through an example of constructing the full tree using the Jeeves training set. I‚Äôve\\ngiven you an order of testing the input features below.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 8 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 8}, page_content='CS 486/686\\nLecture 7\\nProblem:\\nConstruct a (full) decision tree for the Jeeves data set using the following\\norder of testing features.\\n‚Ä¢ First, test Outlook.\\n‚Ä¢ For Outlook = Sunny, test Temp.\\n‚Ä¢ For Outlook = Rain, test Wind.\\n‚Ä¢ For other branches, test Humidity before testing Wind.\\nSolution:\\nHere is the process to generate the decision tree by the given order.\\nWe have 9 positive and 5 negative examples. They are not in the same class, so we\\nwill have to choose a feature to test.\\nBased on the given order, we will test Outlook Ô¨Årst. Outlook has three values: Sunny,\\nOvercast, and Rain. We split the examples into three branches.\\nThe three sets look like this. Example 1 has Outlook equal to Sunny, so it goes into\\nthe left branch. Example 3 has Outlook equal to Overcast, so it goes into the middle\\nbranch, etc.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 9 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 9}, page_content='CS 486/686\\nLecture 7\\nIn the middle branch, all the examples are positive. There is no need to test another\\nfeature, and so we may make a decision. We create a leaf node with the label Yes, and\\nwe are done with this branch.\\nLooking at the left branch next, there are two positive and three negative examples.\\nWe have to test another feature. Based on the given order, we will test Temp next.\\nTemp has three values ‚Äî Hot, Mild, and Cool. We create three branches again. The\\nÔ¨Åve examples are split between these branches.\\nWe will repeat this process at every node. First, check if all the examples are in the\\nsame class. If they are, create a leaf node with the class label and stop. Otherwise,\\nchoose the next feature to test and split the examples based on the chosen feature.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 10 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 10}, page_content='CS 486/686\\nLecture 7\\nThe above is the Ô¨Ånal decision tree. Each internal node represents a test‚ÄîNot all of\\nthese are Boolean. Beside each node, the training examples are partitioned into two\\nclasses based on whether Bertie played tennis that day: Yes (+) and No (‚àí).\\n4.3\\nWhen do we stop?\\nThere are three possible stopping criteria for the decision tree algorithm. For the example\\nin the previous section, we encountered the Ô¨Årst case only: when all of the examples belong\\nto the same class. In this case, we make the decision of that class and then we‚Äôre done.\\n4.4\\nBase case 2: no features left\\nLet‚Äôs look at the second case: what should we do if there are no more features to test?\\nProblem:\\nI took our training set and added a few examples. It now has 17 instead of\\n14 examples. For this modiÔ¨Åed training set, let‚Äôs construct one branch of the decision\\ntree where Outlook is Sunny, Temperature is Mild, and Humidity is High.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 11 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 11}, page_content='CS 486/686\\nLecture 7\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nYes\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\n15\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n16\\nSunny\\nMild\\nHigh\\nWeak\\nYes\\n17\\nSunny\\nMild\\nHigh\\nStrong\\nYes\\nSolution:\\nAfter testing Humidity is High, what should we do next? We have tested\\nthree of the four input features. To continue, testing Wind is the only option. When\\nWind is Strong, we have one positive example, and the decision is Yes. When Wind is\\nWeak, we have three examples: one positive and two negative examples. The examples\\nare mixed, so we cannot make a decision. But, we have tested all four features ‚Äî\\nthere‚Äôs no more feature to test. What should we do in this case?\\nLet‚Äôs take another look at our data set. There are three examples when Wind is Weak.\\nNote that, for the three examples, the values of all input features are all the same ‚Äî\\nSunny, Mild, High, and Weak, but they have diÔ¨Äerent labels, No for 8 and 15 and Yes\\nfor 16. This is an example of a noisy data set. With noisy data, even if we know the\\nvalues of all the input features, we are still unable to make a deterministic decision.\\nOne reason for having a noisy data set is that the decision may be inÔ¨Çuenced by\\nsome features that we do not observe. Perhaps, another factor not related to weather\\ninÔ¨Çuences Bertie‚Äôs decision, but we don‚Äôt know what that factor is.\\nWhat should we do when we run out of features to test? There are a few options.\\nOne option is to predict the majority class. In this case, the majority decision is No.\\nAnother option is to make a randomized decision. We can think of the three examples\\nas a probability distribution. There is a 1/3 probability of predicting Yes and a 2/3\\nprobability of predicting No. We will make the decision based on a random draw from\\nthe distribution. For this example, let‚Äôs use the majority decision.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 12 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 12}, page_content='CS 486/686\\nLecture 7\\n4.5\\nBase case 3: no examples left\\nLet‚Äôs look at the last possible stopping criteria: what should we do if there are no examples\\nleft?\\nProblem:\\nLet‚Äôs consider another modiÔ¨Åed Jeeves training set. Complete one branch\\nof the decision tree where Temperature is Hot, Wind is Weak, and Humidity is High.\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nYes\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\n15\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\nSolution:\\nAfter testing the three features, we have three examples left: one positive\\nand two negative. The only feature left is Outlook. Outlook has three values. Let‚Äôs\\nsplit up the examples into three branches.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 13 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 13}, page_content='CS 486/686\\nLecture 7\\nIf Outlook is Sunny, we have two negative examples, and the decision is No. If Outlook\\nis Overcast, we have one positive example, and the decision is Yes. Finally, if Outlook\\nis Rain, there are no examples left. What should we do here?\\nBefore we decide on what to do, let‚Äôs ask a related question. Why did we encounter\\nthis case? Let‚Äôs take another look at the modiÔ¨Åed data set. The case we are looking\\nfor is: Temperature is Hot, Wind is Weak, Humidity is High, and Outlook is Rain.\\nAfter going through the data set, you will realize that no example in this data set has\\nthis combination of input feature values. This is the reason that we had no examples\\nleft. If we never observe a combination of feature values, we don‚Äôt know how to predict\\nit.\\nNow that we understand why this happened, how should we handle this case? One\\nidea is to try to Ô¨Ånd some examples that are close to this case. If we go up to the\\nparent node, the parent has some examples for diÔ¨Äerent values of Outlook. Arguably,\\nthese are the closest examples to our case. Therefore, we can use the examples at the\\nparent node to make a decision. At the parent node, the examples are likely to be\\nmixed. Most likely, we cannot make a deterministic decision. Similar to the previous\\ncase, we can either make the majority decision or decide based on a random draw from\\na probability distribution.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 14 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 14}, page_content='CS 486/686\\nLecture 7\\n4.6\\nPseudo-code for the decision tree learner algorithm\\nAlgorithm 1 Decision Tree Learner (examples, features)\\n1: if all examples are in the same class then\\n2:\\nreturn the class label.\\n3: else if no features left then\\n4:\\nreturn the majority decision.\\n5: else if no examples left then\\n6:\\nreturn the majority decision at the parent node.\\n7: else\\n8:\\nchoose a feature f.\\n9:\\nfor each value v of feature f do\\n10:\\nbuild edge with label v.\\n11:\\nbuild sub-tree using examples where the value of f is v.\\nHere is the pseudocode for the algorithm. Since a tree is recursive, we will naturally use a\\nrecursive algorithm to build it.\\nThe algorithm starts with three base cases.\\n1. If all the examples are in the same class, we will return the class label.\\n2. If there are no features left, we have noisy data. We can either return the majority\\ndecision or make a decision probabilistically.\\n3. If there are no examples left, then some combination of input features is absent in the\\ntraining set. We can use the examples at the parent node to make a decision. If the\\nexamples are not in the same class, we can either return the majority decision or make\\na decision probabilistically.\\nNext, we have the recursive part. Suppose that we have a pre-speciÔ¨Åed order of testing the\\ninput features. At each step, we will split up the examples based on the chosen feature‚Äôs\\nvalues. We will label the edges with the feature‚Äôs value. Each subtree only has examples\\nwhere the value of the feature corresponds to the value on the edge.\\nThere‚Äôs one crucial step left. So far, we have assumed that a pre-deÔ¨Åned order of testing the\\ninput features. Where does this order come from? In practice, we have to choose this order\\nourselves.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 15 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 15}, page_content='CS 486/686\\nLecture 7\\n5\\nDetermine the Order of Testing Features\\n5.1\\nWhich feature should we test at each step?\\nIn a previous section, I discussed strategies for choosing a decision tree. Given a data set,\\nwe can build many diÔ¨Äerent decision trees. Which tree should we build? One critical issue\\nin machine learning is over-Ô¨Åtting. Over-Ô¨Åtting often happens for a complex model, which\\ncaptures both the useful patterns in the data and the noise. One way to avoid over-Ô¨Åtting is\\nto constrain our model to be a simple one. In our case, we will try to minimize the number\\nof features we have to test by learning a small and shallow tree.\\nIdeally, we would like to Ô¨Ånd the optimal order of testing features, which will minimize the\\nsize of our tree. Unfortunately, Ô¨Ånding the optimal order is too expensive computationally.\\nInstead, we will use a greedy and myopic approach.\\nThe myopic approach will make the best choice at each step without worrying about how\\nour current choice could aÔ¨Äect the potential choices in the future. More concretely, at each\\nstep, we will choose a feature that makes the biggest diÔ¨Äerence to the classiÔ¨Åcation, or a\\nfeature that helps us make a decision as quickly as possible.\\n5.2\\nIdentifying the most important feature\\nIn the previous section, we decided to choose a feature that helps us make a decision as soon\\nas possible, that is, a feature that reduces our uncertainty at much as possible.\\nTo measure the reduction in uncertainty, we will calculate the uncertainty in the examples\\nbefore testing the feature, and subtract the uncertainty in the examples after testing the\\nfeature. The diÔ¨Äerence measures the information content of the feature. Intuitively, testing\\nthe feature allows us to reduce our uncertainty and gain some useful information. We will\\nselect the feature that has the highest information content.\\nFinally, the only remaining question is: How do we measure the uncertainty in a set of\\nexamples? We will use a concept called entropy from information theory.\\nLet‚Äôs look at the deÔ¨Ånition of entropy. Consider a probability distribution over k outcomes:\\nc1 to ck. The probability of each outcome ci is P(ci).\\nGiven a distribution, we will calculate its entropy as follows: The entropy I is the summation\\nof several terms. For each outcome, multiply the probability of the outcome with the log\\nbase 2 of the probability of the outcome. We are using base 2 here because the information\\nis usually measured in bits. Finally, we‚Äôll add all the terms together and negate the result,\\ngiving us a non-negative value. s\\nI(P(c1), . . . , P(c2)) = ‚àí\\nk\\nX\\ni=1\\nP(ci) log2(P(ci)).\\n(1)\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 16 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 16}, page_content='CS 486/686\\nLecture 7\\n5.3\\nEntropy of a distribution over two outcomes\\nLet‚Äôs practice using the formula to calculate entropy For the two questions, we will calculate\\nthe entropy of two binary distributions. While you work on these questions, think about\\nhow the entropy changes as the distribution changes.\\nProblem:\\nWhat is the entropy of the distribution (0.5, 0.5)?\\n(A) 0.2\\n(B) 0.4\\n(C) 0.6\\n(D) 0.8\\n(E) 1\\nSolution:\\nThe correct answer is (E).\\nPerforming the calculation, we have\\n‚àí(0.5 log2(0.5)) √ó 2 = 1\\nThe entropy is 1 bit.\\nYou might be wondering, is one bit of entropy a lot or very little? You will get a better\\nidea of this after question 2. For now, believe me when I say that there is a lot of\\nuncertainty in this binary distribution.\\nThis should make intuitive sense. This distribution is uniform. A uniform distribution\\nhas a lot of uncertainty since every outcome is equally likely to become true.\\nProblem:\\nWhat is the entropy of the distribution (0.01, 0.99)?\\nWe have a very skewed distribution.\\nAlmost all the probability is on the second\\noutcome.\\n(A) 0.02\\n(B) 0.04\\n(C) 0.06\\n(D) 0.08\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 17 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 17}, page_content='CS 486/686\\nLecture 7\\n(E) 0.1\\nSolution:\\nThe correct answer is (D).\\nPerforming the calculation, we have\\n‚àí(0.01 log2(0.01) + 0.99 log2(0.99))\\n= ‚àí(‚àí0.0664 ‚àí0.01435)\\n‚âà0.08.\\nThis distribution has 0.08 bit of uncertainty.\\nCompared to the previous distribution, this distribution has very little uncertainty.\\nAgain, this result makes intuitive sense. Looking at the probabilities, we almost know\\nfor sure that the second outcome will become true. This means that we don‚Äôt really\\nhave that much uncertainty. If you are making a bet, you will probably bet on the\\nsecond outcome and you will likely win the bet.\\nWhat have we learned about entropy from these two questions? Let me summarize some\\nimportant points.\\nProblem:\\nConsider a distribution (p, 1 ‚àíp) where 0 ‚â§p ‚â§1.\\n1. What is the maximum entropy of this distribution?\\n2. What is the minimum entropy of this distribution?\\n3. Plot the entropy of the distribution (p, 1 ‚àíp) with respect to p.\\nSolution:\\nFor any binary distribution, its entropy achieves its maximum value of\\none when the distribution is uniform, and achieves its minimum value of zero when\\nthe distribution is a point mass ‚Äî one outcome has a probability of 1.\\nWhen p is 0 or 1, calculating the entropy is a bit tricky. since log2(0) is undeÔ¨Åned. In\\nthis case, let‚Äôs the term 0 ‚àólog2(0) to be 0. This deÔ¨Ånition is reasonable since limit of\\nx ‚àólog2(x) is 0 when x approaches 0.\\nFinally, here is the plot of the distribution‚Äôs entropy with respect to p. As p increases\\nfrom 0 to 1, the entropy increases Ô¨Årst, reaches the maximum value when p is 0.5, and\\nthen decreases after that.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 18 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 18}, page_content='CS 486/686\\nLecture 7\\nHere is a practice question for you. I‚Äôve summarized some properties of entropy for a binary\\ndistribution. What about a distribution with more than two outcomes. For example, what\\nare the maximum and minimum entropy for a distribution with three outcomes?\\n5.4\\nExpected information gain of testing a feature\\nI have discussed how to measure the uncertainty of a distribution using entropy. The next\\nquestion is, how can we quantify the information content of a feature?\\nConsider a feature with k values, v1 to vk. There are p positive examples and n negative\\nexamples before testing this feature. After testing this feature, we divide the examples into\\nk sets. For each feature value vi, let‚Äôs suppose that the set has pi positive examples and ni\\nnegative examples. This picture shows you the setting.\\nRecall that the information content of a feature is the entropy of the examples before testing\\nthe feature minus the entropy of the examples after testing the future. Formally, we call this\\nthe expected information gain of testing this feature.\\nLet me write down the formula for calculating the expected information gain.\\nBefore testing the feature, we have p positive and n negative examples. Let‚Äôs convert this\\nto a binary distribution: Yes has a probability of p / (p + n), and No has a probability of\\nn / (p + n). We can calculate the entropy of this distribution using the formula we saw.\\nIbefore = I\\n\\x12\\np\\np + n,\\nn\\np + n\\n\\x13\\n.\\n(2)\\nAfter testing the feature, we have k distributions, one for each of the k feature values. We\\nhave a problem here. Without an example, we don‚Äôt know which distribution will be useful.\\nHow do we calculate the entropy of k distributions? The solution is to calculate the expected\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 19 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 19}, page_content='CS 486/686\\nLecture 7\\nentropy of these distributions. We will Ô¨Årst calculate the entropy of each distribution. Then,\\nwe will take the expected value of the k entropies. In the expected value, the weight of each\\ndistribution is the fraction of examples in that distribution.\\nFor example, for the feature value vi, there are pi positive examples and ni negative examples.\\nThe entropy is given by I(pi/(pi + ni), ni/(pi + ni)). The fraction of examples in the this\\ndistribution is (pi +ni)/(p+n) ‚Äî this is the weight of the i-th entropy in the expected value.\\nThe expected entropy after testing the feature is\\nEIafter =\\nk\\nX\\ni=1\\npi + ni\\np + n ‚àóI\\n\\x12\\npi\\npi + ni\\n,\\nni\\npi + ni\\n\\x13\\n.\\n(3)\\nFinally, the expected information gain or entropy reduction is the entropy before testing the\\nfeature minus the expected entropy after testing the feature.\\nInfoGain = Ibefore ‚àíIafter.\\n(4)\\n5.5\\nA full example\\nHere, we will work through generating a complete decision tree based on the rules introduced\\nin this section. We can start with the following questions:\\nProblem:\\nWhat is the entropy of the examples before we select a feature for the\\nroot node of the tree?\\n(A) 0.54\\n(B) 0.64\\n(C) 0.74\\n(D) 0.84\\n(E) 0.94\\nSolution:\\nThere are 14 examples: 9 positive, 5 negative. Applying the formula gives\\nHbefore = ‚àí\\n\\x12 9\\n14 log2\\n\\x12 9\\n14\\n\\x13\\n+ 5\\n14 log2\\n\\x12 5\\n14\\n\\x13\\x13\\n= ‚àí\\n\\x12 9\\n14(‚àí0.637) + 5\\n14(‚àí1.485)\\n\\x13\\n= ‚àí(‚àí0.939)\\n‚âà0.94.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 20 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 20}, page_content='CS 486/686\\nLecture 7\\nThe correct answer is (E).\\n(In an exam, you could calculate log2 x = ln x\\nln 2).\\nProblem:\\nWhat is the expected information gain if we select Outlook as the root\\nnode of the tree?\\n(A) 0.237\\n(B) 0.247\\n(C) 0.257\\n(D) 0.267\\n(E) 0.277\\nSolution:\\nTesting Outlook yields three branches:\\nOutlook =\\n\\uf8f1\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\n\\uf8f3\\nSunny\\n2+\\n3‚àí\\n5 total\\nOvercast\\n4+\\n0‚àí\\n4 total\\nRain\\n3+\\n2‚àí\\n5 total\\nThe expected information gain is\\nGain(Outlook) = 0.94 ‚àí\\n\\x12 5\\n14 ¬∑ I\\n\\x122\\n5, 3\\n5\\n\\x13\\n+ 4\\n14 ¬∑ I\\n\\x124\\n4, 0\\n4\\n\\x13\\n+ 5\\n14 ¬∑ I\\n\\x123\\n5, 2\\n5\\n\\x13\\x13\\n= 0.94 ‚àí\\n\\x12 5\\n14(0.971) + 4\\n14(0) + 5\\n14(0.971)\\n\\x13\\n= 0.94 ‚àí0.694\\n= 0.247.\\nThe correct answer is (B).\\nProblem:\\nWhat is the expected information gain if we select Humidity as the root\\nnode of the tree?\\n(A) 0.151\\n(B) 0.251\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 21 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 21}, page_content='CS 486/686\\nLecture 7\\n(C) 0.351\\n(D) 0.451\\n(E) 0.551\\nSolution:\\nTesting Humidity yields two branches:\\nHumidity =\\n(\\nNormal\\n6+\\n1‚àí\\n7 total\\nHigh\\n3+\\n4‚àí\\n7 total\\nThe expected information gain is\\nGain(Humidity) = 0.94 ‚àí\\n\\x12 7\\n14 ¬∑ I\\n\\x126\\n7, 1\\n7\\n\\x13\\n+ 7\\n14 ¬∑ I\\n\\x123\\n7, 4\\n7\\n\\x13\\x13\\n= 0.94 ‚àí\\n\\x12 7\\n14(0.592) + 7\\n14(0.985)\\n\\x13\\n= 0.94 ‚àí0.789\\n= 0.151.\\nThe correct answer is (A).\\nComparing Outlook and Humidity, the expected information gain of testing Outlook Ô¨Årst is\\ngreater than that of testing Humidity Ô¨Årst.\\nYou may also notice that the expected information gain at a node is always taken with\\nrespect to the entropy before the node, so when comparing features to test at that node\\nwe could simply ignore the entropy before testing and select the feature with the lowest\\npost-testing entropy.\\nExample:\\nHere is the continuation of the example. The calculations have been\\ncondensed, but you should verify them yourself.\\nFor the root node, we can choose from all four features to test:\\nGain(Outlook) = 0.247\\nGain(Humidity) = 0.151\\nGain(Temp) = 0.029\\nGain(Wind) = 0.048\\nWe pick Outlook since it has the greatest expected information gain.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 22 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 22}, page_content='CS 486/686\\nLecture 7\\nCase 1: Outlook = Sunny.\\n+ : 9, 11\\n‚àí: 1, 2, 8\\nTemp =\\n\\uf8f1\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\n\\uf8f3\\nHot\\n+ :\\n‚àí: 1, 2\\nMild\\n+ : 11\\n‚àí: 8\\nCool\\n+ : 9\\n‚àí:\\nGain(Temp) = I\\n\\x122\\n5, 3\\n5\\n\\x13\\n‚àí\\n\\x122\\n5 ¬∑ I\\n\\x120\\n2, 2\\n2\\n\\x13\\n+ 2\\n5 ¬∑ I\\n\\x121\\n2, 1\\n2\\n\\x13\\n+ 1\\n5 ¬∑ I\\n\\x121\\n1, 0\\n1\\n\\x13\\x13\\n= 0.97 ‚àí\\n\\x122\\n5(0) + 2\\n5(1) + 1\\n5(0)\\n\\x13\\n= 0.97 ‚àí0.4\\n= 0.57\\nHumidity =\\n(\\nHigh\\n+ :\\n‚àí: 1, 2, 8\\nNormal\\n+ : 9, 11\\n‚àí:\\nGain(Humidity) = I\\n\\x122\\n5, 3\\n5\\n\\x13\\n‚àí\\n\\x123\\n5 ¬∑ I\\n\\x120\\n3, 3\\n3\\n\\x13\\n+ 2\\n5 ¬∑ I\\n\\x122\\n2, 0\\n2\\n\\x13\\x13\\n= 0.97 ‚àí\\n\\x123\\n5(0) + 2\\n5(0)\\n\\x13\\n= 0.97 ‚àí0\\n= 0.97\\nWind =\\n(\\nWeak\\n+ : 9\\n‚àí: 11\\nStrong\\n+ : 1, 8\\n‚àí: 2\\nGain(Wind) = I\\n\\x122\\n5, 3\\n5\\n\\x13\\n‚àí\\n\\x123\\n5 ¬∑ I\\n\\x121\\n3, 2\\n3\\n\\x13\\n+ 2\\n5 ¬∑ I\\n\\x121\\n2, 1\\n2\\n\\x13\\x13\\n= 0.97 ‚àí\\n\\x123\\n5(0.918) + 2\\n5(1)\\n\\x13\\n= 0.97 ‚àí0.951\\n= 0.019\\nWe pick Humidity since it has the greatest expected information gain. This makes\\nsense since the positive and negative examples are completely separated after testing\\nHumidity.\\nCase 2: Outlook = Overcast.\\n+ : 3, 7, 12, 13\\n‚àí:\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 23 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 23}, page_content='CS 486/686\\nLecture 7\\nNo need to test further, since the examples are already classiÔ¨Åed.\\nCase 3: Outlook = Rain.\\n+ : 4, 5, 10\\n‚àí: 6, 14\\nTemp =\\n\\uf8f1\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\n\\uf8f3\\nHot\\n+ :\\n‚àí:\\nMild\\n+ : 4, 10\\n‚àí: 14\\nCool\\n+ : 5\\n‚àí: 6\\nGain(Temp) = I\\n\\x122\\n5, 3\\n5\\n\\x13\\n‚àí\\n\\x123\\n5 ¬∑ I\\n\\x122\\n3, 1\\n3\\n\\x13\\n+ 2\\n5 ¬∑ I\\n\\x121\\n2, 1\\n2\\n\\x13\\x13\\n= 0.97 ‚àí\\n\\x123\\n5(0.918) + 2\\n5(1)\\n\\x13\\n= 0.97 ‚àí0.951\\n= 0.019\\nHumidity =\\n(\\nHigh\\n+ : 4\\n‚àí: 14\\nNormal\\n+ : 5, 10\\n‚àí: 6\\nGain(Humidity) = I\\n\\x122\\n5, 3\\n5\\n\\x13\\n‚àí\\n\\x122\\n5 ¬∑ I\\n\\x121\\n2, 1\\n2\\n\\x13\\n+ 3\\n5 ¬∑ I\\n\\x122\\n3, 1\\n3\\n\\x13\\x13\\n= 0.97 ‚àí\\n\\x122\\n5(1) + 3\\n5(0.918)\\n\\x13\\n= 0.97 ‚àí0.951\\n= 0.019\\nWind =\\n(\\nWeak\\n+ : 4, 5, 10\\n‚àí:\\nStrong\\n+ :\\n‚àí: 6, 14\\nGain(Wind) = I\\n\\x122\\n5, 3\\n5\\n\\x13\\n‚àí\\n\\x123\\n5 ¬∑ I\\n\\x123\\n3, 0\\n3\\n\\x13\\n+ 2\\n5 ¬∑ I\\n\\x120\\n2, 2\\n2\\n\\x13\\x13\\n= 0.97 ‚àí\\n\\x123\\n5(0) + 2\\n5(0)\\n\\x13\\n= 0.97 ‚àí0\\n= 0.97\\nWe pick Wind since it has the greatest expected information gain. This makes sense\\nsince the positive and negative examples are completely separated after testing Wind.\\nThe Ô¨Ånal decision tree is drawn below:\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 24 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 24}, page_content='CS 486/686\\nLecture 7\\nOutlook\\nHumidity\\nNo\\nYes\\nYes\\nWind\\nYes\\nNo\\nSunny\\n+ : 9, 11\\n‚àí: 1, 2, 8\\nHigh\\n+ :\\n‚àí: 1, 2, 8\\nNormal\\n+ : 9, 11\\n‚àí:\\nOvercast\\n+ : 3, 7, 12, 13\\n‚àí:\\nRain\\n+ : 4, 5, 10\\n‚àí: 6, 14\\nWeak\\n+ : 4, 5, 10\\n‚àí:\\nStrong\\n+ :\\n‚àí: 6, 14\\nRecall that we wanted a shallow, small tree, and that‚Äôs exactly what we got.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 25 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 25}, page_content='CS 486/686\\nLecture 7\\n6\\nReal-Valued Features\\n6.1\\nJeeves dataset with real-valued temperatures\\nSo far, the decision tree learner algorithm only works when all of the features have discrete\\nvalues. In the real world, we are going to encounter a lot of data sets where many features\\nhave continuous values, or they‚Äôre real-valued. Let‚Äôs see how decision trees can handle them.\\nExample:\\nA more realistic Jeeves dataset with real-valued temperatures\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\n29.4\\nHigh\\nWeak\\nNo\\n2\\nSunny\\n26.6\\nHigh\\nStrong\\nNo\\n3\\nOvercast\\n28.3\\nHigh\\nWeak\\nYes\\n4\\nRain\\n21.1\\nHigh\\nWeak\\nYes\\n5\\nRain\\n20.0\\nNormal\\nWeak\\nYes\\n6\\nRain\\n18.3\\nNormal\\nStrong\\nNo\\n7\\nOvercast\\n17.7\\nNormal\\nStrong\\nYes\\n8\\nSunny\\n22.2\\nHigh\\nWeak\\nNo\\n9\\nSunny\\n20.6\\nNormal\\nWeak\\nYes\\n10\\nRain\\n23.9\\nNormal\\nWeak\\nYes\\n11\\nSunny\\n23.9\\nNormal\\nStrong\\nYes\\n12\\nOvercast\\n22.2\\nHigh\\nStrong\\nYes\\n13\\nOvercast\\n27.2\\nNormal\\nWeak\\nYes\\n14\\nRain\\n21.7\\nHigh\\nStrong\\nNo\\nInstead of having the temperature being a discrete feature, having three values: Mild,\\nHot, and Cool, we will use actual numbers for Temperature.\\nFor convenience, we will reorder the data set based on the value of the Temperature.\\nExample:\\nJeeves dataset ordered by temperatures\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 26 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 26}, page_content='CS 486/686\\nLecture 7\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n7\\nOvercast\\n17.7\\nNormal\\nStrong\\nYes\\n6\\nRain\\n18.3\\nNormal\\nStrong\\nNo\\n5\\nRain\\n20.0\\nNormal\\nWeak\\nYes\\n9\\nSunny\\n20.6\\nNormal\\nWeak\\nYes\\n4\\nRain\\n21.1\\nHigh\\nWeak\\nYes\\n14\\nRain\\n21.7\\nHigh\\nStrong\\nNo\\n8\\nSunny\\n22.2\\nHigh\\nWeak\\nNo\\n12\\nOvercast\\n22.2\\nHigh\\nStrong\\nYes\\n10\\nRain\\n23.9\\nNormal\\nWeak\\nYes\\n11\\nSunny\\n23.9\\nNormal\\nStrong\\nYes\\n2\\nSunny\\n26.6\\nHigh\\nStrong\\nNo\\n13\\nOvercast\\n27.2\\nNormal\\nWeak\\nYes\\n3\\nOvercast\\n28.3\\nHigh\\nWeak\\nYes\\n1\\nSunny\\n29.4\\nHigh\\nWeak\\nNo\\n6.2\\nHandling a discrete feature\\nBefore seeing how we can handle real-valued features, let‚Äôs review how we can handle a\\ndiscrete feature. We considered two options:\\n‚Ä¢ Allow multi-way splits.\\nThe tree becomes more complex than just if-then-else.\\nThe tree tends to be shallower.\\nThe expected information gain metric prefers a variable with a larger domain, because\\nwhen a variable has a larger domain we can split the data points into more sets, and\\nthere‚Äôs a higher chance to reduce entropy.\\n‚Ä¢ Restrict to binary splits.\\nThe tree is simpler and more compact.\\nThe tree tends to be deeper.\\nExample:\\nAs an extreme example, pretend that Day is an additional input feature\\nin the Jeeves dataset, then the expected information gain for splitting on day must be\\nthe largest. Since we have one example for each day, and we can make a deterministic\\ndecision right away after splitting on day. However, it clearly does not make sense to\\nuse day as a feature, as the resulting tree does not generalize to any other data sets.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 27 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 27}, page_content='CS 486/686\\nLecture 7\\n6.3\\nHandling a real-valued feature\\nFor handling a real-valued feature:\\n‚Ä¢ Discretize the feature (i.e., put the examples into buckets).\\nThis is easy to do, but we may lose valuable information as it is challenging to Ô¨Ågure\\nout good ranges beforehand.\\nThere is often no way to Ô¨Ågure out the optimal discretization while we are constructing\\nthe tree, which may lead to a more complex decision tree.\\n‚Ä¢ Allow multi-way splits.\\nMulti-way splits are impractical because the domain of the feature could be unbounded.\\n‚Ä¢ Restrict to binary splits.\\nDynamically choose the split points.\\nHowever, binary splits may test the same feature multiple times and make the tree\\nmuch deeper.\\nWe will limit ourselves to binary splits.\\n6.4\\nChoosing a split point for a real-valued feature\\nA na¬®ƒ±ve way to choose a split point is to Ô¨Årst sort the instances by the real-valued feature and\\nconsider each midpoint of two diÔ¨Äerent consecutive values as a possible split point. Then,\\nwe would calculate the expected information gain of each possible split points and pick one\\nwith the greatest expected information gain.\\nHowever, there may be too many possible points to consider if we use this method.\\nExample:\\nWith the modiÔ¨Åed Jeeves data set from before, there are 11 possible split\\npoints using the na¬®ƒ±ve method.\\nA smarter approach is as follows:\\n1. Sort the instances according to the real-valued feature.\\n2. Possible split points are values that are midway between two adjacent values that are\\ndiÔ¨Äerent.\\n3. Suppose that the feature changes from X to Y . Should we consider (X + Y )/2 as a\\npossible split point?\\n4. Let LX be all the labels for the examples where the feature takes the value X.\\n5. Let LY be all the labels for the examples where the feature takes the value Y .\\n6. If there exists a label a ‚ààLX and a label b ‚ààLY such that a Ã∏= b, then (X + Y )/2 is a\\npossible split point.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 28 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 28}, page_content='CS 486/686\\nLecture 7\\n7. Determine the expected information gain for each possible split point and choose the\\nsplit point with the largest gain.\\nExample: Using the modiÔ¨Åed Jeeves data set from before, consider the midway point\\nof X = 23.9 and Y = 26.6. Then LX = {Yes} and LY = {No}. Taking Yes = a ‚ààLX\\nand No = b ‚ààLY , we have a Ã∏= b, so (X + Y )/2 = 25.25 is a possible split point.\\nProblem:\\nFor the Jeeves training set, is the midpoint between 20.0 and 20.6 a\\npossible split point?\\n(A) Yes\\n(B) No\\nSolution:\\nThis is not a possible split point: L20.0 = {Yes} and L20.6 = {Yes}.\\nThe correct answer is (B).\\nProblem:\\nFor the Jeeves training set, is the midpoint between 21.1 and 21.7 a\\npossible split point?\\n(A) Yes\\n(B) No\\nSolution:\\nThis is a possible split point: L21.1 = {Yes} and L21.7 = {No}.\\nThe correct answer is (A).\\nProblem:\\nFor the Jeeves training set, is the midpoint between 21.7 and 22.2 a\\npossible split point?\\n(A) Yes\\n(B) No\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 29 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 29}, page_content='CS 486/686\\nLecture 7\\nSolution:\\nThis is a possible split point: L21.7 = {No} and L22.2 = {No, Yes}.\\nThe correct answer is (A).\\nIntuitively, you can understand this procedure as considering local changes at each midway\\npoint. If the target feature doesn‚Äôt change locally, that point probably isn‚Äôt a valuable split\\npoint.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 30 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 30}, page_content='CS 486/686\\nLecture 7\\n7\\nOver-Ô¨Åtting\\n7.1\\nCorrupted data in the Jeeves dataset\\nOver-Ô¨Åtting is a common problem when we‚Äôre learning a decision tree.\\nAs a model for\\nsupervised machine learning, a decision tree has several nice properties. Decision trees are\\nsimpler, they‚Äôre easy to understand and easy to interpret.\\nWhen it‚Äôs important to explain a model to another human being, a decision tree is a good\\nchoice. In contrast, a neural network is often complex and diÔ¨Écult or impossible to interpret.\\nAlso decision trees can produce a reasonable model even if you have a tiny data set. In\\ncontrast, a neural network often does not work at all with a small data set, and it is extremely\\nprone to over-Ô¨Åtting.\\nTherefore, even though decision trees have so many nice properties, over-Ô¨Åtting is still a\\ncommon problem when we‚Äôre constructing a decision tree.\\nExample:\\nThe Jeeves data set has 14 data points, this is an extremely small data\\nset; we can still learn a reasonable decision tree for this data set.\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nYes\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\nDecision tree generated by the learner algorithm:\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 31 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 31}, page_content='CS 486/686\\nLecture 7\\nOutlook\\nHumidity\\nNo\\nYes\\nYes\\nWind\\nYes\\nNo\\nSunny\\nHigh\\nNormal\\nOvercast\\nRain\\nWeak\\nStrong\\nTest error is 0 out of 14.\\nExample:\\nSuppose that you sent the training set and the test set to your friend.\\nFor some reason the data set gets corrupted during the transmission. Your friend gets\\na corrupted training set where only one data point is diÔ¨Äerent. For this third data,\\npoint, it changed from the label ‚Äùyes‚Äù to the label ‚Äùno‚Äù.\\nThis is a tiny change to the training set, but how would this change aÔ¨Äect the decision\\ntree that we generate?\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nNo\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\nDecision tree generated by the learner algorithm:\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 32 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 32}, page_content='CS 486/686\\nLecture 7\\nOutlook\\nHumidity\\nNo\\nYes\\nHumidity\\nYes\\nWind\\nNo\\nYes\\nWind\\nYes\\nNo\\nSunny\\nHigh\\nNormal\\nOvercast\\nNormal\\nHigh\\nWeak\\nStrong\\nRain\\nWeak\\nStrong\\nWe grew an entire middle sub-tree to accommodate one corrupted data point, and\\nthis small corruption caused a dramatic change to the tree. This new tree is more\\ncomplicated and it likely won‚Äôt generalize well to unseen data.\\nThe decision tree learner algorithm is a perfectionist. The algorithm will keep growing\\nthe tree until it perfectly classiÔ¨Åes all the examples in the training set. However, this\\nis not necessarily a desirable behavior and this can easily lead to over-Ô¨Åtting.\\nThe new test error is 2/14.\\n7.2\\nDealing with over-Ô¨Åtting with pruning\\nIt would be better to grow a smaller and shallower tree. The smaller and shallower tree may\\nnot predict all of the training data points perfectly but it may generalize to test data better.\\nAt a high level we have two options to prevent over-Ô¨Åtting when learning a decision tree:\\nPre-pruning: stop growing the tree early.\\nIf we decide not to split the examples at a node and stop growing the tree there, we may\\nstill have examples with diÔ¨Äerent labels. At this point, we can decide to use the majority\\nlabel as the decision for that leaf node. Here are some criteria we can use:\\n1. Maximum depth: We can decide not to split the examples if the depth of that node\\nhas reached a maximum value that we decided beforehand.\\n2. Minimum number of examples at the leaf node: We can decide not to split the examples\\nif the number of examples remaining at that node is less than a predeÔ¨Åned threshold\\nvalue.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 33 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 33}, page_content='CS 486/686\\nLecture 7\\n3. Minimum information gain: We can decide not to split the examples if the beneÔ¨Åt of\\nsplitting at that node is not large enough. We can measure the beneÔ¨Åt by calculating\\nthe expected information gain. In other words, do not split examples if the expected\\ninformation gain is less than the threshold.\\n4. Reduction in training error: We can decide not to split the examples at a node if the\\nreduction in training error is less than a predeÔ¨Åned threshold value.\\nFor pre-pruning, we will split the examples at a node only when it‚Äôs useful. We can use\\npre-pruning with any of the criteria above.\\nPost-pruning: grow a full tree Ô¨Årst and then trim it afterwards.\\nPost-pruning is particularly useful when any individual feature is not informative, but mul-\\ntiple features working together is very informative.\\nExample:\\nConsider a data set with two input features, both features are binary.\\nThe target feature is computing the XOR function of the two input features. That\\nmeans the target feature is true if and only if the two input features have diÔ¨Äerent\\nvalues.\\nFor this data set, each input feature alone tells us nothing about the value of the target\\nfeature. However, if you know both input features then you know the target feature\\nfor certain.\\nFor this example,\\n‚Ä¢ With pre-pruning,\\nWe will test none of the two input features, testing each feature gives us zero\\ninformation. So we‚Äôll end up with a tree that has only the root node and the\\ntree will predict the target feature randomly.\\n‚Ä¢ With post-pruning,\\nWe will end up growing the full tree Ô¨Årst which means testing both input features\\nin some order. Afterwards, we will try to see if we can prune any of the node.\\nIt turns out it‚Äôs not a good idea to prune any node, because the second input\\nfeature in the order is going to give us all the information that we need.\\nSo we will end up growing a full tree and the full tree will predict the target\\nfeature perfectly.\\nPost-pruning helps us recognize the cases with multiple features working together will be\\nvery beneÔ¨Åcial, but any of the features individually will not be very useful. We can apply\\npost-pruning to any of the criteria we have described above. Note that we will only decide\\nto post-prune a node if it has only leaf nodes as its descendants.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 34 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 34}, page_content='CS 486/686\\nLecture 7\\nExample:\\nSuppose we are considering post-pruning with the minimal information\\ngain metric.\\nFirst of all, we will restrict our attention to nodes that only have leaf nodes as its\\ndescendants.\\nAt a node like this, if the expected information gain is less than a\\npredeÔ¨Åned threshold value, we will delete this node‚Äôs children which are all leaf nodes\\nand then convert this node to a leaf node.\\nThere has to be examples with diÔ¨Äerent labels at this node possibly both positive and\\nnegative examples. We can make a majority decision at this node.\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 35 of 36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.20', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-02T01:46:06+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2021-11-02T01:46:06+00:00', 'trapped': '', 'modDate': 'D:20211102014606Z', 'creationDate': 'D:20211102014606Z', 'page': 35}, page_content='CS 486/686\\nLecture 7\\n8\\nPractice Problems\\n1. When learning the tree, we chose a feature to test at each step by maximizing the ex-\\npected information gain. Does this approach allow us to generate the optimal decision\\ntree? Why or why not?\\n2. Consider a data-set with real-valued features. Suppose that we perform binary splits\\nonly when building a decision tree.\\nIs it possible to encounter the ‚Äúno features left‚Äù base case? Why?\\nIs it possible to encounter the ‚Äúno examples left‚Äù base case? Why?\\n3. What is the main advantage of post-pruning over pre-pruning?\\nc‚ÉùAlice Gao 2021\\nv1.0\\nPage 36 of 36'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 0}, page_content='NEURAL NETWORKS \\n \\n1.0.0 Introduction \\nThe recent rise of interest in neural networks has its roots in the recognition that the \\nbrain performs computations in a different manner than do conventional digital computers. \\nComputers are extremely fast and precise at executing sequences of instructions that have \\nbeen formulated for them. A human information process sing system is composed of \\nneurons switching at speeds about a million times slower than computer gates. Yet, humans \\nare more efficient than computers at computationally complex tasks such as speech \\nunderstanding. Moreover, not only humans, but also even animals, can process visual \\ninformation better than the fastest computers. \\nArtificial neural systems, or neural networks (NN), are physical cellular systems, \\nwhich can acquire, store, and utilize experiential knowledge. The knowledge is in the form \\nof stable states or mappings embedded in networks that can be recalled in response to the \\npresentation cues. Neural network processing typically involves dealing with large-scale \\nproblems in terms of dimensionality, amount of data handled, and the volume of simulation \\nor neural hardware processing. This large-scale approach is both essential and typical for \\nreal-life applications. By keeping view of all these, the research community has made an \\neffort in designing and implementing the various neural network models for different \\napplications. Now let us formally define the basic idea of neural network: \\nDefinition: A neural network is a computing system made up of a number of \\nsimple, highly interconnected nodes or processing elements, which process information \\nby its dynamic state response to external inputs. \\n1.1.0 Humans and Computers \\nHuman beings are more intelligent than computers.  Computers could only do logical \\nthings well.  But in case of solving cross word puzzles, vision problem, controlling an arm to \\npick it up or something similar, that requires exceptionally complex techniques. Like these \\nproblems, human beings do better than computers. \\n \\nComputers are designed to carry out one instruction after another, extremely rapid, \\nwhereas our brains work with many slower units.  Whereas a computer can typically carry \\nout a few million operations every second, the units in the brain respond about ten per \\nsecond.  However, they work on many different things at once, which computer can‚Äôt do. \\n \\nThe computer is a high-speed, serial machine and is used as such, compared to the \\nslow, highly parallel nature of the brain. Counting is an essentially serial activity, as is'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 1}, page_content='adding, with the thing done one after another, and so the computer can beat the brain any \\ntime.  For vision, or speech recognition, the problem is a highly parallel one, with many \\ndifferent and conflicting inputs, triggering many different and conflicting ideas and \\nmemories, and it is only the combining of all these different factors that allow us to perform \\nsuch feats, but then, our brains are able to operate in parallel easily and so we leave the \\ncomputers far behind. \\n \\nThe conclusion that we can reach from all of this is that the problems that we are \\ntrying to solve are immensely parallel ones. \\n1.2.0 History of artificial neural networks \\n‚Ä¢ The field of neural networks is not new. The first formal definition of a synthetic \\nneuron model based on the highly simplified considerations of the biological model \\nproposed by McCulloch and Pitts in 1943. The McCulloch-Pitts (MP) neuron model \\nresembles what is known as a binary logic device.  \\n‚Ä¢ The next major development, after the MP neuron model was proposed, occurred in \\n1949, when D.O. Hebb proposed a learning mechanism for the brain that become the \\nstarting point for artificial neural networks (ANN) learning (training) algorithms. He \\npostulated that as the brain learns, it changes its connectivity patterns. \\n‚Ä¢ The idea of learning mechanism was first incorporated in ANN by E. Rosenblatt \\n1958. \\n‚Ä¢ By introducing the least mean squares (LMS) learning algorithm, Widrow and Hoff \\ndeveloped in 1960 a model of a neuron that learned quickly and accurately. This \\nmodel was called ADALINE for ADAptive LInear NEuron. The applications of \\nADALINE and its extension to MADALINE (for Many ADALINES) include pattern \\nrecognition, weather forecasting, and adaptive controls. The monograph on learning \\nmachines by Nils Nilsson (1965) summarized the developments of that time. \\n‚Ä¢ In 1969, research in the field of ANN suffered a serious setback. Minsky and Papert \\npublished a book on perceptrons in which they proved that single layer neural \\nnetworks have limitations in their abilities to process data, and are capable of any \\nmapping that is linearly separable. They pointed out, carefully applying mathematical \\ntechniques, that are logical Exclusive-OR (XOR) function could not be realized by \\nperceptrons. \\n‚Ä¢ Further, Minsky and Papert argued that research into multi-layer neural networks \\nwould be unproductive. Due to this pessimistic view of Minsky and Papert, the field'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 2}, page_content='of ANN entered into an almost total eclipse for nearly two decades. Fortunately, \\nMinsky and Papert‚Äôs judgment has been disapproved; multi-layer perceptron networks \\ncan solve all nonlinear separable problems. \\n‚Ä¢ Nevertheless, a few dedicated researchers such as Kohonen, Grossberg, Anderson and \\nHopfield continued their efforts. \\n‚Ä¢ The study of learning in networks of threshold elements and of the mathematical \\ntheory of neural networks was pursued by Sun - Ichi ‚Äì Amari (1972, 1977). Also \\nKunihiko Fukushima developed a class of neural network architectures known as \\nneocognitrons in 1980. \\n‚Ä¢ There have been many impressive demonstrations of ANN capabilities: a network has \\nbeen trained to convert text to phonetic representations, which were then converted to \\nspeech by other means (Sejnowsky and Rosenberg 1987); other network can \\nrecognize handwritten characters (Burr 1987); and a neural network based image-\\ncompression system has been devised (Cottrell, Munro, and Zipser 1987). These all \\nuse the backpropagation network, perhaps the most successful of the current \\nalgorithms. Backpropagation, invented independently in three separate research \\nefforts (Werbos 1974, Parker 1982, and Rumelhart, Hinton and Williams 1986) \\nprovides a systematic means for training multi-layer networks, thereby overcoming \\nlimitations presented by Minsky. \\n1.3.0 Characteristics of ANN \\nArtificial neural networks are biologically inspired; that is, they are composed of \\nelements that perform in a manner that is analogous to the most elementary functions of the \\nbiological neuron. The important characteristics of artificial neural networks are learning \\nfrom experience, generalize from previous examples to new ones, and abstract essential \\ncharacteristics from inputs containing irrelevant data. \\n1.3.1 Learning  \\nThe NNs learn by examples. Thus, NN architectures can be ‚Äòtrained‚Äô with known \\nexamples of a problem before they are tested for their ‚Äòinference‚Äô capability on unknown \\ninstances of the problem. They can, therefore, identify new objects previously untrained. \\nANN can modify their behavior in response to their environment. Shown a set of inputs \\n(perhaps with desired outputs), they self-adjust to produce consistent responses. A wide \\nvariety of training algorithms has been discussed in later units.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 3}, page_content='1.3.2 Parallel operation \\nThe NNs can process information in parallel, at high speed, and in a distributed \\nmanner. \\n1.3.3 Mapping \\nThe NNs exhibit mapping capabilities, that is, they can map input patterns to their associated \\noutput patterns. \\n1.3.4 Generalization \\nThe NNs possess the capability to generalize. Thus, they can predict new outcomes \\nfrom past trends. Once trained, a network‚Äôs response can be to a degree, insensitive to minor \\nvariations in its input. This ability to see through noise and distortion to the pattern that lies \\nwithin is vital to pattern recognition in a real-world environment. It is important to note that \\nthe ANN generalizes automatically as a result of its structure, not by using human \\nintelligence embedded in the form of adhoc computer programs. \\n1.3.5 Robust \\nThe NNs are robust systems and are fault tolerant. They can, therefore, recall full \\npatterns from incomplete, partial or noisy patterns \\n1.3.6 Abstraction  \\n       Some ANN‚Äôs are capable of abstracting the essence of a set of inputs. i.e. they can \\nextract features of the given set of data, for example, convolution neural networks are used to \\nextract different features from images like edges, dark spots, shapes ..etc. Such networks are \\ntrained for feature patterns based on which they can classify or cluster the given input set. \\n \\n \\n1.3.7 Applicability \\nANN‚Äôs are not a panacea. They are clearly unsuited to such tasks as calculating the \\npayroll. They are preferred for a large class of pattern-recognition tasks that conventional \\ncomputers do poorly, if at all. \\n1.4.0 Applications \\nNeural networks are preferred when the task is related to large-amount data processing. The \\nfollowing are the potential applications of neural networks: \\n‚Ä¢ Classification'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 4}, page_content='‚Ä¢ Prediction \\n‚Ä¢ Data Association \\n‚Ä¢ Data Conceptualization \\n‚Ä¢ Data Filtering \\n‚Ä¢ Optimization \\nIn addition to the above fields, neural networks can apply to the fields of Medicine, \\nCommercial and Engineering, etc. \\n2.1.0 The Biological Prototype \\nANN‚Äôs are biologically inspired; that is viewing at the organization of the brain \\nconsidering network configurations and algorithms. The human nerve system, built of cells \\ncalled neurons is of staggering complexity. It contains approximately ten thousand million \\n(1011) basic neurons.  Each of these neurons is connected to about ten thousand (104) others. \\nThe connection of each neuron with other neurons forms a densely network called a neural \\nnetwork. These massive interconnections provide an exceptionally large computing power \\nand memory. The neuron accepts many inputs, which are all added up in some fashion.  If \\nenough active inputs are received at once, then the neuron will be activated at once, then the \\nneuron will be activated and ‚Äúfire‚Äù; if not, then the neuron will remain in its inactive, quit \\nstate. The schematic diagram of biological neuron is shown in Fig.2.1. From a systems \\ntheory, the neuron considered to be as a multiple-input-single-output (MISO) system as \\nshown in Fig.2.2. \\n \\nFig. 2.1. A Schematic view of the biological neuron'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 5}, page_content='Fig.2.2 Model representation of a biological neuron with multiple inputs \\nHuman \\nArtificial \\nNeuron \\nProcessing Element    \\nDendrites \\nCombining Function   \\nCell Body  \\nTransfer Function    \\nAxons \\nElement Output    \\nSynapses \\nWeights \\n \\nThe soma is the body of the neuron.  Attached to the soma there are long irregularly \\nshaped filaments, called dendrites.  These nerve processes are often less than a micron in \\ndiameter, and have complex branching shapes.  The dendrites act as the connections through \\nwhich all the inputs to the neuron arrive.  These cells are able to perform more complex \\nfunctions than simple addition on the inputs they receive, but considering simple summation \\nis a reasonable approximation. \\n \\nAnother type of nerve process attached to the soma is called an axon.  This is \\nelectrically active, unlike the dendrite, and serves as the output channel of the neuron.  Axons \\nalways appear on output cell, but are often absent from interconnections, which have both \\ninputs and outputs on dendrites.  The axon is a non-linear threshold device, producing a \\nvoltage pulse, called an action potential, that last about 1 millisecond (10-3 sec) when the \\nresting potential within the soma rises above a certain critical threshold. \\n \\nThe axon terminates in a specialized contact called a synapse that couples the axon \\nwith the dendrite of another cell.  There is no direct linkage across the junction; rather, it is \\ntemporally chemical one.  The synapse releases chemicals called neurotransmitters when its \\npotential is raised sufficiently by the action potential.  It may take the arrival of more than \\none action potential before the synapse is triggered.  The neurotransmitters that are released \\nby the synapse diffuse across the gap, any chemically activate gates on the dendrites, which, \\nwhen open, allow charged ions to flow.  It is this flow of ions that alters the dendrite \\npotential, and provides a voltage pulse on the dendrite, which is then conducted along into the'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 6}, page_content='next neuron body.  Each dendrite may have many synapses acting on it, allowing massive \\ninterconnectivity to be achieved. \\n2.2.0 Artificial Neuron \\nThe artificial neuron is developed to mimic the first-order characteristics of the \\nbiological neuron. In similar to the biological neuron, the artificial neuron receives many \\ninputs representing the output of other neurons. Each input is multiplied by a corresponding \\nweight, analogous to the synaptic strength. All of these weighted inputs are then summed and \\npassed through an activation function to determine the neuron input.  This artificial neuron \\nmodel is shown in Fig.2.3. \\n \\nFig. 2.3 An artificial neuron \\nThe mathematical model of the artificial neuron may written as  \\n \\nu(t) =   w1x1 + w2x2 + w3x3+ . . . . . . . . . + wnxn \\n \\n       =\\n1\\n+Œ∏\\nn\\ni\\ni\\ni\\nw x\\n=\\uf0e5\\n = \\n\\uf0e5\\n=\\nn\\ni\\ni\\ni x\\nw\\n0\\n \\n \\n \\n \\n \\n(2.1) \\nAssuming w0 = \\uf071  and x0  = 1 \\ny(t) = f [u(t)]  \\n \\n \\n \\n \\n \\n \\n(2.2) \\nwhere f[.] is a nonlinear function called as the activation function, the input-output function \\nor the transfer function. In equation (2.1) and Fig.2.3, [x0, x1,  ‚Ä¶., xn] represent the inputs, \\n[w0, w1, . . .  . , wn] represents the corresponding synaptic weights. In vector form, we can \\nrepresent the neural inputs and the synaptic weights as  \\nX = [x0, x1,  ‚Ä¶., xn]T , and  W = [w0, w1, . . .  . , wn] \\nEquations (2.1) and (2.2) can be represented in vector form as: \\nU = WX \\n \\n \\n \\n \\n \\n \\n \\n(2.3) \\nY = f[U] \\n \\n \\n \\n \\n \\n \\n \\n(2.4) \\n \\nThe activation function f[.] is chosen as a nonlinear function to emulate the nonlinear \\nbehavior of conduction current mechanism in biological neuron. The behavior of the artificial \\nneuron depends both on the weights and the activation function. Sigmoidal functions are the'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 7}, page_content='commonly used activation functions in multi-layer static neural networks. Other types of \\nactivation functions are discussed in later units. \\n2.0.0 McCulloch-Pitts Model \\nThe McCulloch-Pitts model of the neuron is shown in Fig. 2.4(a). The inputs xi , for i= 1,2, . . \\n.,n are 0 or 1, depending on the absence or presence of the input impulse at instant k. The \\nneuron‚Äôs output signal is denoted as Y.  The firing rule for this model is defined as follows \\nYk+1 = \\n\\uf0ef\\n\\uf0ef\\n\\uf0ee\\n\\uf0ef\\uf0ef\\n\\uf0ed\\n\\uf0ec\\n\\uf03c\\n\\uf0b3\\n\\uf0e5\\n\\uf0e5\\n=\\n=\\nn\\ni\\nk\\ni\\ni\\nn\\ni\\nk\\ni\\ni\\nT\\nx\\nw\\nif\\nT\\nx\\nw\\nif\\n1\\n1\\n0\\n1\\n1 \\nwhere super script k = 0,1,2,. . . . , denotes the discrete ‚Äì time instant, and wi is the \\nmultiplicative weight connecting the i‚Äôth input with the neuron‚Äôs membrane. Note that wi = \\n+1 for excitatory synapses, wi = -1 for inhibitory synapses for this model, and T is the \\nneuron‚Äôs threshold value, which needs to be exceeded by the weighted sum of the signals for \\nthe neuron to fire. \\nThis model can perform the basic operations NOT, OR and AND, provided its weights and \\nthresholds are approximately selected. Any multivariable combinational function can be \\nimplemented using either the NOT and OR, or alternatively the NOT and AND, Boolean \\noperations. Examples of three-input NOR and NAND gates using the McCulloch-Pitts neuron \\nmodel are shown in (Fig.2.4 (b) and Fig 2.4(c)).  \\n \\n \\n \\n \\nFig.2.4 McCulloch-Pitts \\n \\n2.1.0 Keyword definitions'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 8}, page_content='Action potential: The pulse of electrical potential generated across the membrane of a \\nneuron (or an axon) following the application of a stimulus greater than threshold value. \\nAxon: The output fiber of a neuron, which carries the information in the form of action \\npotentials to other neurons in the network. \\nDendrite: The input line of the neuron that carries a temporal summation of action potentials \\nto the soma. \\nExcitatory neuron: A neuron that transmits an action potential that has excitatory (positive) \\ninfluence on the recipient nerve cells. \\nInhibitory neuron: A neuron that transmits an action potential that has inhibitory (negative) \\ninfluence on the recipient nerve cells. \\nLateral inhibition: The local spatial interaction where the neural activity generated by one \\nneuron is suppressed by the activity of its neighbors. \\nLatency: The time between the application of the stimulus and the peak of the resulting \\naction potential output. \\nRefractory period: The minimum time required for the axon to generate two consecutive \\naction potentials.  \\nNeural state: A neuron is active if it‚Äôs firing a sequence of action potentials. \\nNeuron: The basic nerve cell for processing biological information. \\nSoma: The body of a neuron, which provides aggregation, thresholding and nonlinear \\nactivation to dendrite inputs. \\n Synapse: The junction point between the axon (of a pre-synaptic neuron) and the dendrite \\n(of a post-synaptic neuron). This acts as a memory (storage) to the past-accumulated \\nexperience (knowledge). \\nActivation Functions \\n3.1.0 Operations of Artificial Neuron \\nThe schematic diagram of artificial neuron is shown in Fig.3.1.  The artificial neuron \\nmainly performs two operations, one is the summing of weighted net input and the second is \\npassing the net input through an activation function. The activation function also called \\nnonlinear function and some time transfer function of artificial neuron.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 9}, page_content=\"The net input of jth  neuron may be written as  \\nNETj = w1x1 + w2x2 + w3x3+ .. . . + wnxn +\\uf071j     (3.1) \\nwhere \\uf071j is the threshold of jth neuron, \\n \\nFig. 3.1 Artificial neuron. \\nX = [x1 x2 . . .  xn] in the input vector and W = [w1  w2 . . . wn] is the synaptic weight vector. \\nThe NETj signal is processed by an activation function F to produce the neuron‚Äôs output \\nsignal.  \\n          OUTj = F(NETj) \\n \\n \\n \\n \\n \\n \\n(3.2) \\nWhat functional form for F(.) should be selected? Can it be ‚Äì square root, log, ex , x3 \\nand so on. Mathematicians and computer scientists, however, have found that, the sigmoid \\n(S-shaped) function is more useful. In addition to this sigmoid function, there are number of \\nother function are using in artificial neural networks. They are discussed in the next section. \\n3.2.0 Types of activation functions \\n       The behavior of the artificial neuron depends both on the synaptic weights and the \\nactivation function. Sigmoid functions are the commonly used activation functions in multi-\\nlayered feed forward neural networks. Neurons with sigmoid functions bear a greater \\nresemblance to the biological neurons than with other activation functions. The other feature \\nof sigmoid function is that it is differentiable, and gives a continuous values output. Some of \\nthe popular activation functions are described below along with their other characteristics.  \\n1. Sigmoid function ( Unipolar sigmoid) . The characteristics of this function is shown in \\nFig.3.2 and its mathematical description is  \\ny(x) = f(x) = \\nx\\ne‚àí\\n+\\n1\\n1\\n  \\n \\n(3.1) \\nand its range of signal is 0<y<1. \\nThe derivative of the above function is \\nwritten as  \\n    \\n)\\n(\\ny' x  = \\n)\\n(\\nf ' x  = f(x) (1-f(x)) \\n(3.2) \\n \\nFig.3.2 A sigmoid (S-shaped) function\"),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 10}, page_content='Moreover, sigmoid functions are continuous and monatonic, and remain finite even as x \\napproaches to \\uf0b1\\uf0a5. Because they are monatonic, they also provide for more efficient \\nnetwork training.  \\n2. \\nHyperbolic tangent (bipolar sigmoid) function. The characteristics of this function is \\nshown in Fig.3.3 and its mathematical description is  \\ny(x)=f(x)=\\nx\\nx\\nx\\nx\\ne\\ne\\ne\\ne\\nx\\n‚àí\\n‚àí\\n+\\n‚àí\\n=\\n)\\ntanh(\\n     (3.3) \\nrange of signal is -1<y<1 and its \\nderivative can be obtained as  \\n = f‚Äô(x) =  1-[f(x)]2        (3.4) \\n \\nFig.3.3 A hyperbolic tangent (bipolar sigmoid) function  \\n3. \\nRadial basis function:  The Gaussian function is the most commonly used ‚Äú radially \\nsymmetric‚Äù function, the characteristics of this function is shown in Fig.3.4 and its \\nmathematical description is  \\ny = f(x) = \\n)\\n2\\nexp(\\n2\\nx\\n‚àí\\n  (3.5) \\nRange of signal is 0<y<1 and its \\nderivative can be obtained as  \\ny‚Äô= f‚Äô(x) = -x \\n)\\n2\\nexp(\\n2\\nx\\n‚àí\\n \\n(3.6) \\n \\nFig.3.4. A Gaussian function \\n \\nThe function has maximum response, f(x) =1, when the input is x=0, and the response \\ndecreases to f(x)=0 as the input approaches x=\\uf0b1\\uf0a5. \\n4. Hard Limiter:  The hard limiter function is the mostly used in classification of patterns, \\nthe characteristics of this function is shown in Fig.3.5 and its mathematical description is  \\nf(u(t))= sign (u(t)) = \\n\\uf0ee\\n\\uf0ed\\n\\uf0ec\\n\\uf03c\\n\\uf03e\\n+\\n0 \\n \\nu(t)\\n  \\n          \\n1\\n-\\n0\\n \\nu(t)\\n         \\n, 1\\n \\n         (3.7) \\n \\nFig. 3.5 Hard Limiter \\nThis function is not differentiable. Therefore it cannot be used for continuation type of \\napplications.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 11}, page_content='5. Piecewise linear:  The piecewise linear function characteristics is shown in Fig.3.6 and \\nits mathematical description is  \\n\\uf0ef\\uf0ee\\n\\uf0ef\\uf0ed\\n\\uf0ec\\n\\uf03c\\n\\uf03c\\n\\uf03e\\n+\\n=\\n1\\n- \\ngu  \\n  \\nif\\n       \\n1\\n-\\n1 \\n  \\ngu\\n \\nif\\ngu      \\n1 \\ngu \\n   \\nif\\n      \\n1\\n  \\n  \\n))\\n(\\n(\\nt\\nu\\nf\\n          (3.8) \\n \\nFig. 3.6 Piecewise linear \\n6. Linear:  The Linear function characteristics is shown in Fig.3.8 and its mathematical \\ndescription is  \\n       f(u(t)) = gu(t) \\n \\n(3.10) \\n \\nFig. 3.8 Linear function  \\nIt is differentiable and is mostly used for output nodes of the networks.  \\n3.3.0 Selection of activation function \\nThe selection of an activation function is depends upon the application to which the \\nneural network used and also the level (in which layer) neuron. The activation functions that \\nare mainly used are the sigmoid (unipolar sigmoidal), the hyperbolic tangent (bipolar \\nsigmoid), radial basis function, hard limiter and linear functions.  The sigmoid and hyperbolic \\ntangent functions perform well for the prediction and the process-forecasting types of \\nproblems. However, they do not perform as well for classification networks. Instead, the \\nradial basis function proves more effective for those networks, and highly recommended \\nfunction for any problems involving fault diagnosis and feature categorization. The hard \\nlimiter suits well for classification problems. The linear function may be used at output layer \\nin feed forward networks. \\n \\nClassification of Artificial Neural Networks \\n \\n4.0.0 Introduction \\n   \\nThe development of artificial neuron based on the understanding of the biological \\nneural structure and learning mechanisms for required applications. This can be summarized \\nas (a) development of neural models based on the understanding of biological neurons, (b) \\nmodels of synaptic connections and structures, such as network topology and (c) the learning'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 12}, page_content='rules. Researchers are explored different neural network architectures and used for various \\napplications.  Therefore the classification of artificial neural networks (ANN) can be done \\nbased on structures and based on type of data.  \\n  \\nA single neuron can perform a simple pattern classification, but the power of neural \\ncomputation comes from neuron connecting networks.  The basic definition of artificial \\nneural networks as physical cellular networks that are able to acquire, store and utilize \\nexperimental knowledge has been related to the network‚Äôs capabilities and performance. The \\nsimplest network is a group of neurons are arranged in a layer. This configuration is known \\nas single layer neural networks. There are two types of single layer networks namely, feed-\\nforward and feedback networks.  The single linear neural (that is activation function is linear) \\nnetwork will have very limited capabilities in solving nonlinear problems, such as \\nclassification etc., because their decision boundaries are linear. This can be made little more \\ncomplex by selecting nonlinear neuron (that is activation function is nonlinear) in single layer \\nneural network. The nonlinear classifiers will have complex shaped decision boundaries, \\nwhich can solve complex problems. Even nonlinear neuron single layer networks will have \\nlimitations in classifying more close nonlinear classifications and fine control problems. In \\nrecent studies shows that the nonlinear neural networks in multi-layer structures can simulate \\nmore complicated systems, achieve smooth control, complex classifications and have \\ncapabilities beyond those of single layer networks. In this unit we discuss first classifications, \\nsingle layer neural networks and multi-layer neural networks. The structure of a neural \\nnetwork refers to how its neurons are interconnected. \\n4.2.0 Applications \\n    Having different types artificial neural networks, these networks can be used to broad \\nclasses of applications, such as (i) Pattern Recognition and Classification, (ii) Image \\nProcessing and Vision, (iii) System Identification and Control, and (iv) Signal Processing.  \\nThe details of suitability of networks as follows: \\n(i) \\nPattern Recognition and Classification: Almost all networks can be used to \\nsolve these types of problems. \\n(ii) \\nImage Processing and Vision: The following networks are used for the \\napplications in this area:  Static single layer networks, Dynamic single layer \\nnetworks, BAM, ART, Counter ‚Äì propagation networks, First ‚Äì Order dynamic \\nnetworks.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 13}, page_content=\"(iii) \\nSystem Identification and Control: The following networks are used for the \\napplications in this area: Static multi layer networks, Dynamic multi layer \\nnetworks of types time-delay and Second-Order dynamic networks.  \\n(iv) \\nSignal Processing: The following networks are used for the applications in this \\narea: Static multi layer networks of type RBF, Dynamic multi layer networks of \\ntypes Cellular and Second-Order dynamic networks.  \\n4.3.0 Single Layer Artificial Neural Networks \\nThe simplest network is a group of neuron arranged in a layer. This configuration is \\nknown as single layer neural networks. This type of network comprises of two layers, namely \\nthe input layer and the output layer. The input layer neurons receive the input signals and the \\noutput layer neurons receive the output signals. The synaptic links carrying the weights \\nconnect every input neuron to the output neuron but not vice-versa. Such a network is said \\nto'be feedforward in type or acyclic in nature. Despite the two layers, the network is termed \\nsingle layer, since it is the output layer alone Which performs computation. The input layer \\nmerely transmits the signals to the output layer. Hence, the name single layer feedforward \\nnetwork. Figure 4.2 illustrates an example network. \\n There are two types of single layer networks namely, feed-forward and feedback \\nnetworks. \\n4.3.1 Feed forward single layer neural network \\n   \\nConsider m numbers of neurons are arranged in a layer structure and each neuron \\nreceiving n inputs as shown in Fig.4.2. \\nOutput and input vectors are respectively \\n \\nO = [o1  o2  . . .    om]T  \\n \\n \\n \\n \\n \\n(4.1) \\n \\nX = [x1  x2   . . .    xn]T \\n \\nWeight wji connects the jth  neuron with the ith input. Then the activation value for jth neuron \\nas  \\nnetj  =  \\uf0e5\\n=\\nn\\ni\\ni\\njix\\nw\\n1\\n \\n \\nfor j = 1,2, ‚Ä¶ m \\n \\n \\n(4.2) \\nThe following nonlinear transformation involving the activation function f(netj), for j=1,2,. . \\n.m, completes the processing of X. The transformation will be done by each of the m neurons \\nin the network. \\n  oj  = f(\\nX\\nW t\\nj\\n),  \\n \\nfor j = 1, 2,  . . . m \\n \\n \\n(4.3)\"),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 14}, page_content='where weight vector wj contains weights leading toward the jth output node and is defined as \\nfollows \\n \\nWj   =  [ wj1   wj2   . . .   wjn]   \\n \\n \\n \\n \\n(4.4) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFig. 4.2 Feed forward single layer neural network \\n \\nIntroducing the nonlinear matrix operator F, the mapping of input space X to output space O \\nimplemented by the network can be written as  \\nO = F (W X)  \\n \\n \\n \\n \\n \\n \\n(4.5a) \\nWhere W is the weight matrix and also known as connection matrix and is represented as  \\nW = \\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n2\\n1\\n2\\n22\\n21\\n1\\n12\\n11\\nmn\\nm\\nm\\nn\\nn\\nw\\nw\\nw\\nw\\nw\\nw\\nw\\nw\\nw\\n  \\n \\n \\n \\n(4.5b) \\nThe weight matrix will be initialized and it should be finalized through appropriate \\ntraining method. \\nF (.)  = \\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n.\\n(.)\\n.\\n.\\n0\\n0\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n0\\n.\\n.\\n(.)\\n0\\n0\\n.\\n.\\n0\\n(.)\\nf\\nf\\nf\\n \\n \\n \\n \\n(4.5c) \\nW \\nX \\n \\nF \\nO \\n(b) Block diagram of single layer network'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 15}, page_content='The nonlinear activation function f(.) on the diagonal of the matrix operator  F(.) operates \\ncomponent-wise on the activation values net of  each neuron.  Each activation value is, in \\nturn, a scalar product of an input with the respective weight vector, X is called input vector \\nand O is called output vector. The mapping of an input to an output is shown as in (4.5) is of \\nthe feed-forward and instantaneous type, since it involves no delay between the input  and the \\noutput . Therefore the relation (4.5a) may be written in terms of time t as \\n \\nO (t) = F (W X(t)) \\n \\n \\n \\n \\n \\n(4.6) \\nThis type of networks can be connected in cascade to create a multiplayer network. Though \\nthere is no feedback in the feedforward network while mapping from input X(t) to output \\nO(t),  the output values are compared with the ‚Äúteachers‚Äù information, which provides the \\ndesired output values. The error signal is used for adapting the network weights. The details \\nabout will be discussed in later units.  \\nExample: To illustrate the computation of output O(t), of the single layer feed forward \\nnetwork consider an input vector X(t) and a network weight matrix W (say initialized \\nweights), given below. Consider the neurons uses the hard limiter as its activation function.   \\nX = [-1  1  -1]T  \\n \\nW = \\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n‚àí\\n‚àí\\n‚àí\\n‚àí\\n3\\n1\\n0\\n0\\n1\\n0\\n2\\n0\\n1\\n1\\n0\\n1\\n \\nThe out vector may be obtained from the (4.5) as  \\nO = F (W X)    = [ sgn(-1-1)  sgn(+1+2)  sgn(1)  sgn(-1+3) ] \\n   = [ -1  1  1  1] \\nThe output vector of the above single layer feedforward network is    = [ -1  1  1  1]. \\n \\n4.4 Types of connections \\n \\nThere are three different options are available for connecting nodes to one \\nanother, as shown in Fig. 4.5 They are: \\n Intralayer connection: The output from a node fed into other nodes in the same layer. \\nInterlayer connection: The output from a node in one layer fed into nodes in other layer. \\nRecurrent connection: The outputs from a node fed into itself.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 16}, page_content='Fig. 4.5 Different connection option of Neural Networks \\n \\nIn general, when building a neural network its structure will be specified. In \\nengineering applications, suitable and mostly preferred structure is the interlayer connection \\ntype topology. Within the interlayer connections, there are two more options: (i) feed forward \\nconnections and (ii) feedback connections, as shown in Fig. 4.6. \\n \\nFig. 4.6 Feed forward and feed back connections of Neural Networks \\n4.4.0 Multi Layer Artificial Neural Networks \\n \\nCascading a group of single layers networks can form the feed forward neural \\nnetwork. This type networks also known as feed forward multi layer neural network. In \\nwhich, the output of one layer provides an input to the subsequent layer. The input layer gets \\ninput from outside; the output of input layer is connected to the first hidden layer as input. \\nThe output layer receives its input from the last hidden layer.  The multi layer neural network \\nprovides no increase in computational power over single layer neural networks unless there is \\na nonlinear activation function between layers. Therefore, due to nonlinear activation \\nfunction of each neuron in hidden layers, the multi layer neural networks able to solve many \\nof the complex problems, such as, nonlinear function approximation, learning generalization, \\nnonlinear classification etc. \\n \\nA multi layer neural network consists of input layer, output layer and hidden layers. \\nThe number of nodes in input layer depends on the number of inputs and the number of nodes \\nin the output layer depends upon the number of outputs. The designer selects the number of \\nhidden layers and neurons in respective layers. According to the Kolmogorov‚Äôs theorem \\nsingle hidden layer is sufficient to map any complicated input ‚Äì output mapping.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 17}, page_content='Fig. 4.7. Multilayer feedforward network \\nRecurrent Networks \\nThese networks differ from feedforward network architectures in the sense that there \\nis atleast one feedback loop. Thus, in these networks, for example, there could exist .one \\nlayer with feedback connections as shown in Fig. 4.8. There could also be neurons with self-\\nfeedback links, i.e. the output of a neuron is fed back into itself as input. \\nThe idea behind RNNs is to make use of sequential information. In a traditional \\nneural network we assume that all inputs (and outputs) are independent of each other. But for \\nmany tasks that‚Äôs a very bad idea. If you want to predict the next word in a sentence you \\nbetter know which words came before it. RNNs are called recurrent because they perform the \\nsame task for every element of a sequence, with the output being depended on the previous \\ncomputations. Another way to think about RNNs is that they have a ‚Äúmemory‚Äù which \\ncaptures information about what has been calculated so far. In theory RNNs can make use of \\ninformation in arbitrarily long sequences, but in practice they are limited to looking back only \\na few steps. \\n \\nFig. 4.8. A recurrent neural network.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 18}, page_content='Training Methods of Artificial Neural Networks \\n \\n \\n6.0.0 Introduction  \\n \\n \\nThe dynamics of neuron consists of two parts. One is the dynamics of the \\nactivation state and the second one is the dynamics of the synaptic weights. The Short Term \\nMemory (STM) in neural networks is modeled by the activation state of the network and the \\nLong Term Memory is encoded the information in the synaptic weights due to learning. The \\nmain property of artificial neural network is that, the ability of the learning from its \\nenvironment and history. The network learns about its environment and history through its \\ninteractive process of adjustment applied to its synaptic weights and bias levels. Generally, \\nthe network becomes more knowledgeable about its environment and history, after \\ncompletion each iteration of learning process. It is important to distinguish between \\nrepresentation and learning.  Representation refers to the ability of a perceptron (or other \\nnetwork) to simulate a specified function.  Learning requires the existence of a systematic \\nprocedure for adjusting the network weights to produce that function.  Here we will discuss \\nmost of popular learning rules. \\n \\n6.1.0 Definition of learning  \\nThere are too many activities associated with the notion of learning and we define \\nlearning in the context of neural networks [1] as \\n \\n‚ÄúLearning is a process by which the free parameters of neural network are adapted \\nthrough a process of stimulation by the environment in which the network is embedded. The \\ntype of learning is determined by the manner in which the parameter changes takes place‚Äù \\n   \\nBased on the above definition the learning process of ANN can be divided into the following \\nsequence of steps: \\n1. The ANN is stimulated by an environment. \\n2. The ANN undergoes changes in its free parameters as a result of the above \\nstimulation. \\n3. The ANN responds in a new way to the environment because of the changes that have \\noccurred in its internal structure.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 19}, page_content='6.1.1 Types of Learning Methods / Learning Strategies \\nA set of defined rules for the solution of a learning problem is called algorithm. There \\nare different approaches to train an ANN. Most of the methods fall into one of two classes \\nnamely supervised learning and unsupervised learning. \\nSupervised learning: An external signal known as teacher controls learning and incorporates \\ninformation. \\nSupervised training requires the pairing of each input vector with a target vector \\nrepresenting the desired output; together these are called a training pair.  Usually a network is \\ntrained over a number of such training pairs.  An input vector is applied, the output of the \\nnetwork is calculated and compared to the corresponding target vector and the difference \\n(error) is fed back through the network and weights are changed according to an algorithm \\nthat tends to minimize the error.  The vectors of the training set are applied sequentially, and \\nerrors are calculated and weights adjusted for each vector, until the error for the entire \\ntraining set is at the acceptably low value. \\n \\n \\nUnsupervised learning: No external signal (teacher) is used in the learning process. The \\nneural network relies upon both internal and local information. \\nUnsupervised training is a far more plausible model of training in the biological system.  \\nDeveloped by Kohonen (1984) and many others, it requires no target vector for the outputs, \\nand hence, no comparisons to predetermined ideal responses.  The training set consists solely'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 20}, page_content='of input vectors.  The training algorithm modifies network weights to produce output vectors \\nthat consistent; i.e., both application of one of the training vectors and application of a vector \\nthat is sufficiently similar to it will produce the same patterns of outputs. \\n‚Ä¢ The training process, therefore, extracts the statistical properties of the training set and \\ngroup‚Äôs similar vector into classes. \\n‚Ä¢ Applying a vector from a given class as a input will produce a specific output vector, \\nbut there is no way to determine prior to training which specific output pattern will be \\nproduced by a given input vector class.  Hence, the outputs of such a network must \\ngenerally be transformed into a comprehensible form subsequent to the training \\nprocess. \\n \\n6.1.2 Types of basic learning mechanisms \\nIn general the training of any artificial neural network has to use one of the following \\nbasic learning mechanisms.  \\nThe basic learning mechanisms of neural networks are:  \\nHebbian learning rule'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 21}, page_content=''),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 22}, page_content='Competitive Learning  \\nIn competitive learning, the output of neurons of a neural network competes among \\nthemselves to become active (fired). Whereas in a neural network based on Hebbian learning, \\nseveral output neurons may be active simultaneously, in competitive learning only a single \\noutput neuron is active at any one time.  \\nThe basic elements in the competitive learning rule are:  \\n‚Ä¢ A set of neurons that are all the same except for some randomly distributed synaptic \\nweights, which therefore respond differently to given set of input patterns.  \\n‚Ä¢ A limit imposed on the ‚Äústrength‚Äù of each neuron. \\n‚Ä¢ A mechanism that permits two neurons to compete for the right to respond to a given \\nsubset of outputs, such that only one output neuron or only one neuron per group is \\nactive (i.e. ‚Äúon‚Äù) at a time. The neuron that wins the competition is called a ‚ÄúWinner-\\ntakes-all neuron‚Äù.  \\nIn the simplest form of competitive learning the neural network has a single layer of output \\nneurons each of which is fully connected to the input nodes. The network may include of \\nfeedback connections among the neurons as indicated in Fig.6.6.  \\nIn the network architecture described herein the feedback connections perform lateral \\ninhibition, with each neuron tending to exhibit the neuron to which it is laterally connected. \\nThe feed forward and synaptic connections in the above network are all excitatory.  \\n \\nx2 \\nLayer of source nodes  \\nx1 \\nx3 \\nx4 \\nSingle layer of output \\nneurons \\nFigure 6.6. Architectural graph of a simple competitive learning network with feedforward (excitory) connections from the source nodes to \\nthe neurons, and lateral (inhibirory) connections among the neurons, the lateral connection are signified by open  arrows[1].'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 23}, page_content='Mathematical Relations of competitive learning \\nFor a neuron k to be winning neuron, its induced local field vk for a specified input \\npattern X must be the largest among all the neurons in the network.  The output signal ok of \\nwinning neuron k is set equal to one and the output signals of all the neurons that lose the \\ncompetition are set equal to zero. This can be written as  \\n \\n\\uf0ee\\n\\uf0ed\\n\\uf0ec\\n\\uf0b9\\n\\uf03e\\n=\\n \\notherwise\\n    \\n0 \\nk \\nj j, \\nall\\nfor \\n    \\n v\\n \\n v\\nif\\n    \\n1 \\n \\n \\no\\nj\\nk\\nk\\n  \\n \\n \\n \\n(6.18) \\nwhere the induced local field vk represents the combined action of all the forward and \\nfeedback inputs to the neuron k. Let wkj denote the synaptic weight connecting input node j to \\nneuron k. Suppose that each neuron is allotted a fixed amount of synaptic weight (i.e.; all \\nsynaptic weights are positive), which is distributed among its input nodes, i.e. \\n \\n\\uf0e5\\n=\\nj\\nw\\nk \\nall\\nfor \\n  \\n          \\n1\\n  \\n  \\nkj\\n \\n \\n \\n \\n \\n(6.19) \\nA neuron then learns by shifting synaptic weights from its inactive to active input nodes. If a \\nneuron does not respond to a particular input pattern, no learning takes places in that neuron. \\nIf a particular neuron wins the competition, each input nodes of that neuron relinquish some \\nproportion of its synaptic weight, and the weight relinquished is then distributed equally \\namong the active input nodes.  \\nAccording this rule, the change \\nkj\\nw\\n\\uf044\\n applied to synaptic weight wkj is defined by  \\n \\n\\uf0ee\\n\\uf0ed\\n\\uf0ec\\uf068\\n=\\n\\uf044\\nn.\\ncompetitio\\n \\n the\\nloses\\nk \\nneuron \\n \\nif\\n          \\n          \\n0\\n  \\n \\nn.\\ncompetitio\\n \\n the\\nk wins\\nneuron \\n \\nif\\n      \\n)\\n w\\n- \\n(x\\n  \\n \\n \\nw\\nkj\\nj\\nkj\\n \\n \\n(6.20) \\nwhere \\uf068 is the learning rate parameter. This rule has the overall effect of moving the \\nsynaptic weight vector wk of winning neuron k toward the input pattern X. The example of \\nthis mechanism is ‚Äúwinner-take-all learning rule‚Äù and discussed in the following section. \\n6.7.0 Boltzmann Learning   \\nThe Boltzman learning rule, named on honor of Ludwig Boltzman, is a statistical learning \\nalgorithm derived from ideas rooted in statistical machines. In a Boltzman machine the \\nneurons forms a recurrent structure and they operate in a binary manner. That is, neuron ‚Äòon‚Äô \\nstate denoted by ‚Äò+1‚Äô  or in an ‚Äúoff‚Äù state denoted by ‚Äì1.  \\nThe machine is characterized by an energy function, E the value of which is determined by \\nthe particular states occupied by the individual neurons of the machine, as given by'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 24}, page_content='k \\n j\\n  \\n          \\n  x\\n  x\\nw\\n2\\n1\\n- \\n \\nE\\nj\\nk\\nj\\nk\\nkj\\n\\uf0b9\\n=\\n\\uf0e5\\uf0e5\\n \\n \\n \\n \\n \\n(6.23) \\nwhere xj is the state of neuron j, and wkj is the synaptic weight connecting neuron j to neuron \\nk. The fact that \\nk \\n j\\uf0b9\\nmeans simply none of the neurons in the machine has self-feedback. The \\nmachine operates by choosing a neuron at random for example, neuron k at some step of \\nlearning process, then flipping the state of neuron k from state xk to state -xk at some \\ntemperate T with probability.  \\n \\n \\n/T)\\nE\\nexp(-\\n1\\n1\\n  \\n  \\n)\\n x\\n-\\n  \\n  \\n(x\\n P\\nk\\nk\\nk\\n\\uf044\\n+\\n=\\n‚Üí\\n  \\n \\n \\n(6.24) \\nwhere \\nk\\nE\\n\\uf044\\nis the energy change (i.e. the change in the energy function of the machine) \\nresulting from such a flip. \\nNote that T is not a physical temperature, but rather a pseudo temperature. If this rule is \\napplied repeatedly, the machine will reach thermal equilibrium.  \\nThe neurons of a Boltzman machine partition into two functional groups : visible and hidden. \\nThe visible neurons provide an interface between the network and the environment in which \\nit operates, whereas the hidden neurons always operate freely.  \\nThere are two modes of operation to be considered.  \\n‚Ä¢ Clamped condition in which the visible neurons are all clamped into specific states \\ndetermined by environment.  \\n‚Ä¢ Free running condition in which all the neurons (visible and hidden) are allowed to \\noperate freely.  \\nLet Pkj+ denote the correlation between the states of neurons j and k, with the network in its \\nclamped condition. Let Pkj- denote the correlation between the states of neurons j and k with \\nthe network in its free-running condition.  \\nBoth correlations are averaged over all possible states of the machine when it is in thermal \\nequilibrium. Then, according to the Boltzmann learning rule, the change \\nkj\\nw\\n\\uf044\\n applied to the \\nsynaptic weight wkj from the neuron j to neuron k defined by  \\n \\n \\n(\\n)\\nk\\nj\\n          \\n,\\nP\\n  -  \\nP\\n \\n  \\n  \\nw\\n-\\nkj\\nkj\\nkj\\n\\uf0b9\\n\\uf068\\n=\\n\\uf044\\n+\\n \\n \\n \\n \\n(6.25) \\nwhere \\uf068 is the learning rate parameter. Both Pkj+  and Pkj- range in value from ‚Äì1 to +1.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 25}, page_content='PERCEPTRONS \\n \\n8.0.0 Introduction \\nWe know that perceptron is one of the early models of artificial neuron. It was proposed \\nby Rosenblatt in 1958. It is a single layer neural network whose weights and biases could be \\ntrained to produce a correct target vector when presented with the corresponding input vector. \\nThe perceptron is a program that learns concepts, i.e. it can learn to respond with True (1) or \\nFalse (0) for inputs we present to it, by repeatedly \"studying\" examples presented to it.  The \\ntraining technique used is called the perceptron learning rule. The perceptron generated great \\ninterest due to its ability to generalize from its training vectors and work with randomly \\ndistributed connections. Perceptrons are especially suited for simple problems in pattern \\nclassification. In this also we give the perceptron convergence theorem. \\n8.1.0 Perceptron Model \\nIn the 1960, perceptrons created a great deal of interest and optimism. Rosenblatt (1962) \\nproved a remarkable theorem about perceptron learning.  Widrow (Widrow 1961, 1963, \\nWidrow and Angell 1962, Widrow and Hoff 1960) made a number of convincing \\ndemonstrations of perceptron like systems. Perceptron learning is of the supervised type.  A \\nperceptron is trained by presenting a set of patterns to its input, one at a time, and adjusting \\nthe weights until the desired output occurs for each of them. \\nThe schematic diagram of perceptron is shown inn Fig. 8.1. Its synaptic weights are denoted \\nby w1, w2, . . .  wn. The inputs applied to the perceptron are denoted by x1, x2, . . . . xn. The \\nexternally applied bias is denoted by b.  \\n \\n \\n \\n \\n \\n \\n \\n \\nThe net input to the activation of the neuron is written as  \\n \\n\\uf0e5\\n=\\n+\\n=\\nn\\n1\\ni\\ni\\ni\\nb \\n \\n x\\nw\\n \\n \\nnet\\n \\n \\n \\n \\n \\n \\n(8.1) \\nThe output of perceptron is written as  \\no = f(net) \\n \\n(8.2) \\nxn \\no\\nw2 \\nwn \\nf(.) \\nOutput \\nx2 \\nHard \\nlimiter \\nx1 \\nw1 \\nnet\\nbias, b \\nInputs \\nFig. 8.1 Schematic diagram of perceptron \\n\\uf053'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 26}, page_content='where f(.) is the activation function of perceptron. Depending upon the type of activation \\nfunction, the perceptron may be classified into two types  \\ni) Discrete perceptron, in which the activation function is hard limiter or sgn(.) function  \\nii) Continuous perceptron, in which the activation function is sigmoid function, which is \\ndifferentiable. The input-output relation may be rearranged by considering w0=b and \\nfixed bias x0 = 1.0. Then  \\n   WX\\n  \\n x\\nw\\n \\n \\nn\\n0\\ni\\ni\\ni\\n=\\n=\\uf0e5\\n=\\nnet\\n \\n \\n \\n(8.3) \\nwhere W = [w0, w1, w2, . . . . wn] and X = [x0, x1, x2, . . . xn]T. \\nThe learning rule for perceptron has been discussed in unit 7. Specifically the learning of \\nthese two models is discussed in the following sections.  \\n \\n8.2.0 Single Layer Discrete Perceptron Networks \\nFor discrete perceptron the activation function should be hard limiter or sgn() \\nfunction. The popular application of discrete perceptron is a pattern classification. To develop \\ninsight into the behavior of a pattern classifier, it is necessary to plot a map of the decision \\nregions in n-dimensional space, spanned by the n input variables. The two decision regions \\nseparated by a hyper plane defined by  \\n \\n\\uf0e5\\n=\\n=\\nn\\ni\\ni\\nw\\n0\\ni\\n 0\\n  \\n  \\n x\\n  \\n \\n \\n \\n \\n \\n(8.4) \\nThis is illustrated in Fig. 8.2 for two input variables x1 and x2, for which the decision \\nboundary takes the form of a straight line.  \\n \\nFor the perceptron to function properly, the two classed C1 and C2 must be linearly separable. \\nThis in turn, means that the patterns to be classified must be sufficiently separated from each \\nClass C1 \\nClass C2 \\nx1 \\nx2 \\nFig. 8.2 Illustration of the hyper plane (in this example, a straight lines) \\n as decision boundary for a two dimensional, two-class patron classification problem.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 27}, page_content='other to ensure that the decision surface consists of a hyper plane. This is illustrated in Fig. \\n8.3.  \\n \\nIn Fig. 8.3(a), the two classes C1 and C2 are sufficiently separated from each other to draw a \\nhyper plane (in this it is a straight line) as the decision boundary. If however, the two classes \\nC1 and C2 are allowed to move too close to each other, as in Fig. 8.3 (b), they become \\nnonlinearly separable, a situation that is beyond the computing capability of the perceptron.  \\nSuppose then that the input variables of the perceptron originate from two linearly separable \\nclasses. Let √¶1 be the subset of training vectors X1(1), X1(2),  . . . . , that belongs to class C1 \\nand √¶2 be the subset of train vectors X2(1), X2(2), . . . . . , that belong to class C2.  The union \\nof √¶1 and √¶2 is the complete training set √¶. Given the sets of vectors √¶1 and √¶2 to train the \\nclassifier, the training process involves the adjustment of the W in such a way that the two \\nclasses C1 and C2 are linearly separable. That is, there exists a weight vector W such that we \\nmay write, \\n\\uf0fe\\n\\uf0fd\\n\\uf0fc\\n\\uf0a3\\n\\uf03e\\n2\\n1\\nC\\n \\nclass\\n \\n to\\nbelonging\\n \\nX\\nor \\ninput vect\\nevery \\nfor \\n   \\n0 \\n \\n \\nC\\n \\nclass\\n \\n to\\nbelonging\\n \\nX\\nor \\ninput vect\\nevery \\nfor \\n   \\n0 \\n \\n WX\\nWX\\n  \\n \\n(8.5) \\nIn the second condition, it is arbitrarily chosen to say that the input vector X belongs \\nto class C2 if WX = 0. \\nThe algorithm for updating the weights may be formulated as follows:  \\n1. \\nIf the kth member of the training set, Xk is correctly classified by the weight vector \\nW(k) computed at the kth iteration of the algorithm, no correction is made to the \\nweight vector of perceptron in accordance with the rule.  \\n \\nWk+1 = Wk  \\n if WkXk >0   and Xk belongs to class C1 \\n \\n(8.6) \\n \\nWk+1 = Wk  \\n if Wk\\n0\\nXk \\uf0a3\\n and Xk belongs to class C2 \\n \\n(8.7) \\nClass \\nC\\nClass \\nC\\n(b) \\nClass \\nC\\nClass C2 \\n(a) \\nDecision boundary \\nFig. 8.3  (a) A pair of linearly separable patterns   \\n(b) A pair of nonlinearly separable'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 28}, page_content='2. \\nOtherwise, the weight vector of the perceptron is updated in accordance with the rule.  \\nk\\nkT\\n)1\\n(\\nŒ∑X\\n  - \\n W\\n =\\n+ T\\nk\\nW\\n \\n if Wk Xk >0 and Xk belongs to class C2 \\n(8.8a) \\n \\nk\\nkT\\n)1\\n(\\nX\\n Œ∑ \\n \\n  W\\n  \\n+\\n=\\n+ T\\nk\\nW\\n \\n if WkXk\\uf0a3 0 and Xk belongs to class C1 \\n(8.8b) \\nwhere the learning rule parameter \\uf068 controls the adjustment applied to the weight vector. \\nEquations (8.8a) and (8.8b) may be written general expression as  \\n \\nk\\nk\\nk\\nk\\nX\\no\\nd\\nW\\n)\\n(\\n2\\n  \\n  \\n  W\\n  \\nkT\\n)1\\n(\\n‚àí\\n+\\n=\\n+\\n\\uf068\\n \\n \\n \\n \\n \\n \\n(8.9) \\n8.2.1 Summary of the discrete perceptron training algorithm  \\nGiven are P training pairs of patterns \\n{X1, d1, X2, d2, . . . . Xp, dp}, where Xi is (n√ó1), di is (1√ó1), i = 1, 2, . . . P. Define w0=b is \\nbias and X0 = 1.0 , then  the size of augmented input vector is  Xi ((n+1)√ó).  \\nIn the following, k denotes the training step and p denotes the step counter with the training \\ncycle.  \\nStep 1: \\n0\\n\\uf03e\\n\\uf068\\n is chosen and define Emax. \\nStep 2: Initialize the weights at small random values, W =  [wij] , augmented size is (n+1)√ó1 \\nand initialize counters and error function as:  \\n \\nk \\uf0ac 1,  \\np \\uf0ac1  \\nE \\uf0ac 0. \\nStep 3: The training cycle begins. Apply input and compute the output: \\n \\nX \\uf0ac Xp,  \\n \\nd \\uf0ac  dp,  \\no \\uf0ac sgn(WX) \\nStep 4:  Update the weights:  \\nX\\n \\no)\\n - \\n(d\\n \\n \\n \\n W\\n \\nT\\n\\uf068\\n+\\n\\uf0ac\\nT\\nW\\n \\nStep 5:  Compute the cycle error: \\nE\\n \\n \\n)\\no\\nd\\n(\\n2\\n1 \\n \\nE\\n2 +\\n‚àí\\n\\uf0ac\\n  \\nStep 6:  If p < P, the p \\uf0ac p+1, k \\uf0ac k+1 and go to step 3, otherwise go to step 7. \\nStep 7:  The training cycle is completed. For E< Emax terminates the training session with \\noutput weights and k. If E > Emax , then E \\uf0ac0, p\\uf0ac1 and enter the new training cycle \\nby going to step 3. \\nIn general, a continuous perceptron element with sigmoidal activation function will be used \\nto facilitate the training of multi layer feed forward networks used for classification and \\nrecognition. \\n8.3.0 Single-Layer Continuous Perceptron networks \\nIn this, the concept of an error function in multidimensional weight space has been \\nintroduced. Also the hard limiter (sgn(.)) with weights will be replaced by the continuous \\nperceptron. By introduction of this continuous activation function, there are two advantages'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 29}, page_content='(i) finer control over the training procedure and (ii) differential characteristics of the \\nactivation function, which is used for computation of the error gradient.  \\nThe gradient or steepest descent is used in updating weights starting from any arbitrary \\nweight vector W, the gradient \\uf0d1E(W) of the current error function is computed. The next \\nvalue of W as obtained by moving in the direction of the negative gradient along the \\nmultidimensional error surface. Therefore the relation of modification of weight vector may \\nbe written as  \\n \\n)\\nE(W\\n - \\n W\\n  \\nk\\nkT\\n)1\\n(\\n\\uf0d1\\n=\\n+\\n\\uf068\\nT\\nk\\nW\\n  \\n \\n \\n \\n \\n(8.10) \\nwhere \\uf068 is the learning constant and is the positive constant and the superscript k denotes the \\nstep number. Let us define the error function between the desired output dk and actual output \\nok as  \\n \\n(\\n)\\n2\\nk\\nk\\nk\\no - \\nd\\n2\\n1\\n  \\n  \\nE\\n=\\n \\n \\n \\n \\n \\n \\n(8.11a) \\n \\nor \\n \\nEk =\\n(\\n)\\n\\uf05b\\n\\uf05d\\n2\\nkX\\nW\\nf - \\n2\\n1\\nk\\nd\\n \\n \\n \\n \\n \\n \\n(8.11b) \\nwhere the coefficient ¬Ω in from of the error expression is only for convenience in simplifying \\nthe expression  of the gradient value and it does not effect the location of the error function \\nminimization. The error minimization algorithm (8.10) requires computation of the gradient \\nof the error function (8.11) and it may be written as  \\n \\n\\uf05b\\n\\uf05d\\n2\\nk\\nk\\n)\\nf(net\\n - d\\n2\\n1\\n  \\n  )\\nW\\n(\\nE\\n\\uf0d1\\n=\\n\\uf0d1\\n  \\n \\n \\n \\n \\n(8.12) \\nThe n+1 dimensional gradient vector is defined as  \\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n=\\n\\uf0d1\\nn\\nk\\nw\\nw\\nw\\nW\\nE\\nE\\n.\\n   \\n.\\n   \\nE\\nE\\n   \\n  \\n)\\n(\\n1\\n0\\n \\n  (8.13)'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 30}, page_content=\"Using (8.12), we obtain the gradient vector as\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n=\\n\\uf0d1\\nn\\nk\\nk\\nk\\nk\\nw\\nnet\\nw\\nnet\\nw\\nnet\\nW\\nE\\n)\\n(\\n.\\n   \\n.\\n   \\n)\\n(\\n)\\n(\\n )\\n(net\\n \\nf )\\no - \\n(d\\n-\\n   \\n  \\n)\\n(\\n1\\n0\\nk\\n'\\nk\\nk\\n \\n (8.14) \\nSince netk  = WkX, \\nwe have  \\n \\n,\\n  x\\n  \\n)\\n(\\ni\\n=\\n\\uf0b6\\n\\uf0b6\\ni\\nk\\nw\\nnet\\n \\n \\nfor i =0, 1, . . . n. \\n \\n \\n(8.15) \\n(x0=1 for bias element) and equation (8.15) can be written as  \\n)X\\n(net\\n)f\\no - \\n(d\\n-  \\n  \\n)\\n(\\nk\\n'\\nk\\nk\\n=\\n\\uf0d1\\nk\\nW\\nE\\n \\n \\n \\n \\n \\n(8.16a) \\nor \\ni\\nk\\n'\\nk\\nk\\n)x\\n(net\\n)f\\no - \\n(d\\n-\\n  \\n  =\\n\\uf0b6\\n\\uf0b6\\ni\\nw\\nE\\n   \\nfor i = 0, 1, . . . n \\n \\n(8.16b) \\ni\\nk\\n'\\nk\\nk\\nk\\nk\\ni\\n)x\\n(net\\n)f\\no - \\n(d\\n  \\n  \\n)\\nE(W\\n-\\n  \\n  \\nw\\n  \\n\\uf068\\n\\uf068\\n=\\n\\uf0d1\\n=\\n\\uf044\\n\\uf05c\\n \\n \\n \\n(8.17) \\nEquation (8.17) is the training rule for the continuous perceptron. Now the requirement is \\nhow to calculate \\n)\\n(\\n' net\\nf\\n in terms of continuous perceptron output. Consider the bipolar \\nactivation function f(net) of the form  \\n \\n1\\n   \\n-\\n   \\nexp(-net)\\n1\\n2\\n  \\n  \\n)\\nnet\\n(\\nf\\n+\\n=\\n  \\n \\n \\n \\n \\n(8.18) \\nDifferentiating the equation (8.18) with respect to net: \\n\\uf05b\\n\\uf05d\\n2\\n'\\nexp(-net)\\n1\\nexp(-net)\\n 2\\n  \\n  )\\n(\\n+\\n\\uf0b4\\n=\\nnet\\nf\\n  (8.19) \\nThe following identity can be used in finding the derivative of the function. \\n\\uf05b\\n\\uf05d\\n2\\nexp(-net)\\n1\\nexp(-net)\\n 2\\n+\\n\\uf0b4\\n=  \\n)\\no - 1(\\n2\\n1\\n2   \\n \\n \\n \\n \\n(8.20) \\nThe relation (8.20) may be verified as follows: \\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n‚àí\\n+\\n‚àí\\n‚àí\\n‚àí\\n=\\n2\\n2\\n)\\nexp(\\n1\\n)\\nexp(\\n1\\n1\\n2\\n1\\n)\\no - 1(\\n2\\n1\\nnet\\nnet\\n \\n \\n \\n \\n(8.21) \\nThe right side of (8.21) can be rearranged as  \\n\\uf05b\\n\\uf05d\\n2\\n2\\n)\\nexp(\\n1\\n)\\nexp(\\n2\\n)\\nexp(\\n1\\n)\\nexp(\\n1\\n1\\n2\\n1\\nnet\\nnet\\nnet\\nnet\\n‚àí\\n+\\n‚àí\\n=\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n‚àí\\n+\\n‚àí\\n‚àí\\n‚àí\\n  \\n \\n \\n(8.22) \\nThis is same as that of (8.20) and now the derivative may be written as\"),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 31}, page_content=\")\\n1(\\n2\\n1\\n  \\n  )\\n(net\\nf  \\n2\\nk\\n'\\nko\\n‚àí\\n=\\n\\uf05c\\n \\n \\n \\n \\n \\n \\n(8.23) \\nThe gradient (8.16a) can be written as \\n  \\n)X\\no\\n-\\n(1\\n )\\no - \\n(d\\n2\\n1\\n-  \\n  )\\nW\\n(\\nE\\n2\\nk\\nk\\nk\\nk\\n=\\n\\uf0d1\\n (8.24) \\nand the complete delta training for the bipolar continuous activation function results from \\n(8.24) as  \\n \\nk\\n2\\nk\\nk\\nkT\\n)1\\n(\\n)X\\no - \\n(1\\n )\\no - \\n(\\n2\\n1\\n  \\n  \\n  W\\n  \\nk\\nT\\nk\\nd\\nW\\n\\uf068\\n+\\n=\\n+\\n \\n \\n \\n \\n \\n(8.25) \\nwhere k denotes the reinstated number of the training step.  \\nThe weight adjustment rule (8.25) corrects the weights in the same direction as the discrete \\nperceptron learning rule as in equation (8.8). The main difference between these two is the \\npresence of the moderating factor (1-ok2). This scaling factor is always positive and smaller \\nthan 1. Another main difference between the discrete and continuous perceptron training is \\nthat the discrete perceptron training algorithm always leads to a solution for linearly \\nseparable problems. In contrast to this property, the negative gradient-based training does not \\nguarantee solutions for linearly separable patterns. \\n8.3.1 Summary of the Single Continuous Perceptron Training Algorithm \\nGiven are P training pairs  \\n{X1, d1, X2, d2, . . . . . Xp, dp}, where Xi is ((n+1)\\uf0b41), di is (1\\uf0b41), for i = 1, 2, . . . P \\n \\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n=\\nin\\ni1\\ni0\\ni\\nx\\n.  \\n.  \\nx\\nx\\n  \\n  \\nX\\n,  where xi0 = 1.0 (bias element) \\nLet k is the training step and p is the step counter within the training cycle.  \\nStep 1: \\n0\\n\\uf03e\\n\\uf068\\n and Emax > 0 chosen.  \\nStep 2: Weights are initialized at W at small random values, W =  [wij]  is (n+1)√ó1. Counter \\nand error function are initialized.  \\n \\nk \\uf0ac 1,  \\np \\uf0ac1  \\nE \\uf0ac 0. \\nStep 3:  The training cycle begins. Input is presented and output is computed.  \\nX \\uf0ac Xp,  \\n \\nd \\uf0ac  dp,  \\no \\uf0ac f(WX) \\nStep 4:  Weights are updated:  \\n)X\\no - \\n(1\\n \\no)\\n - \\n(d\\n \\n2\\n1\\n \\n \\n W\\n \\n2\\nT\\n\\uf068\\n+\\n\\uf0ac\\nT\\nW\\n \\nStep 5:  Cycle error is computed: \\nE\\n \\n \\n)\\no\\nd\\n(\\n2\\n1 \\n \\nE\\n2 +\\n‚àí\\n\\uf0ac\"),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 32}, page_content=\"Step 6:  If p < P, the p \\uf0ac p+1, k \\uf0ac k+1 and go to step 3, otherwise go to step 7. \\nStep 7:  The training cycle is completed. For E < Emax terminated the training session with \\noutput weights, k and E. If \\n \\nE\\n \\n \\nE\\nmax\\n\\uf0b3\\n, then E \\uf0ac0, p\\uf0ac1 and enter the new training \\ncycle by going to step 3.  \\n8.4.0 Perceptron Convergence Theorem \\n(Separate document sent) \\n8.5.0 Problems and Limitations of the perceptron training algorithms \\nIt may be difficult to determine if the caveat regarding linear separability is satisfied \\nfor the particular training set at hand.  Further more, in many real world situations the inputs \\nare often time varying and may be separable at one time and not at another.  Also, these is no \\nstatement in the proof of the perceptron learning algorithm that indicates how many steps will \\nbe required to train the network.  It is small consolation; to know that training will only take a \\nfinite number of steps if the time it takes is measured in geological units. \\n \\nFurther more, there is no proof that perceptron training algorithm is faster than simply \\ntrying all possible adjustment of the weights; in some cases this brute force approach may be \\nsuperior. \\n8.5.1 Limitations of perceptrons \\nThere are limitations to he capabilities of perceptrons however.  They will learn the \\nsolution, if there is a solution to be found.  First, the output values of a perceptron can take on \\nonly one of two values (True or False). Second, perceptrons can only classify linearly \\nseparable sets of vectors. If a straight line or plane can be drawn to separate the input vectors \\ninto their correct categories, the input vectors are linearly separable and the perceptron will \\nfind the solution. If the vectors are not linearly separable learning will never reach a point \\nwhere all vectors are classified properly. The most famous example of the perceptron's \\ninability to solve problems with linearly non-separable vectors is the boolean exclusive-OR \\nproblem. \\nConsider the case of the exclusive-or (XOR) problem.  The XOR logic function has \\ntwo inputs and one output, how below. \\nx \\ny \\nZ \\n0 \\n0 \\n0 \\n0 \\n1 \\n1 \\n1 \\n0 \\n1 \\n1 \\n1 \\n0 \\nFig. 8.4   \\n \\n \\n \\n(b) Truth Table     \\nx \\ny \\nz \\n(a) Exclusive ‚ÄìOR gate\"),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 33}, page_content='It produces an output only if either one or the other of the inputs is on, but not if both \\nare off or both are on.  It is shown in above table.  We can consider this has a problem that \\nwe want the perceptron to learn to solve; output a 1 of the x is on and y is off or y is on and x \\nis off, otherwise output a ‚Äò0‚Äô.   It appears to be a simple enough problem.  \\n \\nWe can draw it in pattern space as shown in Fig. (8.5). The x-axis represents the value \\nof x, the y-axis represents the value of y.  The shaded circles represent the inputs that produce \\nan output of 1, whilst the un-shaded circles show the \\ninputs that produce an output of 0.  Considering the \\nshaded circles and un-shaded circles as separate classes, \\nwe find that, we cannot draw a straight line to separate \\nthe two classes.  Such patterns are known as linearly \\ninseparable since no straight line can divide them up \\nsuccessfully.  Since we cannot divide them with a single \\nstraight line, the perceptron will not be able to find any \\nsuch line either, and so cannot solve such a problem.  In fact, a single-layer perceptron cannot \\nsolve any problem that is linearly inseparable. \\n  \\n-\\n+\\n+\\n-\\nx1\\nx2\\n-\\n+\\n+\\n-\\nx1\\nx2'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 34}, page_content=''),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Office 365', 'creator': 'Microsoft¬Æ Word for Office 365', 'creationdate': '2019-07-02T13:53:30+05:30', 'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'total_pages': 36, 'format': 'PDF 1.7', 'title': 'Introduction to ANN', 'author': 'Harish  Balaga', 'subject': '', 'keywords': '', 'moddate': '2019-07-02T13:53:30+05:30', 'trapped': '', 'modDate': \"D:20190702135330+05'30'\", 'creationDate': \"D:20190702135330+05'30'\", 'page': 35}, page_content='9.0.0 Backpropagation Algorithm  \\n(Separate document Attached)'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 0}, page_content='Machine learning methodology: Overfitting,\\nregularization, and all that\\nCS194-10 Fall 2011\\nCS194-10 Fall 2011\\n1'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 1}, page_content='Outline\\n‚ô¶Measuring learning performance\\n‚ô¶OverÔ¨Åtting\\n‚ô¶Regularization\\n‚ô¶Cross-validation\\n‚ô¶Feature selection\\nCS194-10 Fall 2011\\n2'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 2}, page_content='Performance measurement\\nWe care about how well the learned function h generalizes to new data:\\nGenLossL(h) = Ex,yL(x, y, h(x))\\nEstimate using a test set of examples drawn from\\nsame distribution over example space as training set\\nLearning curve = loss on test set as a function of training set size\\n(often averaged over many trials)\\ngeneralization loss\\n# of examples\\nslow learning\\nfast learning\\nThis is a way of evaluating learning algorithms\\nCS194-10 Fall 2011\\n3'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 3}, page_content='Performance measurement contd.\\nE.g., suppose data generated by quadratic + noise:\\n‚Äì Quadratic h is the realizable case (can express true f up to noise);\\nlearns quickly, reaches noise Ô¨Çoor\\n‚Äì Linear h is the non-realizable case (restricted H or missing inputs);\\nsuÔ¨Äers additional structural error\\n‚Äì High-degree polynomial h: realizable but redundant; learns slowly\\ngeneralization loss\\n# of examples\\nnonrealizable\\nredundant\\nrealizable\\nnoise floor\\nstructural error\\nCS194-10 Fall 2011\\n4'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 4}, page_content='Training error\\nDuring learning, we have access to training error (empirical loss);\\nthings may look quite diÔ¨Äerent given Ô¨Åxed training set:\\nempirical loss\\n# of examples\\nnonrealizable\\nredundant\\nrealizable\\nnoise floor\\nCS194-10 Fall 2011\\n5'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 5}, page_content='OverÔ¨Åtting\\nFix the training set size, vary H complexity (e.g., degree of polynomials)\\nExample from Bishop, Figure 1.5\\nM\\nERMS\\n \\n \\n0\\n3\\n6\\n9\\n0\\n0.5\\n1\\nTraining\\nTest\\nFor any given N, some h of suÔ¨Écient complexity Ô¨Åts the data\\nbut may have very bad generalization error!!\\nCS194-10 Fall 2011\\n6'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 6}, page_content='Regularization\\nReduces overÔ¨Åtting by adding a complexity penalty to the loss function\\nL2 regularization: complexity = sum of squares of weights\\nCombine with L2 loss to get ridge regression:\\nÀÜw = arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•2\\n2\\nwhere Œª ‚â•0 is a Ô¨Åxed multiplier and ‚à•w‚à•2\\n2 = PD\\nj = 1 w2\\nj\\nw0 not penalized, otherwise regularization eÔ¨Äect depends on y-origin\\nCS194-10 Fall 2011\\n7'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 7}, page_content='L2 Regularization Solution\\nFirst ‚Äúcenter‚Äù the data:\\n‚Äì Fix w0 = y = 1\\nN\\nPN\\ni = 1 yi\\n‚Äì Drop dummy x0 from data matrix X and set x‚Ä≤\\nij = xij ‚àíxj\\nNow can write\\nÀÜw = arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + ŒªwTw\\nDerivative with respect to w is\\n‚àí2XTY + 2XTXw\\n|\\n{z\\n}\\nas before\\n+2Œªw\\nand setting this to zero gives\\nÀÜw = (XTX + ŒªI)‚àí1XTY\\nCS194-10 Fall 2011\\n8'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 8}, page_content='MAP (maximum a posteriori) interpretation\\nGeneral MAP learning:\\nÀÜh = arg max\\nh\\nP(data | h)P(h)\\n= arg min\\nh ‚àílog P(data | h)\\n|\\n{z\\n}\\nas in MLE\\n‚àílog P(h)\\n|\\n{z\\n}\\ncomplexity penalty\\nFor regression, suppose we think weights are a priori independent and (except\\nfor w0) probably small:\\nP(hw) =\\nD\\nY\\nj = 1\\nN(wj | 0, œÅ2) = Œ±D\\nœÅ e‚àíP\\nj w2\\nj/2œÅ2 = Œ±D\\nœÅ ewTw/2œÅ2\\nCS194-10 Fall 2011\\n9'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 9}, page_content='MAP interpretation contd.\\nAssuming Gaussian regression model with variance œÉ2, MAP formula is\\nÀÜw = arg min\\nw\\n\\x12 1\\n2œÉ2(Y ‚àíXw)T(Y ‚àíXw) ‚àíNŒ±œÉ\\n\\x13\\n+\\n\\x12 1\\nœÅ2wTw ‚àíDŒ±œÅ\\n\\x13\\n= arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + œÉ2\\nœÅ2wTw\\nwhich is identical to L2 regularization with Œª = œÉ2/œÅ2\\nCS194-10 Fall 2011\\n10'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 10}, page_content='EÔ¨Äect of L2 regularization\\nAs Œª increases, wTw decreases\\nExample from Hastie, Fig 3.8 (scale is inverse of Œª):\\nCS194-10 Fall 2011\\n11'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 11}, page_content='L1 regularization (LASSO)\\nÀÜw = arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•1\\nwhere Œª ‚â•0 and ‚à•w‚à•1 = PD\\nj = 1|wj|\\nLooks like a small tweak, but makes a big diÔ¨Äerence!\\n1) No more closed-form solution\\n‚Äì use quadratic programming\\nminw(Y ‚àíXw)T(Y ‚àíXw) s.t. ‚à•w‚à•1 ‚â§s\\n‚Äì convex problem, polytime (but expensive) solution\\n2) LASSO = MAP learning with Laplacian prior\\nP(wj) = 1\\n2be‚àí\\n|wj|\\nb\\nwhere b is the scale\\nCS194-10 Fall 2011\\n12'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 12}, page_content='EÔ¨Äect of L1 regularization\\nLaplace prior encourages sparsity, i.e., mostly zero weights\\nExample from Hastie et al., Fig 3.10:\\nCS194-10 Fall 2011\\n13'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 13}, page_content='Cross-validation\\nRegularization helps but still need to pick Œª.\\nWant to minimize test-set error, but we have no test set!\\nIdea: make one (a validation set) by pretending we can‚Äôt see the labels\\nTry diÔ¨Äerent values of Œª, learn ÀÜhŒª on rest of data,\\ntest ÀÜhŒª on validation set, pick best Œª, train on all\\nProblem: small validation set ‚áílarge error in estimated loss\\nlarge validation set ‚áísmall training set ‚áíbad ÀÜhŒª\\nCS194-10 Fall 2011\\n14'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 14}, page_content='Cross-validation contd.\\nK-fold cross-validation: divide data into K blocks\\nfor k = 1 to k\\ntrain on blocks except kth block, test on kth block\\naverage the results, choose best Œª\\nCommon cases: K = 5, 10 or K = N (LOOCV)\\nHigh computation cost: K folds √ó many choices of model or Œª\\nCS194-10 Fall 2011\\n15'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 15}, page_content='Feature selection\\nAnother way to get a sparse predictor: pick out a small set of the most\\nrelevant features\\nA set of features F ‚äÜ{X1, . . . , XD} is minimally relevant\\nif there is some h deÔ¨Ånable using F such that\\n1) no h‚Ä≤ deÔ¨Åned on a superset of F has lower generalization loss\\n2) any h‚Ä≤‚Ä≤ deÔ¨Åned on a subset of F has higher generalization loss\\nAny feature not in a minimally relevant set is irrelevant\\nProblems in choosing a minimally relevant set:\\n‚Äì inaccurate estimate of generalization loss\\n‚áísome features appear relevant when they‚Äôre not\\n‚Äì NP-hard to Ô¨Ånd a set even with perfect estimates\\nForward selection: greedily add feature that decreases CV error most\\nBackward selection: greedily delete feature that decreases CV error most\\nCS194-10 Fall 2011\\n16'),\n",
       " Document(metadata={'producer': 'pdfeTeX-1.21a', 'creator': 'TeX', 'creationdate': '2011-09-05T14:01:42-07:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'total_pages': 17, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20110905140142-07'00'\", 'page': 16}, page_content='Summary\\nLearning performance = prediction accuracy measured on test set\\nTrading oÔ¨Äcomplexity and degree of Ô¨Åt is hard\\nRegularization penalizes hypothesis complexity\\nL2 regularization leads to small weights\\nL1 regularization leads to many zero weights (sparsity)\\nFeature selection tries to discard irrelevant features\\nCross-validation enables selection of feature sets or regularization penalties\\nby estimating test-set error on parts of the training set\\nCS194-10 Fall 2011\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 0}, page_content='STAT 479: Machine Learning\\nLecture Notes\\nSebastian Raschka\\nDepartment of Statistics\\nUniversity of Wisconsin‚ÄìMadison\\nhttp://stat.wisc.edu/‚àºsraschka/teaching/stat479-fs2018/\\nFall 2018\\nContents\\n8\\nModel Evaluation 1: OverÔ¨Åtting and UnderÔ¨Åtting\\n1\\n8.1\\nOverview\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n1\\n8.2\\nOverÔ¨Åtting and UnderÔ¨Åtting . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n1\\n8.3\\nBias and Variance\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n3\\n8.4\\nBias-Variance Decomposition of the Squared Loss . . . . . . . . . . . . . . . .\\n6\\n8.5\\nBias-Variance Decomposition of the 0-1 Loss\\n. . . . . . . . . . . . . . . . . .\\n7\\n8.6\\nConclusion\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 1}, page_content='STAT 479: Machine Learning\\nLecture Notes\\nSebastian Raschka\\nDepartment of Statistics\\nUniversity of Wisconsin‚ÄìMadison\\nhttp://stat.wisc.edu/‚àºsraschka/teaching/stat479-fs2018/\\nFall 2018\\n8\\nModel Evaluation 1: OverÔ¨Åtting and UnderÔ¨Åtting\\n8.1\\nOverview\\n‚Ä¢ In this lecture, we discuss some of the basic terms and machine learning fundamentals\\nthat are relevant for model evaluation, namely, bias and variance, and overÔ¨Åtting and\\nunderÔ¨Åtting.\\nFigure 1: Overview of topics being covered in this lecture in the context of topics related to model\\nevaluation that we will cover at a later point in time.\\n8.2\\nOverÔ¨Åtting and UnderÔ¨Åtting\\n‚Ä¢ The overall goal in machine learning is to obtain a model/hypothesis that generalizes\\nwell to new, unseen data.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 2}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 2\\n‚Ä¢ In other words, we want a model that generalizes well to unseen data, which we can\\nmeasure, for example, by using an independent test set ‚Äì while it sounds like this\\nshould be very straightforward, there are some pitfalls which we will discuss in the\\nnext lecture.\\n‚Ä¢ Some of the evaluation metrics we can use to measure the performance on the test set\\nare the prediction accuracy and misclassiÔ¨Åcation error in the context of classiÔ¨Åcation\\nmodels ‚Äì we say that a good model has a ‚Äúhigh generalization accuracy‚Äù or ‚Äúlow\\ngeneralization error‚Äù (or, simply ‚Äúgood generalization performance‚Äù).\\n‚Ä¢ The assumptions we generally make are the following:\\n‚Äì i.i.d. assumption: inputs are independent, and training and test examples are\\nidentically distributed (drawn from the same probability distribution).\\n‚Äì For some random model that has not been Ô¨Åt to the training set, we expect both\\nthe training and test error to be equal.\\n‚Äì The training error or accuracy provides an (optimistically) biased estimate of the\\ngeneralization performance.\\nNow, overÔ¨Åtting and underÔ¨Åtting are two terms that we can use to diagnose a machine\\nlearning model based on the training and test set performance. I.e., a model that suÔ¨Äers\\nfrom underÔ¨Åtting does perform well on the test AND training set. In contrast, a model that\\noverÔ¨Åts (e.g., from Ô¨Åtting the noise in the training dataset) can be usually recognized by a\\nhigh training set accuracy, but low test set accuracy. Intuitively, as a rule of thumb, the\\nlarger the hypothesis space a model has access to, the higher the risk of overÔ¨Åtting.\\nA more technical term for the size of the hypothesis space is the so-called capacity. There\\nare diÔ¨Äerent measures for speciÔ¨Åc models and datasets that can be used to calculate the\\ncapacity of the model such as the VC dimension12 (however, topics from learning theory\\nsuch as VC dimension are beyond the scope of this course).\\nFigure 2: Illustration of overÔ¨Åtting and underÔ¨Åtting in relation to the training and test error.\\n1VC dimension stands for Vapnik-Chervonenkis dimension.\\n2Vladimir N Vapnik and A Ya Chervonenkis. ‚ÄúOn the uniform convergence of relative frequencies of\\nevents to their probabilities‚Äù. In: Measures of complexity. Springer, 2015, pp. 11‚Äì30.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 3}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 3\\n8.3\\nBias and Variance\\nOften, researchers use the terms bias and variance or ‚Äúbias-variance tradeoÔ¨Ä‚Äù to describe\\nthe performance of a model ‚Äì i.e., you may stumble upon talks, books, or articles where\\npeople say that a model has a high variance or high bias. So, what does that mean? In\\ngeneral, we might say that ‚Äúhigh variance‚Äù is proportional to overÔ¨Åtting, and ‚Äúhigh bias‚Äù\\nis proportional to underÔ¨Åtting. However, in this lecture, we are going to deÔ¨Åne these terms\\nmore precisely.\\nFigure 3: Results from searching the terms ‚Äúmodel has high variance‚Äù and ‚Äúmodel has high bias‚Äù\\non GoogleScholar\\nNote that the so-called Bias-Variance decomposition we are talking about in this lecture was\\ninitially formulated for regression losses (i.e., mean squared error3); however, we are also\\ngoing to look into formulations for the 0-1 loss that we use to measure the misclassiÔ¨Åcation\\nerror (or accuracy).\\n‚Ä¢ Why are we doing this? The Decomposition of the loss into bias and variance help us\\nunderstand learning algorithms, concepts are correlated to underÔ¨Åtting and overÔ¨Åtting.\\n‚Ä¢ Thinking back of the ensemble lecture, the bias-variance decomposition and tradeoÔ¨Ä\\nhelp explain why ensemble methods might perform better than single models (i.e.,\\nwhy bagging reduces the variance, and why a boosting model has a lower bias than\\nindividual weak learners like decision tree stumps).\\n3In particular, in statistics, we evaluate the goodness of an estimator in relation to the true parameter\\nor function'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 4}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 4\\nLow Variance\\n(Precise)\\nHigh Variance\\n(Not Precise)\\nLow Bias\\n(Accurate)\\nHigh Bias\\n(Not Accurate)\\nFigure 4: Bias-variance intuition.\\nTo use the more formal terms for bias and variance, assume we have a point estimator ÀÜŒ∏ of\\nsome parameter or function Œ∏. Then, the bias is commonly deÔ¨Åned as the diÔ¨Äerence between\\nthe expected value of the estimator and the parameter that we want to estimate:\\nBias = E[ÀÜŒ∏] ‚àíŒ∏.\\n(1)\\nIf the bias is larger than zero, we also say that the estimator is positively biased, if the\\nbias is smaller than zero, the estimator is negatively biased, and if the bias is exactly zero,\\nthe estimator is unbiased. Similarly, we deÔ¨Åne the variance as the diÔ¨Äerence between the\\nexpected value of the squared estimator minus the squared expectation of the estimator:\\nVar(ÀÜŒ∏) = E\\n\\x02ÀÜŒ∏2\\x03\\n‚àí\\n\\x12\\nE\\n\\x02ÀÜŒ∏\\n\\x03\\x132\\n.\\n(2)\\nNote that in the context of this lecture, it will be more convenient to write the variance in\\nits alternative form:\\nVar(ÀÜŒ∏) = E[(E[ÀÜŒ∏] ‚àíÀÜŒ∏)2].\\n(3)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 5}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 5\\nHigh bias\\nFigure 5: Suppose there is an unknown target function or ‚Äútrue function‚Äù to which we do want\\nto approximate. No, suppose we have diÔ¨Äerent training sets drawn from an unknown distribution\\ndeÔ¨Åned as ‚Äútrue function + noise.‚Äù This plot shows diÔ¨Äerent linear regression models, each Ô¨Åt to\\na diÔ¨Äerent training set. None of these hypotheses approximate the true function well, except at\\ntwo points (around x=-10 and x=6). Here, we can say that the bias is large because the diÔ¨Äerence\\nbetween the true value and the predicted value, on average (here, average means ‚Äúexpectation of\\nthe training sets‚Äù not ‚Äúexpectation over examples in the training set‚Äù), is large\\nHigh variance\\nFigure 6: Suppose there is an unknown target function or ‚Äútrue function‚Äù to which we do want\\nto approximate. No, suppose we have diÔ¨Äerent training sets drawn from an unknown distribution\\ndeÔ¨Åned as ‚Äútrue function + noise.‚Äù This plot shows diÔ¨Äerent unpruned decision tree models, each\\nÔ¨Åt to a diÔ¨Äerent training set. Note that these hypotheses Ô¨Åt the training data very closely. However,\\nif we would consider the expectation over training sets, the average hypothesis would Ô¨Åt the true\\nfunction perfectly (given that the noise is unbiased and has an expected value of 0). However, as we\\ncan see, the variance is very high, since on average, a prediction diÔ¨Äers a lot from the expectation\\nvalue of the prediction.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 6}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 6\\n8.4\\nBias-Variance Decomposition of the Squared Loss\\nWe can decompose a loss function such as the squared loss into three terms, a variance, bias,\\nand a noise term (and the same is true for the decomposition of the 0-1 loss later). However,\\nfor simplicity, we will ignore the noise term in this lecture (some of the literature referenced\\nin later sections include the noise term if you are eager to learn more about variance-bias\\ndecomposition.).\\nBefore we introduce the bias-variance decomposition of the 0-1 loss for classiÔ¨Åcation, let us\\nstart with the decomposition of the squared loss as an easy warm-up exercise to get familiar\\nwith the overall concept.\\nThe previous section already listed the common formal deÔ¨Ånitions of bias and variance,\\nhowever, let us deÔ¨Åne them again for convenience:\\nBias(ÀÜŒ∏) = E[ÀÜŒ∏] ‚àíŒ∏,\\nVar(ÀÜŒ∏) = E[(E[ÀÜŒ∏] ‚àíÀÜŒ∏)2].\\n(4)\\nRecall that in the context of these machine learning lecture (notes), we deÔ¨Åned\\n‚Ä¢ the true or target function as y = f(x),\\n‚Ä¢ the predicted target value as ÀÜy = ÀÜf(x) = h(x),\\n‚Ä¢ and the squared loss as S = (y ‚àíÀÜy)2. (I use S here because it will be easier to tell it\\napart from the E, which we use for the expectation in this lecture.)\\nNote that unless noted otherwise, the expectation is over training sets!\\nTo get started with the squared error loss decomposition into bias and variance, let use do\\nsome algebraic manipulation, i.e., adding and subtracting the expected value of ÀÜy and then\\nexpanding the expression using the quadratic formula (a + b)2 = a2 + b2 + 2ab):\\nS = (y ‚àíÀÜy)2\\n(y ‚àíÀÜy)2 = (y ‚àíE[ÀÜy] + E[ÀÜy] ‚àíÀÜy)2\\n= (y ‚àíE[ÀÜy])2 + (E[ÀÜy] ‚àíy)2 + 2(y ‚àíE[ÀÜy])(E[ÀÜy] ‚àíÀÜy).\\n(5)\\nNext, we just use the expectation on both sides, and we are already done:\\nE[S] = E[(y ‚àíÀÜy)2]\\nE[(y ‚àíÀÜy)2] = (y ‚àíE[ÀÜy])2 + E[(E[ÀÜy] ‚àíÀÜy)2]\\n= [Bias]2 + Variance\\n(6)\\nYou may wonder what happened to the ‚Äú2ab‚Äù term (2(y ‚àíE[ÀÜy])(E[ÀÜy] ‚àíÀÜy)) when we used\\nthe expectation. It turns that it evaluates to zero and hence vanishes from the equation,\\nwhich can be shown as follows:\\nE[2(y ‚àíE[ÀÜy])(E[ÀÜy] ‚àíÀÜy)] = 2E[(y ‚àíE[ÀÜy])(E[ÀÜy] ‚àíÀÜy)]\\n= 2(y ‚àíE[ÀÜy])E[(E[ÀÜy] ‚àíÀÜy)]\\n= 2(y ‚àíE[ÀÜy])(E[E[ÀÜy]] ‚àíE[ÀÜy])\\n= 2(y ‚àíE[ÀÜy])(E[ÀÜy] ‚àíE[ÀÜy])\\n= 0.\\n(7)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 7}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 7\\nSo, this is the canonical decomposition of the squared error loss into bias and variance. The\\nnext section will discuss some approaches that have been made to decompose the 0-1 loss\\nthat we commonly use for classiÔ¨Åcation accuracy or error.\\nFigure 7: A sketch of variance and bias in relation to the training error and generalization error\\n‚Äì how high variance related to overÔ¨Åtting, and how large bias relates to underÔ¨Åtting.\\n8.5\\nBias-Variance Decomposition of the 0-1 Loss\\nNote that decomposing the 0-1 loss into bias and variance components is not as straight-\\nforward as for the squared error loss. To quote Pedro Domingos, a well-known machine learn-\\ning researcher and professor at University of Washington: ‚Äúseveral authors have proposed\\nbias-variance decompositions related to zero-one loss (Kong & Dietterich, 1995; Breiman,\\n1996b; Kohavi & Wolpert, 1996; Tibshirani, 1996; Friedman, 1997). However, each of these\\ndecompositions has signiÔ¨Åcant shortcomings.‚Äù4. In fact, the paper this quote was taken from\\nmay oÔ¨Äer the most intuitive and general formulation at this point. However, we will Ô¨Årst,\\nfor simplicity, go over Kong & Dietterich formulation5 of the 0-1 loss decomposition, which\\nis the same as Domingos‚Äôs but excluding the noise term (for simplicity).\\nThe table below summarizes the relevant terms we used for the squared loss in relation to\\nthe 0-1 loss. Recall that the 0-1 loss, L, is 0 if a class label is predicted correctly, and one\\notherwise. The main prediction for the squared error loss is simply the average over the\\npredictions E[ÀÜy] (the expectation is over training sets), for the 0-1 loss Kong & Dietterich\\nand Domingos deÔ¨Åned it as the mode. I.e., if a model predicts the label one more than\\n50% of the time (considering all possible training sets), then the main prediction is 1, and\\n0 otherwise.\\nSquared Loss\\n0-1 Loss\\nSingle loss\\n(y ‚àíÀÜy)2\\nL(y, ÀÜy)\\nExpected loss\\nE[(y ‚àíÀÜy)2]\\nE[L(y, ÀÜy)]\\nMain prediction E[ÀÜy]\\nmean (average)\\nmode\\nBias2\\n(y ‚àíE[ÀÜy])2\\nL(y, E[ÀÜy])\\nVariance\\nE[(E[ÀÜy] ‚àíÀÜy)2]\\nE[L(ÀÜy, E[ÀÜy])]\\n4Pedro Domingos. ‚ÄúA uniÔ¨Åed bias-variance decomposition‚Äù. In: Proceedings of 17th International Con-\\nference on Machine Learning. 2000, pp. 231‚Äì238.\\n5Thomas G Dietterich and Eun Bae Kong. Machine learning bias, statistical bias, and statistical variance\\nof decision tree algorithms. Tech. rep. Technical report, Department of Computer Science, Oregon State\\nUniversity, 1995.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 8}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 8\\nHence, as result from using the mode to deÔ¨Åne the main prediction of the 0-1 loss, the bias\\nis 1 if the main prediction does not agree with the true label y, and 0 otherwise:\\nBias =\\n(\\n1 if y Ã∏= E[ÀÜy],\\n0 otherwise.\\n(8)\\nThe variance of the 0-1 loss is deÔ¨Åned as the probability that the predicted label does not\\nmatch the main prediction:\\nV ariance = P(ÀÜy Ã∏= E[ÀÜy]).\\n(9)\\nNext, let us take a look at what happens to the loss if the bias is 0. Given the general\\ndeÔ¨Ånition of the loss, loss = bias + variance, if the bias is 0, then we deÔ¨Åne the loss as the\\nvariance:\\nLoss = 0 + V ariance = Loss = P(ÀÜy Ã∏= y) = V ariance = P(ÀÜy Ã∏= E[ÀÜy]).\\n(10)\\nIn other words, if a model has zero bias, it‚Äôs loss is entirely deÔ¨Åned by the variance, which\\nis intuitive if we think of variance in the context of being proportional overÔ¨Åtting.\\nThe more surprising scenario is if the bias is equal to 1. If the bias is equal to 1, as explained\\nby Pedro Domingos, the increasing the variance can decrease the loss, which is an interesting\\nobservation. This can be seen by Ô¨Årst rewriting the 0-1 loss function as\\nLoss = P(ÀÜy Ã∏= y) = 1 ‚àíP(ÀÜy = y).\\n(11)\\n(Note that we have not done anything new, yet.) Now, if we look at the previous equation\\nof the bias, if the bias is 1, we have $ y Ã∏= E[{ÀÜy}]$.Ify is not equal to the main prediction,\\nbut y is also is equal to ÀÜy, then ÀÜy must be equal to the main prediction. Using the ‚Äúinverse‚Äù\\n(‚Äú1 minus‚Äù), we can then write the loss as\\nLoss = P(ÀÜy Ã∏= y) = 1 ‚àíP(ÀÜy = y) = 1 ‚àíP(ÀÜy Ã∏= E[ÀÜy]).\\n(12)\\nSince the bias is 1, the loss is hence deÔ¨Åned as ‚Äúloss = bias - variance‚Äù if the bias is 1 (or\\n‚Äúloss = 1 - variance‚Äù). This might be quite unintuitive at Ô¨Årst, but the explanations Kong,\\nDietterich, and Domingos oÔ¨Äer was that if a model has a very high bias such that it main\\nprediction is always wrong, increasing the variance can be beneÔ¨Åcial, since increasing the\\nvariance would push the decision boundary, which might lead to some correct predictions\\njust by chance then. In other words, for scenarios with high bias, increasing the variance\\ncan improve (decrease) the loss!\\n8.6\\nConclusion\\nIn this lecture, we decomposed the squared error loss into variance and bias terms and\\ndiscussed how these components relate to overÔ¨Åtting and underÔ¨Åtting. Then, we referred\\nto a bias-variance decomposition that Kong & Dietterich deÔ¨Åned for the 0-1 loss. Pedro\\nDomingos later generalized this further, including the noise term, which we did not discuss\\nin this lecture. However, interested students are encouraged to read the original paper:\\n‚Ä¢ Domingos, P. (2000). A uniÔ¨Åed bias-variance decomposition. In Proceedings of 17th\\nInternational Conference on Machine Learning (pp. 231-238).6\\n6https://homes.cs.washington.edu/‚àºpedrod/bvd.pdf'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.19', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-29T02:28:51-05:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'total_pages': 10, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2018-10-29T02:28:51-05:00', 'trapped': '', 'modDate': \"D:20181029022851-05'00'\", 'creationDate': \"D:20181029022851-05'00'\", 'page': 9}, page_content='Sebastian Raschka\\nSTAT479 FS18. L01: Intro to Machine Learning\\nPage 9\\nNow, we should be more familiar with the terms bias and variance (or, as statistics students,\\nconsider this as a refresher) and how it relates to overÔ¨Åtting and underÔ¨Åtting if we say that\\na model has a high variance or high bias, respectively.\\nIn the next lecture, we will take a closer look at the holdout method for model evaluation\\n(and estimating the generalization performance). Also, we will discuss several methods for\\nconstructing conÔ¨Ådence intervals.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 0}, page_content='GRADIENT DESCENT\\nArshia Anjum and Sibabrata Biswal\\nNational Institute of Science Education and Research ,\\nBhubaneswar,Odisha\\nJanuary 31, 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 1}, page_content='PART I: WHAT IS GRADIENT DESCENT?\\n1\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n2\\nThe Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 2}, page_content='PART II: GRADIENT DESCENT - DETAILED WORKING\\n1\\nAlgorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2\\nGradient Descent of Simple Linear Regression Model (Example) . . . . . . . . . . . . . . . 12\\n3\\nRequirements of Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n4\\nFunction Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n5\\nAll the Requirements of Gradient Descent: Listed . . . . . . . . . . . . . . . . . . . . . . . 21\\n2 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 3}, page_content='PART III: VARIOUS TYPES OF GRADIENT DESCENT\\n1\\nTypes of Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n2\\nStochastic Gradient Descent (SGD) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n3\\nBatch Gradient Descent (BGD) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n4\\nMini-Batch Gradient Descent (MBGD) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n3 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 4}, page_content='PART IV: PSEUDO-CODE FOR GRADIENT DESCENT\\n1\\nPseudo-Code for Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n2\\nPseudo-Code for Stochastic Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n3\\nPseudo-Code for Batch Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n4\\nPseudo-Code for Mini-Batch Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n5\\nPython Code for Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n4 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 5}, page_content='PART V: APPLICATION OF GRADIENT DESCENT\\n1\\nGradient Descent Example 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n2\\nGradient Descent Example 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n5 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 6}, page_content='PART VI: IS GRADIENT DESCENT A GOOD ALGORITHM?\\n1\\nAdvantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\n2\\nDisadvantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\\n6 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 7}, page_content='Part I\\nWHAT IS GRADIENT DESCENT?\\n7 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 8}, page_content='INTRODUCTION\\nGradient Descent is\\n‚ñ∂An optimisation technique/algorithm.\\n‚ñ∂Mostly used in supervised machine learning models and deep learning.\\n‚ñ∂Also called as first order optimisation algorithm.\\n‚ñ∂One of the most used algorithms for optimisation of parameters in ML models.\\nThe meaning of Gradient Descent:\\n‚ñ∂The meaning of Gradient - first order derivative/ slope of a curve.\\n‚ñ∂The meaning of descent - movement to a lower point.\\n‚ñ∂The algorithm thus makes use of the gradient/slope to reach the minimum/ lowest point of a\\nMean Squared Error (MSE) function.\\n8 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 9}, page_content='THE FORMULA\\nWhile performing the algorithm of gradient descent, the machine iteratively calculates the next\\npoint it has to reach by using the gradient at the current position, and subtracting it from the\\nparameter value by scaling it with a learning rate. The formula for the same looks like:\\npn+1 = pn ‚àíl‚àáf(pn)\\n(1)\\nWhere, l is the learning rate, pn is the parameter to be optimised, and ‚àáf(pn) depicts the gradient of\\nthe expected loss function.\\n9 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 10}, page_content='Part II\\nGRADIENT DESCENT - DETAILED WORKING\\n10 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 11}, page_content='ALGORITHM\\n‚ñ∂Suppose we have two unknown parameters, p1 and p2.\\n‚ñ∂Assume the parameters (initial values of p1 and p2).\\n‚ñ∂Plot the expected loss function for various values of the other parameter, p2.\\n‚ñ∂The point on the curve, where the value of the function is minimum, is the required value of p2\\ngiven p1. (Note that the value of p2 might change with a change in p1).\\n‚ñ∂Now we change the values of p1 and p2 such that the expected loss reduces after each iteration.\\n‚ñ∂To define the iterations, we have the formula:\\npn+1 = pn ‚àíl‚àáf(pn)\\n(2)\\nwhere, l defines the learning parameter and n defines the iteration number.\\n11 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 12}, page_content='GRADIENT DESCENT OF SIMPLE LINEAR REGRESSION MODEL (EXAMPLE)\\n‚ñ∂The Simple Linear Regression Model predicts the outcome through the equation [‚ÄúNormal\\nEquations‚Äù 2008]\\nypredicted = yp = w √ó x + b\\n(3)\\nwhere, w is the slope of the linear curve, and b is the intercept value. x being the independent\\nvariable (the data given to us) and y being the dependent variable (the label we need to find).\\n‚ñ∂The Loss function for the same becomes\\nL(w, b) = 1\\nn\\nn\\nX\\ni=0\\n(yi(predicted) ‚àíyi(actual))2 = 1\\nn\\nn\\nX\\ni=0\\n(yp\\ni ‚àíya\\ni )2\\n(4)\\n‚ñ∂Now, Gradient Descent has to minimize this Loss function by choosing a set of w and b\\nappropriately.\\n‚ñ∂We begin by choosing a set w0 and b0. Then the equation becomes:\\nyp\\ni = w0xi + b0\\n(5)\\n‚ñ∂Now we have to update w and b re-iteratively to minimize the Loss function L(w, b). The\\nequations for the same become:\\nw\\n=\\nw ‚àíl‚àÜw\\n(6)\\nb\\n=\\nb ‚àíl‚àÜb\\n(7)\\nwhere l is the learning parameter.\\n12 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 13}, page_content='GRADIENT DESCENT OF SIMPLE LINEAR REGRESSION MODEL (EXAMPLE)\\n‚ñ∂To calculate ‚àÜw and ‚àÜb we use the relation:\\n‚àÜw\\n=\\n‚àÇL(w, b)\\n‚àÇw\\n(8)\\n‚àÜb\\n=\\n‚àÇL(w, b)\\n‚àÇb\\n(9)\\n‚ñ∂The definition of the Loss function was given in Eq. (4). Using the Simple Linear Regression\\nModel Line (3),\\nL(w, b) = 1\\nn\\nn\\nX\\ni=0\\n(wxi + b ‚àíya\\ni )2\\n(10)\\n‚ñ∂This makes the Delta functions[Gradient Descent n.d.]/ Gradient functions to be:\\n‚àÇL(w, b)\\n‚àÇw\\n=\\n1\\nn2\\nn\\nX\\ni=0\\n(wxi + b ‚àíya\\ni )w\\n(11)\\n‚àÇL(w, b)\\n‚àÇc\\n=\\n1\\nn2\\nn\\nX\\ni=0\\n(wxi + b ‚àíya\\ni )b\\n(12)\\n13 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 14}, page_content='GRADIENT DESCENT OF SIMPLE LINEAR REGRESSION MODEL (EXAMPLE)\\n‚ñ∂After getting the Delta function values/ gradients through (11 and 12), we substitute them in\\nEq. (6 and 7).\\n‚ñ∂This counts for one iteration, however, it possible to get more accurate values, hence more such\\niterations are done until we reach the best fit.\\nFigure. Linear Regression Example for Gradient Descent.[Visualizing the gradient descent method n.d.]\\n14 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 15}, page_content='LEARNING PARAMETER\\n‚ñ∂The learning rate is mentioned in Eq (6 and 7) is an important parameter.\\n‚ñ∂It decides the rate at which the algorithm learns/ improves its unknown parameters [Jordan\\n2018].\\n‚ñ∂The gradients were calculated in Eq. (8 and 9), however, those used alone are not enough to\\nmake sure we reach the best fit at a low computational time.\\n‚ñ∂The learning parameter l decides the step size of the learning/iteration.\\n‚ñ∂There can be three cases when we don‚Äôt use the learning parameter:\\n1. The gradient is too small, and we reach the best fit point in too many iterations.\\n2. The gradient is too high, and we jump the best fit point to go farther away from it.\\n3. The gradient is just right, and we reach the best fit just fine.\\n‚ñ∂To make sure that the step size is just right, we use the learning parameter, which scales the\\nchange in the previous value of the parameter to get the new value.\\n15 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 16}, page_content='FUNCTION REQUIREMENTS\\n‚ñ∂The gradient descent algorithm is not written for all types of functions.\\n‚ñ∂The function has to satisfy two conditions for Gradient Descent to be applicable on it:\\n1. It has to be differentiable\\n2. It has to be a convex function\\n16 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 17}, page_content='FUNCTION REQUIREMENTS\\nDIFFERENTIABILITY\\n‚ñ∂Being differentiable means the function should have a derivative at each point in its domain.\\n(cf. 2)\\nFigure. Examples of differentiable functions.[Kwiatkowski 2022]\\n17 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 18}, page_content='FUNCTION REQUIREMENTS\\nDIFFERENTIABILITY\\n‚ñ∂Not all functions satisfy this condition. Some examples of functions not satisfying this\\ncondition is given below in Fig. 3\\n‚ñ∂If the function is not differentiable at all points, there may arise a circumstance where the\\ngradient algorithm is not able to iteratethe values as there is no gradient to work with.\\nFigure. Examples of non-differentiable functions.[Kwiatkowski 2022]\\n18 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 19}, page_content='FUNCTION REQUIREMENTS\\nCONVEX FUNCTION\\n‚ñ∂A convex function is one in which if any two points are connected on the curve, the line\\nsegment lies on or above the curve.\\n‚ñ∂If a function is non-convex, we do not have a surity that the gradient descent algorithm would\\ngive us the local minima or the global minima as the result.\\nFigure. Example of convex and non-convex functions.[Kwiatkowski 2022]\\n19 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 20}, page_content='FUNCTION REQUIREMENTS\\nCONVEX FUNCTION\\n‚ñ∂A special case is where the function has a saddle point. At the saddle point, the function has\\ngradient as zero, but the double derivative is also zero at that point. This defines that the point\\nis a saddle and hence not a global minimum.\\nFigure. Example of saddle point in a function.[Kwiatkowski 2022]\\n20 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 21}, page_content='ALL THE REQUIREMENTS OF GRADIENT DESCENT: LISTED\\nTherefore, the gradient descent algorithm takes 5 parameters as its basic requirement:\\n‚ñ∂Initial Point (w0, b0)\\n‚ñ∂Gradient Function\\n‚ñ∂Learning Rate (l)\\n‚ñ∂Number of iterations (n)\\n‚ñ∂Tolerance - helps to give an end point/ stop to an algorithm.\\n21 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 22}, page_content='Part III\\nTYPES OF GRADIENT DESCENT\\n22 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 23}, page_content='TYPES OF GRADIENT DESCENT\\nThere are three types of Gradient Descent Algorithms:\\n1. Stochastic Gradient Descent (SGD)\\n2. Batch Gradient Descent (BGD)\\n3. Mini-Batch Gradient Descennt (MBGD)\\n23 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 24}, page_content='STOCHASTIC GRADIENT DESCENT (SGD)\\n‚ñ∂SGD computes the gradient for only one random sample at each iteration.\\n‚ñ∂This property of SGD helps in it being faaster and efficient as it does not have to process all the\\ndata in each of its iterations.\\n‚ñ∂However, the randomness of SGD contributes to the fact that it can in some cases give the\\nsuboptimal solutions/local minima as the result rather than the global minimum.\\n‚ñ∂One of the techniques to overcome this fault is to decrease the learning rate of the model over\\ntime, which helps in reducing the updates in the parameter with each iteration.\\n‚ñ∂SGD also has its variants, like Mini-Batch SGD, where the Gradient ddescent is done for a\\nrandom subset of data, and Momentum SGD, where a term is added to the gradient update to\\nhelp with the optimisation and avoiding getting stuck at a local minima.\\n‚ñ∂SGD is majorly used in Deep Learning and has found applications in classification, regression,\\nand neural machine translation.\\n24 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 25}, page_content='BATCH GRADIENT DESCENT (BGD)\\n‚ñ∂BGD computes the gradient based on the average of the gradients of all data samples in the\\ntraining set.\\n‚ñ∂Therefore, for each iteration, the gradient has to be calculated for the entire dataset, making\\nBGD a computationally expensive process for huge datasets.\\n‚ñ∂However, it also gives BGD the advantage of being more stable and avoiding overfitting\\ncompared to SGD.\\n‚ñ∂The learning parameter has to be chosen carefully, so that with each iteration the step size\\ndoesn‚Äôt get bigger or diverge from the minima.\\n‚ñ∂BGD is usually used in simpler models with lesser data.\\n‚ñ∂It is widely used in linear regression and logistic regression, not so much in deep learning\\nwhere the training set is typically large and the models have many parameters.\\n25 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 26}, page_content='MINI-BATCH GRADIENT DESCENT (MBGD)\\n‚ñ∂MBGD is a combination of SGD and BGD.\\n‚ñ∂MBGD, in comparison to BGD, computed the gradient over a subset of the data, called the\\nmini-batch.\\n‚ñ∂This helps in computing faster than BGD and avoiding overfitting as compared to SGD.\\n‚ñ∂The mini-batch size is a trade-off between speed and stability, with smaller sizes leading to\\nfaster convergence but increased variability in the optimization, and larger sizes leading to\\nmore stable convergence but slower processing times.\\n‚ñ∂The learning rate, which determines the size of the parameter update at each iteration, must be\\ncarefully tuned to ensure that the optimization converges to the minimum and does not\\noscillate or diverge.\\n‚ñ∂Mini-Batch Gradient Descent is widely used in deep learning and has been applied to a variety\\nof tasks, including classification, regression, and neural machine translation.\\n26 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 27}, page_content='Part IV\\nPSEUDO-CODE FOR GRADIENT DESCENT\\n27 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 28}, page_content='PSEUDO-CODE FOR GRADIENT DESCENT\\nLet us look at the pseudo-code of the gradient descent algorithm:\\nInput: parameters (Œ∏), gradient of the loss function with respect to\\nthe parameters (dŒ∏), learning rate (Œ±)\\nUpdate parameters: Œ∏ = Œ∏ ‚àíŒ±√ó dŒ∏\\nOutput: updated parameters (Œ∏)\\n28 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 29}, page_content='PSEUDO-CODE FOR STOCHASTIC GRADIENT DESCENT\\nLet us look at the pseudo-code of the gradient descent algorithm:\\nINPUT: cost function J(Œ∏), learning rate Œ±, numberofiterationsN\\nINITIALIZE: random Œ∏\\nFOR i = 1 to N DO\\nFOR j = 1 to number of training examples m DO\\nCompute the gradient of J with respect to Œ∏ for a single training example:\\ngradient = ‚àáŒ∏ J(Œ∏, xj, yj)\\nUpdate the parameters Œ∏ :\\nŒ∏ = Œ∏ ‚àíŒ±√ó gradient\\nEND FOR\\nEND FOR\\nOUTPUT: Œ∏\\n29 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 30}, page_content='PSEUDO-CODE FOR BATCH GRADIENT DESCENT\\nLet us look at the pseudo-code for Batch Gradient Descent:\\nINPUT: cost function J(Œ∏), learning rate Œ±, number of iterations N\\nINITIALIZE: random Œ∏\\nFOR i = 1 to N DO\\nCompute the gradient of J with respect to Œ∏ for all training examples:\\ngradient = 1/m * ‚àáŒ∏ Œ£(J(Œ∏, xj, yj))\\nUpdate the parameters Œ∏ :\\nŒ∏ = Œ∏ ‚àíŒ±√ó gradient\\nEND FOR\\nOUTPUT: Œ∏\\n30 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 31}, page_content='PSEUDO-CODE FOR MINI-BATCH GRADIENT DESCENT\\nLet us look at the pseudo-code for mini-batch gradient descent:\\nINPUT: cost function J(Œ∏), learning rate Œ±, number of iterations N,\\nbatch size B\\nINITIALIZE: random Œ∏\\nFOR i = 1 to N DO\\nSplit the training examples into B mini-batches of size b:\\nFOR j = 1 to number of mini-batches B DO\\nCompute the gradient of J with respect to Œ∏ for a mini-batch\\nof training examples:\\ngradient = 1/b √ó ‚àáŒ∏ Œ£(J(Œ∏, xj, yj))\\nUpdate the parameters Œ∏ :\\nŒ∏ = Œ∏ ‚àíŒ±√ó gradient\\nEND FOR\\nEND FOR\\nOUTPUT: Œ∏\\n31 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 32}, page_content='PYTHON CODE FOR GRADIENT DESCENT\\ndef GradientDescent(X, y, w, b, learningRate, MaxIterations):\\nfor i in range(MaxIterations):\\n# Compute the error/cost function J(w,b)\\nJ = CostFunction(X, y, w, b)\\n# Compute the gradient of the cost function with respect to w and b\\ndw = gradientOfw(X, y, w, b)\\ndb = gradientOfb(X, y, w, b)\\n# Update the parameters:\\nw = w - learningRate * dw\\nb = b - learningRate * db\\nreturn w, b\\n32 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 33}, page_content='Part V\\nAPPLICATIONS OF GRADIENT DESCENT\\n33 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 34}, page_content='GRADIENT DESCENT EXAMPLE 1\\nOne common example of gradient descent is training a linear regression model. The model tries to\\nfit a line to a set of data points by minimizing the mean squared error between the predicted values\\nand the actual target values. The model adjusts the parameters (slope and intercept) in the direction\\nof the negative gradient of the error function, until the error reaches a minimum. See section (2),\\nwhich clearly explains this example.\\n34 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 35}, page_content='GRADIENT DESCENT EXAMPLE 2\\n‚ñ∂Let‚Äôs say we want to minimize the following quadratic function:\\nQ(x, y) = (x ‚àí2)2 + (y ‚àí3)2\\n(13)\\n‚ñ∂The gradient of Q(x, y) with respect to x and y is given by:\\n‚àáQ(x, y) = [2(x ‚àí2), 2(y ‚àí3)]\\n(14)\\n‚ñ∂The gradient descent algorithm updates x and y in each iteration according to the formula:\\nx\\n=\\nx ‚àíŒ± √ó 2(x ‚àí2)\\n(15)\\ny\\n=\\ny ‚àíŒ± √ó 2(y ‚àí3)\\n(16)\\nwhere Œ± is the learning rate.\\n‚ñ∂By repeating the above updates, the algorithm converges to the minimum of Q(x, y), which is\\n(2, 3).\\n‚ñ∂The rate of convergence depends on the choice of Œ±, but as Œ± approaches 0, the convergence\\nbecomes slower, while as Œ± approaches infinity, the algorithm may not converge at all.\\n35 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 36}, page_content='Part VI\\nIS GRADIENT DESCENT A GOOD ALGORITHM?\\n36 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 37}, page_content='ADVANTAGES\\nGradient descent is a widely used optimization algorithm in various fields such as machine\\nlearning, deep learning, and optimization problems. It has several advantages, including:\\n1. Ease of implementation: Gradient descent is relatively easy to implement, as it only requires\\nthe calculation of gradients and updates to the parameters. It does not require complex\\nmathematical techniques like linear algebra, eigenvalue decomposition, or matrix inversion.\\n2. Convergence guarantee: Gradient descent is guaranteed to converge to a minimum, under\\ncertain conditions such as the cost function being differentiable and having a unique global\\nminimum. The convergence speed can be controlled by the learning rate, which can be set\\nappropriately to achieve a good balance between convergence speed and accuracy.\\n3. Scalability: Gradient descent can be used for high-dimensional problems and can scale well\\nwith large amounts of data. In practice, the convergence of gradient descent can be accelerated\\nthrough techniques such as batch normalization, early stopping, or momentum.\\n4. Versatility: Gradient descent can be applied to a wide range of optimization problems,\\nincluding linear regression, logistic regression, and neural networks. It can also be used for\\nnon-convex optimization problems, where multiple local minima may exist, although\\nconvergence to a good solution may be less certain in such cases.\\n37 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 38}, page_content='DISADVANTAGES\\nHowever, gradient descent has some limitations as well, including:\\n1. Sensitivity to learning rate: The choice of the learning rate can have a significant impact on the\\nconvergence of the algorithm. If the learning rate is too high, the algorithm may oscillate or\\nconverge slowly, while if it is too low, the convergence may be slow.\\n2. Sensitivity to initialization: The initial values of the parameters can also have an impact on the\\nconvergence of the algorithm. If the parameters are initialized too far from the minimum, the\\nalgorithm may converge slowly, or get stuck in a suboptimal solution.\\n3. Convergence speed: The convergence speed of gradient descent can be slow for some\\nproblems, especially for high-dimensional or non-convex optimization problems. This can be\\nmitigated to some extent by using techniques such as mini-batch gradient descent, momentum,\\nor adaptive learning rates.\\n4. Termination of Algorithm: The termination of this algorithm isn‚Äôt as easy as it seems. It is either\\ndone by giving a tolerance limit or an upper cap on the number of iterations.\\n5. Correctness: Though the algorithm makes sure that output converges to best fit, it doesn‚Äôt\\nguarantee the correctness of the solution.\\n38 / 39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with Beamer class', 'creationdate': '2023-01-31T17:02:04+00:00', 'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'total_pages': 40, 'format': 'PDF 1.5', 'title': 'Gradient Descent', 'author': 'Arshia Anjum and Sibabrata Biswal', 'subject': '', 'keywords': '', 'moddate': '2023-01-31T17:02:04+00:00', 'trapped': '', 'modDate': 'D:20230131170204Z', 'creationDate': 'D:20230131170204Z', 'page': 39}, page_content='REFERENCES I\\nGradient Descent (n.d.). https://www.niser.ac.in/ smishra/teach/cs460/2020/lectures/lec8/.\\n[Online; accessed 2023-01-31].\\nJordan, Jeremy (Mar. 2018). Setting the learning rate of your neural network.\\nhttps://www.jeremyjordan.me/nn-learning-rate/. [Online; accessed 2023-01-31].\\nKwiatkowski, Robert (July 2022). Gradient Descent Algorithm ‚Äî a deep dive.\\nhttps://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21.\\n[Online; accessed 2023-01-31].\\n‚ÄúNormal Equations‚Äù (2008). In: The Concise Encyclopedia of Statistics. New York, NY: Springer\\nNew York, pp. 380‚Äì382. ISBN: 978-0-387-32833-1. DOI: 10.1007/978-0-387-32833-1_286.\\nURL: https://doi.org/10.1007/978-0-387-32833-1_286.\\nVisualizing the gradient descent method (n.d.).\\nhttps://scipython.com/blog/visualizing-the-gradient-descent-method/. [Online; accessed\\n2023-01-31].\\n39 / 39'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 0}, page_content='35 \\n      UNIT 2 \\nEVALUATION METRICS \\nFOR MACHINE LEARNING \\nMODELS   \\nStructure  \\n2.1    Introduction \\n          Expected Learning Outcomes   \\n2.2    Partition of a Dataset into \\nTraining and Testing \\nDatasets \\n2.3    Overall Accuracy of an \\nAlgorithm \\n2.4    Confusion Matrix and \\nEvaluation Metrics \\n2.5    Summary \\n2.6    Terminal Questions \\n2.7    Solutions/Answers\\n2.1   INTRODUCTION  \\nIn the previous unit, you studied types of machine learning. Like me, you were \\nalso eagerly waiting to see how a machine can learn from data. In Sec. 2.3, \\nyou get a tiny flavour of that. But the actual objective of this unit is to explain \\nsome performance measures of evaluating a machine learning algorithm on \\nthe basis of which we can say that one algorithm is better than the other. To \\ndo so, first, we have to build at least two machine learning algorithms so that \\nwe can compare their performance measures. In machine learning \\nterminology, performance measures are known as evaluation metrics. \\nHowever, before doing all this, first we have to define training and testing \\ndatasets and the same is done in Sec. 2.2. After that some evaluation metrics \\nare discussed in Secs. 2.3 and 2.4.                 \\nWhat we have discussed in this unit is summarised in Sec. 2.5. Self-\\nAssessment Questions (SAQs) have been given in some sections which are \\ngenerally based on the content discussed in that section. But to give you a \\ngood practice of what we have discussed in this unit, some more problems \\nbased on the entire unit are given in Sec. 2.6 under the heading Terminal \\nQuestions. Due to the reason mentioned in Sec. 1.1 of Unit 1 of this course, \\nsolutions of all the SAQs and Terminal Questions are given in Sec. 2.7.  \\nIn the next unit, you will study the OC curve and the area under the curve \\n(AUC) in detail.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 1}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n36 \\nExpected Learning Outcomes  \\nAfter completing this unit, you should be able to:  \\n‚ùñ explain training and testing datasets; \\n‚ùñ obtain a confusion matrix of an algorithm and some other evaluation \\nmetrics such as sensitivity, specificity, positive predictive value, negative \\npredictive value, overall accuracy, balanced accuracy, etc. \\n2.2   PARTITION OF A DATASET INTO TRAINING \\nAND TESTING DATASETS  \\nFrom Sec. 1.2 of the previous unit, recall that the term \"machine learning\" was \\ncoined by computer scientist Arthur Samuel in 1959, and he defined machine \\nlearning as follows: \\n‚ÄúThe field of study that gives computers the ability to learn without being \\nexplicitly programmed‚Äù. \\n \\n \\n \\n \\n \\n‚Ä¶ (2.1) \\nIf you know the meaning of ‚Äúexplicitly programmed‚Äù used in this definition, then \\ngood, but if you do not know its meaning, very good. Here, by very good, I \\nmean do not lose heart, you are reading IGNOU study learning material (SLM) \\nwhich is known for its three features: self-explanatory, self-contained and \\nteacher-built-in. So, if you go through the SLM sequentially, then you will get \\nthe answers to most of your queries related to the learning part of the topics \\ndiscussed in SLM. \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.2) \\nNow, come to the point of what the meaning of explicitly programmed is. It \\nmeans you have a complete flow chart for every possible situation and clear-\\ncut instructions for each situation on what to do. The job of a computer is just \\nto follow a given set of rules and perform operations accordingly. The list of all \\nrules and operations in a logical sequence is prepared by a traditional \\ncomputer programmer. For example, if you want to obtain the mean of the \\nnumbers 3, 6, 7, 4 using R software, then it can be done as follows: \\n \\nNow, here, first of all, the four numbers 3, 6, 7, 4 are stored in a vector x1. \\nAfter that, we have applied the built-in function mean(). The programming of \\nmean() function is explicitly programmed in the R software, i.e., the system will \\nperform the operation Sum of all observations .\\nNumber of observations  So, hope this simple example \\nhas explained the meaning of explicitly programmed.  \\n \\n‚Ä¶ (2.3) \\nIn this definition, the second important thing that you should know is the \\nmeaning of ‚Äúability to learn‚Äù. The learning part in machine learning algorithms \\nis dictated by the dataset, and the more data we have, the more the machine \\nlearning algorithm learns. So, the algorithm‚Äôs learning ability increases with \\nmore and more data we have to train the algorithm. So, the moral of the story'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 2}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n37 \\nis we need a good amount of data not only for training an algorithm, but \\nwe also need a good amount of data to test the trained algorithm. ‚Ä¶ (2.4) \\nTo define these two datasets (i) Training dataset and (ii) Testing dataset is the \\nobjective of this section. So, it is the right place to meet that objective. This \\nclassification of the original dataset into two datasets: training and testing \\ndatasets is visualised in Fig. 2.1. \\nTraining Dataset: The original dataset is partitioned into two datasets \\ngenerally in the ratio 80 : 20 or 75 : 25 or 70 : 30. That is, the larger dataset \\ncontains 70 to 80% of the original dataset. This larger dataset, which is a \\nrandom subset of the original dataset, is used to train the machine learning \\nalgorithm and is known as the training dataset. A machine learning algorithm \\ntries to find insights into the training dataset and discovers patterns in the \\ntraining dataset. So, the more training data an algorithm has, the more \\nlearning will take place and therefore more accuracy will be there when we will \\napply this trained algorithm to an unseen dataset.   \\n \\n‚Ä¶ (2.5) \\nTesting Dataset: The original dataset is partitioned into two datasets \\ngenerally in the ratio 80 : 20 or 75 : 25 or 70 : 30. That is, the smaller dataset \\ncontains 20 to 30% of the original dataset. This smaller dataset, which is a \\nrandom subset of the original dataset, is used to test the trained machine \\nlearning algorithm and is known as the test dataset. The test dataset is used to \\ndetermine the performance of the trained model on an unseen dataset.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.6) \\nBefore closing this section, one important point that you should keep in mind is \\nthat the difference between the performance measures of an algorithm \\nbetween the training dataset and testing dataset should be less. If the \\nalgorithm performs well in the training dataset but poorly in the testing dataset, \\nit is an indication of the problem of overfitting.    \\n \\n \\n‚Ä¶ (2.7) \\n \\nFig. 2.1: Visualisation of the classification of the original dataset into two datasets \\nNow, you can try the following Self-Assessment Question. \\nSAQ 1 \\nState whether the following statement is TRUE or FALSE. Give a reason in \\nsupport of your answer.  \\nGenerally, a testing dataset is a random subset of the original dataset and \\ncontains 20 to 30% instances of the original dataset.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 3}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n38 \\n2.3   OVERALL ACCURACY OF AN ALGORITHM  \\nAs mentioned in Sec. 2.1 of this unit, the main objective of this unit is to \\nexplain some evaluation metrics of machine learning algorithms. We want to \\ndo it so that later on, we can use these metrics to compare two machine \\nlearning algorithms to determine which is better than the other with respect to \\na metric. So, first, we have to build two machine learning algorithms.  \\nLet us consider the GaltonFamilies dataset in the HistData package of R. I \\nhave already installed this package in my system. So, I have to just load this \\npackage in my system and the same can be done as follows. \\n \\nAfter that, we have to check how many rows and columns are in the \\nGaltonFamilies dataset, which can be checked as follows. \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.8) \\nWe see that there are 934 rows and 8 columns in this dataset. To see the first \\ntwo rows of this dataset, we can run the following R code. \\n \\nTo give you a tiny flavour of a machine learning algorithm, we are going to \\nbuild a machine learning algorithm where the sex of a child will be predicted \\non the basis of the given height of the child. So, we need only two variables, \\ngender and childHeight, out of the 8 variables in this dataset. This can be done \\nas follows. \\n \\nNow, let us see the first two rows of this new data frame, which has only two \\ncolumns. \\n \\nGreat, we need only two variables in this new dataset. Now, let us see how \\nmany male and female children there are. This can be obtained by running the \\nfollowing R code. \\n \\n \\n \\n \\n‚Ä¶ (2.10) \\nFrom a machine learning algorithm point of view, it is great that the ratio of \\nmale and female children is almost equal. In other words, we can say that this \\ndataset is not biased from a gender point of view. \\nBut dear learner, I want to explain an issue that you may face in your career \\nas a data scientist. To explain that point, I have to start with a biased dataset'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 4}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n39 \\nwith respect to some variable. The technical word that is used to express this \\nfact is prevalence, which you have already studied in Section 2.4 of Unit 2 of \\nthe course MST-019 (you may refer to page number 38). In this dataset \\nprevalences of male and female children are given by \\n \\n‚Ä¶ (2.11) \\nPrevalence of male children in the study \\nNumber of male children\\nTotal number of children\\n=\\n \\n \\n \\n \\n \\n                 \\n481\\n481\\n0.5149893\\n453\\n481\\n934\\n=\\n=\\n=\\n+\\n \\nPrevalence of female children in the study \\nNumber of male children\\nTotal number of children\\n=\\n \\n \\n \\n \\n \\n                    \\n453\\n453\\n0.4850107\\n453\\n481\\n934\\n=\\n=\\n=\\n+\\n \\nSo, as mentioned earlier, the prevalence of male and female children is almost \\nequal. This much difference is considered ok. But we want to make it biased \\nwith respect to the gender variable, so that as a data scientist, you should \\nhave an idea of the effect of prevalence in building a machine learning \\nalgorithm. So, to make it biased with respect to the gender variable, let us \\nremove 300 rows of female children randomly from this dataset. This can be \\ndone as follows. \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.12) \\nFirst of all, we have to set a seed for reproducibility purposes. \\n \\nNext, we have to identify the positions of rows corresponding to female \\nchildren. This can be done as follows. \\n \\nSo, positions of rows of female children have been stored in the variable \\nfemale_rows. If we want to see the first 10 positions of the female children, it \\ncan be seen by running the following R code. \\n \\nSince the dataset GaltonFamilies_2 has 453 female children (you may refer to \\n2.10), so we expect that there should be 453 elements in the vector \\nfemale_rows. Let us verify it. \\n \\nSo, verification is done. Next, we have to select 300 row positions randomly \\nout of 453, and it can be done using the sample() function as follows. \\n \\nNext, we have to remove rows corresponding to these randomly selected 300 \\nrows from the data frame GaltonFamilies_2, and it can be done as follows.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 5}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n40 \\nNow, we expect that the number of rows in GaltaonFamilies_300 should be \\n634 (= 934 ‚Äì 300). Let us check it. \\n \\n \\n \\n \\n \\n‚Ä¶ (2.13) \\nLet us now check the number of male and female children in this dataset. \\n  \\n \\n \\n‚Ä¶ (2.14) \\nFinally, we now have a data frame GaltonFamilies_300, to work with.   \\nIn usual notations, we denote the feature variable by x and the target variable \\nby y. Let us store values in x and y as follows. \\n \\n \\n \\n‚Ä¶ (2.15) \\nNext, to split the dataset GaltonFamilies_300 into train and test datasets, we \\nwill use createDataPartition() function of the caret package. I have already \\ninstalled the caret package, so I have to just load it. Also, we will use the pipe \\noperator, which lies in the package tidyverse. I have already installed the \\ntidyverse package. So, I have to just load it. This time, if we want, we can use \\na different seed before running the createDataPartition() function. Let us use \\n2007. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.16) \\nLet us explain the roles of the arguments of the createDataPartition() function. \\n‚Ä¢ The times argument tells how many random samples of indices we want to \\ncreate. Here, the times argument is 1, which means we need only one such \\nsample. \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.17) \\n‚Ä¢ Argument p tells the proportion of the indices of the data. Here, p is 0.5 \\nmeans we need 50% of the data.  \\n \\n \\n \\n‚Ä¶ (2.18) \\n‚Ä¢ The argument list simply tells whether we need the output of the function as \\na list or not. If the list argument is set to TRUE, the output will be a list; \\nhere, we set it to FALSE, so the output will not be a list.  \\n‚Ä¶ (2.19) \\nNow, using (2.16), we can obtain training and testing datasets using the \\nfollowing R code given as follows. \\n \\n‚Ä¶ (2.20) \\nLet us first use the sample() function to decide sex of the child. We know that \\nsample() function randomly selects a male or a female. So, sample() function \\nis not using the feature childHeight in its prediction. It is a totally random \\nselection. This can be done as follows.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 6}, page_content=\"Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n41 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.21) \\nHere, the target variable is gender, which is a categorical variable. We know \\nthat for a categorical variable, the suitable measure that can be used to check \\nhow many of them are predicted correctly is the proportion (you may refer to \\npage number 30 of the course MST-019). This can be seen by running the \\nfollowing code. \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.22) \\n \\n \\n \\n‚Ä¶ (2.23) \\nThe result is close to 50% as expected, because we selected males and \\nfemales randomly. This output may change run to run because we did not use \\nany seed before running the R code (2.21). Note that here we have compared \\nthe values of the data object y_hat_1 with the values of the data object \\ntest_dataset$gender, not with train_dataset$gender, because evaluation of an \\nalgorithm is done using the test dataset, not the training dataset. The second \\npoint is that we created the y_hat_1 variable of length equal to the length of \\nthe variable test_index (you may refer to the code mentioned in 2.21). \\nBut we can do better if we use the information available in the dataset \\nGaltonFamilies_300. Let us obtain some information about this dataset using \\ntwo statistical tools: the mean and standard deviation of male and female \\nchildren's height separately. This can be obtained by running the following R \\ncode.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.24) \\nAfter getting this information, think for a while about how we can use this \\ninformation to make a better prediction of the sex of the children. \\nHope you have given some thought. One point that is striking in my mind is \\nthat the mean height of male children is 5 (\\n69.2\\n64.2)\\n=\\n‚àí\\n inches more than \\nthe mean height of female children. So, we should utilise this information in \\nour prediction. If you have any other brilliant idea(s), then you should also give \\nit(these) a try.  \\nWe know that the height of a population follows a normal distribution. We also \\nknow that in a normal distribution, 95% population lies within two standard \\ndeviations. But we take more than that, and consider all children having height \\ngreater than the mean minus two standard deviations as male. \\nSo, mean\\n2(Standard deviation)\\n69.2\\n2\\n2.62\\n69.2\\n5.24\\n63.96\\n‚àí\\n=\\n‚àí\\n\\uf0b4\\n=\\n‚àí\\n=\\n \\nLet us predict the gender of a child as male if the height is greater than 63.96 \\nand female otherwise. This can be done by using the following R code. \\n \\n‚Ä¶ (2.25)\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 7}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n42 \\nLet us now check the overall accuracy. \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.26) \\nGreat! Overall accuracy has increased from 49.37% to 83.59%. It indicates \\nthat there may be some other cutoff value which can do better. We will try that. \\nBut at this point, one question that may arise in your mind is here (means in \\n2.26), we compared y_hat_2 with y, while in (2.23) we did a comparison of \\ny_hat_1 with test_dataset$gender, not with y. Why did we do so? Good \\nquestion. It shows your learning sincerity and hunger to dive deeper into the \\nsubject. The answer to this question is y_hat_2 is created using x (you may \\nrefer to 2.25), which is of length 634, and so the length of y_hat_2 is also 634. \\nBut the length of test_dataset$gender is 318. We can verify it using the \\nfollowing codes. \\n \\nWe know that in a normal distribution, within 3 standard deviations around the \\nmean more than 99% values lie. So, let us obtain these values as follows. \\nmean\\n3(Standard deviation)\\n69.2\\n3\\n2.62\\n69.2\\n7.86\\n61.34 and 77.06.\\n=\\n\\uf0b4\\n=\\n=\\n\\uf06d\\uf06d\\uf06d\\n \\nSo, we check for cutoff values 61, 62, 63, ‚Ä¶, 77. First, we create a sequence \\nof these numbers as follows and save it under the name of the cutoff variable. \\n \\n \\n‚Ä¶ (2.27) \\nNow, we want to apply (2.25) for each value of the variable cutoff. That is, we \\nwant to apply a function to different values of an already created variable. \\nSuch a function that can perform this kind of job is the map_dbl() function of \\nthe purrr package. First, you have to install this package and then load it \\nbefore applying the map_dbl() function. I have already installed it in my \\nsystem. So, I only need to load it. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.28) \\nLet us see all values of overall accuracy just saved in the variable \\noverall_accuracy. \\n \\nWe see that the maximum value among these is 0.8544304. Let us find out at \\nwhich value of cutoff it is obtained. This can be found out by running the'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 8}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n43 \\nfollowing code. \\n \\n‚Ä¶ (2.29) \\nWe see that among the whole numbers 61, 62, 63, ‚Ä¶, 77, the number 64 \\nplays the role of the best cutoff. If we go in decimal numbers, then there may \\nbe some other number better than 64. If you are interested in getting that \\nnumber, then you have to just replace the value of ‚Äòby‚Äô argument in (2.27) by \\n0.1 or 0.01 or 0.001, etc. and run the codes mentioned in (2.28) and (2.29), \\nyou will get the number of your interest. \\nNote that in (2.28), we have used the training data set, while, as mentioned in \\n(2.4), we know that evaluation of a machine learning algorithm is done using a \\ntesting dataset instead of the training dataset. So, let us do that as follows. \\n \\nOverall accuracy on the test dataset can be obtained as follows. \\n \\n \\n \\n‚Ä¶ (2.30) \\nIt is less than the overall accuracy (0.8544304) of the training dataset but \\nmuch greater than the overall accuracy (0.4937107) of the guessing model. \\nNow, we move toward the learning side of the point that we discussed in \\n(2.11) and (2.12). The point of concern with overall accuracy, especially when \\nwe have a biased dataset, is that it may hide the truth with respect to the \\nactual prediction of each category (in the present case, individual accuracy of \\nmale and female children) of the variable of bias (in the present case gender is \\nthe variable of bias because we have more male than female children). So, \\nour next goal is to obtain the accuracy of male and female children, \\nindividually. This point and some other evaluation metrics are discussed in the \\nnext section.   \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.31) \\nNow, you can try the following Self-Assessment Question. \\nSAQ 2 \\nWrite any one line of R code where the pipe operator of the tidyverse package \\nis used. After getting the output explain how pipe operator works. Objective of \\nthis SAQ is to tell you the silent power of pipe operator so that it can motivate \\nyou to apply pipe operator in your codes. Make a habit of applying pipe \\noperator where possible It will make you smart in coding. \\n2.4   CONFUSION MATRIX AND EVALUATION \\nMETRICS \\nIn this section, we have to continue the discussion of the previous section. \\nKeeping our objective in view, we need four entries: \\n‚Ä¢ Actually, female and machine learning algorithm also predicted female. \\n‚Ä¢ Actually, female, but the machine learning algorithm predicted as male.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 9}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n44 \\n‚Ä¢ Actually, male and machine learning algorithm also predicted male. \\n‚Ä¢ Actually, male, but the machine learning algorithm predicted as female. \\nWhen these four entries are taken together in a 2 by 2 matrix form constitute \\nwhat is known as a confusion matrix. So, the confusion matrix for the dataset \\ndiscussed in the previous section can be obtained by running the following R \\ncode. The screenshot with output is shown as follows. \\n(2.32) \\nNext, let us also obtain the margins sum of the above confusion matrix given \\nby (2.32) by running the following R code. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.33) \\nWe see that actual male children are 241 and actual female children are 77. \\nAlso, the number of male children who are actually males and also predicted \\nby the machine learning algorithm as male is 235. Similarly, the number of \\nfemale children who are actually female and also predicted female is 31. So, \\nthe accuracy of predicting male children correctly 235\\n0.9751\\n241 \\uf06d\\n and  \\nthe accuracy of predicting female children correctly 31\\n0.4026\\n77 \\uf06d\\n  \\nUsing R code, we can obtain the same as follows. \\n \\nYou have noted the huge difference in the individual accuracy of male and \\nfemale children 97.5% versus 40.3% respectively, while overall accuracy was \\n83.6% (you may refer to 2.30). This was the point I wanted to highlight: you \\nshould keep in mind when you compute overall accuracy, especially when you \\nare working with a biased dataset. This happened because the prevalence of \\nmale children is much higher than the prevalence of female children in the \\nGaltonFamilies_300 dataset. My objective in creating a biased dataset, \\nGaltonFamilies_300, from the original dataset, GaltonFamilies, was to give'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 10}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n45 \\nyou an exposure to this important learning that you should have as a data \\nscientist. \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.34) \\nAs promised in (2.30), in this section, other than the confusion matrix, we will \\nalso learn some other evaluation metrics which can also be used to notice the \\nissues because of the presence of the problem of a higher prevalence of one \\ncategory compared to the other category. Two such measures are sensitivity \\nand specificity. Recall that you have already studied sensitivity and specificity \\nin Unit 4 of the course MST-019. To refresh your memory, let us copy and \\npaste Table 4.1 of the course MST-019 as follows. \\nTable 4.1 Result of Screening Test and Disease Status \\n \\nDisease Status \\n \\nYes (D )\\n+  \\nNo (D )\\n‚àí \\nTotal \\nScreening test result \\n \\n \\nT+\\n \\na \\n(True positive) \\nb \\n(False positive) \\na + b  \\n(Total number of \\nparticipants who are tested \\npositive by the test) \\n \\n \\nT‚àí\\n \\nc \\n(False negative) \\nd \\n(True negative) \\nc+ d \\n(Total number of \\nparticipants who are tested \\nnegative by the test) \\n \\nTotal \\na + c  \\n(Total screened \\nparticipants who actually \\nhave disease) \\nb + d  \\n(Total screened \\nparticipants who actually \\ndo not have disease) \\na + b +c + d = N \\n(Total number of screened \\nparticipants) \\nLet us prepare a similar table by following the terminology of the present \\ncourse on machine learning instead of epidemiology that was discussed in \\nBlock-1 of the Course MST-019. After doing that, Table 4.1 will look like this, \\nand we give it the name Table 2.1. \\nTable 2.1 General Result of Algorithm Prediction and Actual Status \\n \\nActual Status \\n \\nActual Positive \\nActual Negative \\nTotal \\nAlgorithm Prediction \\nPredicted \\nPositive \\na \\nTrue Positive (TP) \\nb \\nFalse Positive (FP) \\na + b  \\nThe total of those who \\nare predicted positive \\nby the algorithm \\nPredicted \\nNegative \\nc \\nFalse Negative (FN) \\nd \\nTrue Negative (TN) \\nc + d \\nThe total of those who \\nare predicted negative \\nby the algorithm \\n \\nTotal \\na + c  \\nThe total of those who \\nare actually positive \\nb + d  \\nThe total of those who \\nare actually negative \\na + b + c + d = N \\nGrand Total'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 11}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n46 \\nNow, we can define sensitivity and specificity as follows. \\nSensitivity: The ability of an algorithm to correctly predict a positive outcome \\nwhen it is actually positive. So, sensitivity is the probability, and in the \\nterminology of the above table, it is defined as follows. \\nSensitivity \\nTP\\na\\nTP\\nFN\\na\\nc\\n=\\n=\\n+\\n+\\n  \\n \\n \\n \\n \\n‚Ä¶ (2.35) \\nRemark: Sensitivity is also known as the True Positive Rate (TPR). It has \\none more name recall. \\nSpecificity: The ability of an algorithm to correctly predict a negative outcome \\nwhen it is actually negative. So, specificity is the probability, and in the \\nterminology of the above table, it is defined as follows. \\nSpecificity \\nTN\\nd\\nTN\\nFP\\nb\\nd\\n=\\n=\\n+\\n+\\n  \\n \\n \\n \\n \\n‚Ä¶ (2.36) \\nRemark: Specificity is also known as the True Negative Rate (TNR). \\nRecall from Unit 4 of the course MST-019: in such a situation, we define two \\nadditional measures, the positive predictive value (PPV) and the negative \\npredictive value (NPV), as follows. \\nPositive Predictive Value: The proportion of outcomes that are predicted \\npositive by the algorithm that are actually positive. In the terminology of the \\nabove table, it is defined as follows. \\nPositive predictive value \\nTP\\na\\nTP\\nFP\\na\\nb\\n=\\n=\\n+\\n+\\n  \\n \\n \\n‚Ä¶ (2.37) \\nRemark: Positive predictive value is also known as precision. \\nNegative Predictive Value: The proportion of outcomes that are predicted \\nnegative by the algorithm that are actually negative. In the terminology of the \\nabove table, it is defined as follows. \\nNegative predictive value \\nTN\\nd\\nTN\\nFN\\nc\\nd\\n=\\n=\\n+\\n+\\n \\n \\n \\n‚Ä¶ (2.38) \\nLet us add two more measures to our list of measures, known as balanced \\naccuracy and \\n1F -score  which are defined as follows. \\nBalanced accuracy is defined as the average of sensitivity and specificity, so \\nBalanced accuracy \\nSensitivity\\nSpecificity\\n2\\n+\\n=\\n \\n \\n \\n‚Ä¶ (2.39) \\n1F -score  is the harmonic mean of recall and precision, and so can be defined \\nas follows. \\n1\\n(Precision)\\n(Recall)\\nF -score\\n2 Precision\\nRecall\\n\\uf0b4\\n=\\n+\\n \\n \\n \\n \\n \\n‚Ä¶ (2.40)'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 12}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n47 \\nLet us obtain these measures using the confusion matrix given by (2.33) as \\nfollows. \\n \\nSensitivity (or Recall) \\nTP\\na\\n31\\n0.4026\\n40.26%\\nTP\\nFN\\na\\nc\\n77\\n=\\n=\\n=\\n=\\n+\\n+\\n\\uf06d\\n \\nSpecificity \\nTN\\nd\\n235\\n0.9751\\n95.51%\\nTN\\nFP\\nb\\nd\\n241\\n=\\n=\\n=\\n=\\n+\\n+\\n\\uf06d\\n \\n \\n \\nPositive predictive value (or Precision) \\nTP\\na\\n31\\n0.8378\\nTP\\nFP\\na\\nb\\n37\\n=\\n=\\n=\\n+\\n+\\n\\uf06d\\n \\n   \\n83.78%\\n=\\n \\nNegative predictive value \\nTN\\nd\\n235\\n0.8363\\n83.63%\\nTN\\nFN\\nc\\nd\\n281\\n=\\n=\\n=\\n=\\n+\\n+\\n\\uf06d\\n \\nBalanced accuracy \\n0.4026\\n0.9751\\n1.3777\\n0.68885\\n68.885%\\n2\\n2\\n+\\n=\\n=\\n=\\n=\\n \\n1\\n(Precision)\\n(Recall)\\n0.8378\\n0.4026\\nF -score\\n2\\n2\\n0.5439\\nPrecision\\nRecall\\n0.8378\\n0.4026\\n\\uf0b4\\n\\uf0b4\\n=\\n=\\n+\\n+\\n\\uf06d\\n \\nAll these measures and some more can be obtained by using \\nconfusionMatrix() function of caret package as follows. \\n \\n \\n \\n‚Ä¶ (2.41)'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 13}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n48 \\nLet us do one example. \\nExample 1: Consider the iris dataset in R. First, add a categorical column \\n‚ÄúSetosa‚Äù which takes the yes category if the Species column of that row has \\nthe entry ‚Äòsetosa‚Äô and no otherwise and call this new dataset ‚Äúiris_setosa‚Äù. \\nAfter that, split this new dataset randomly into 70:30, resulting in train_set and \\ntest_set. Train a logistic regression model with Setosa as a target variable \\nwhile Sepal.Length and Sepal.Width as features. Construct a confusion matrix \\ncorresponding to this model. Hence, find sensitivity, specificity, overall \\naccuracy, PPV, NPV, balanced accuracy and \\n1F -score.  \\nSolution: We know that there are 150 rows and 5 columns in the iris dataset. \\nThis can be checked as follows. \\n \\nThe first two rows of the dataset iris can be seen as follows. \\n \\nLet us first make a copy of the iris dataset and give it a new name iris_setosa. \\nThis can be done as follows. \\n \\nNow, in this new dataset iris_setosa, let us create a new categorical column \\n‚ÄúSetosa‚Äù which takes the ‚Äòyes‚Äô category if the Species column of that row has \\nthe entry ‚Äòsetosa‚Äô and ‚Äòno‚Äô otherwise. This can be done as follows. \\n \\nNow, one column ‚ÄúSetosa‚Äù has been added to the original dataset iris. This \\ncan be seen as follows. \\n \\nNote that now we have 6 columns instead of 5 in new dataset iris_Setosa_col. \\nNext, we have to select a random sample of 70% of row indices of this \\ndataset, which can be done as follows. For reproducibility purposes, we will \\nset 2006 as the seed. \\n \\nNow, we can obtain train and test sets as follows.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 14}, page_content=\"Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n49 \\n \\n \\n \\n‚Ä¶ (2.42) \\nWe know that \\n70\\n70% of 150 rows\\n150\\n105 rows\\n100\\n=\\n\\uf0b4\\n=\\n and \\n30\\n30% of 150 rows\\n150\\n45 rows\\n100\\n=\\n\\uf0b4\\n=\\n \\nSo, we expect that the number of rows in the train_set and test_set datasets \\nshould be 105 and 45, respectively. This can be verified as follows. \\n \\nVerified. Good. \\nTo ensure consistent factor levels where yes remains first and no remains \\nsecond, we have to run the following R code. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.43) \\nWe know that the logistic model predicts probabilities. We want that model to \\npredict P(yes) = probability of yes. We also know that glm() function predicts \\nthe probability of the second level. Here, the second level is no. So, we have \\nto relevel. This can be done as follows. \\n‚Ä¶ (2.44) \\nNow, we can train a logistic regression model with Setosa as a target variable \\nwhile Sepal.Length and Sepal.Width as features as follows. \\n‚Ä¶ (2.45) \\nYou may get some warning messages. Ignore them. \\nNext, we need to obtain the model's predicted probabilities. Let us store these \\nprobabilities in the variable probabilities. It can be done as follows. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.46) \\nTo convert these probabilities into outcomes, we have to apply a classification \\nfunction. This can be done as follows. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.47)\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 15}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n50 \\nNext, before obtaining the confusion matrix, we have to convert \\npredicted_classes into a factor variable with levels yes and no. This can be \\ndone as follows. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.48) \\nFinally, we can obtain a confusion matrix by running the following code. Let us \\nsave the output in the variable conf_matrix. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.49) \\nNow, the confusion matrix has been saved in the object conf_matrix, which \\ncan be seen by typing conf_matrix in the R console and hitting enter. The \\nscreenshot of the output is shown as follows.   \\n  \\n \\n \\n \\n \\n \\n‚Ä¶ (2.50) \\nNow, if we compare the confusion matrix given by (2.50) with the general form \\nof the confusion matrix given by (2.40), we have \\nTP\\na\\n15, FP\\nb\\n0, FN\\nc\\n0, TN\\nd\\n30\\n=\\n=\\n=\\n=\\n=\\n=\\n=\\n=\\n \\n \\n \\n‚Ä¶ (2.51) \\nNow, required evaluation metrics are given by \\nSensitivity (or Recall) \\nTP\\na\\n15\\n15\\n1\\n100%\\nTP\\nFN\\na\\nc\\n15\\n0\\n15\\n=\\n=\\n=\\n=\\n=\\n=\\n+\\n+\\n+\\n \\nSpecificity \\nTN\\nd\\n30\\n30\\n1\\n100%\\nTN\\nFP\\nb\\nd\\n0\\n30\\n30\\n=\\n=\\n=\\n=\\n=\\n=\\n+\\n+\\n+\\n \\n \\n \\nOverall accuracy \\nTP\\nTN\\na\\nd\\n15\\n30\\nTP\\nFP\\nFN\\nTN\\na\\nb\\nc\\nd\\n15\\n0\\n0\\n30\\n+\\n+\\n+\\n=\\n=\\n=\\n+\\n+\\n+\\n+\\n+\\n+\\n+\\n+\\n+\\n \\n    \\n45\\n1\\n100%\\n45\\n=\\n=\\n=\\n \\nPositive predictive value (or Precision) \\nTP\\na\\n15\\n15\\nTP\\nFP\\na\\nb\\n15\\n0\\n15\\n=\\n=\\n=\\n=\\n+\\n+\\n+\\n \\n   \\n1 100%\\n= =\\n \\nNegative predictive value \\nTN\\nd\\n30\\n30\\n1\\n100%\\nTN\\nFN\\nc\\nd\\n0\\n30\\n30\\n=\\n=\\n=\\n=\\n=\\n=\\n+\\n+\\n+\\n \\nBalanced accuracy \\nSensitivity\\nSpecificity\\n100\\n100\\n200\\n%\\n%\\n100%\\n2\\n2\\n2\\n+\\n+\\n=\\n=\\n=\\n='),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 16}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n51 \\n1\\n(Precision)\\n(Recall)\\n100 100\\nF -score\\n2\\n2\\n%\\n100%\\nPrecision\\nRecall\\n100\\n100\\n\\uf0b4\\n\\uf0b4\\n=\\n=\\n=\\n+\\n+\\n \\nAll these measures and some more can be obtained by using \\nconfusionMatrix() function of caret package as follows. \\n \\nNow, you can try the following Self-Assessment Question. \\nSAQ 3 \\nRe do Example 1, just this time make an even split as train and test datasets. \\nThat is, make 50 : 50 split instead of 70 : 30 split. Do not obtain evaluation \\nmetrics manually like we did in Example 1. I assume that you can make a \\ngood practice of that from the TEE point of view as per your need. Like \\nExample 1, just obtain those evaluation metrics using the confusionMatrix() \\nfunction of the caret package. Comment on the output of the confusionMatrix() \\nfunction by comparing the output with the output of Example 1. \\n2.5   SUMMARY  \\nA brief summary of what we have covered in this unit is given as follows: \\n‚Ä¢ Training Dataset: The original dataset is partitioned into two datasets \\ngenerally in the ratio 80 : 20 or 75 : 25 or 70 : 30. That is, the larger dataset \\ncontains 70 to 80% of the original dataset. This larger dataset, which is a \\nrandom subset of the original dataset, is used to train the machine learning \\nalgorithm and is known as training dataset.  \\n‚Ä¢ Testing Dataset: The original dataset is partitioned into two datasets \\ngenerally in the ratio 80 : 20 or 75 : 25 or 70 : 30. That is, the smaller \\ndataset contains 20 to 30% of the original dataset. This smaller dataset, \\nwhich is a random subset of the original dataset, is used to test the trained \\nmachine learning algorithm and is known as the test dataset.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 17}, page_content=\"Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n52 \\n‚Ä¢ If the algorithm performs well in the training dataset but poorly in the testing \\ndataset, it is an indication of the problem of overfitting.  \\n‚Ä¢ Sensitivity or True Positive Rate (TPR) or Recall: The ability of an \\nalgorithm to correctly predict a positive outcome when it is actually positive. \\nSo, sensitivity is the probability that is defined as follows:               \\nSensitivity \\nTP\\na\\nTP\\nFN\\na\\nc\\n=\\n=\\n+\\n+\\n.  \\n‚Ä¢ Specificity or True Negative Rate (TNR): The ability of an algorithm to \\ncorrectly predict a negative outcome when it is actually negative. So, \\nspecificity is the probability that is defined as follows:                     \\nSpecificity \\nTN\\nd\\nTN\\nFP\\nb\\nd\\n=\\n=\\n+\\n+\\n \\n‚Ä¢ Positive Predictive Value or Precision: The proportion of outcomes that \\nare predicted positive by the algorithm that are actually positive. So, \\npositive predictive value is the probability and is defined as follows: \\nPositive predictive value or Precision \\nTP\\na\\nTP\\nFP\\na\\nb\\n=\\n=\\n+\\n+\\n \\n‚Ä¢ Negative Predictive Value: The proportion of outcomes that are predicted \\nas negative by the algorithm that are actually negative. So, negative \\npredictive value is the probability and is defined as follows. \\nNegative predictive value \\nTN\\nd\\nTN\\nFN\\nc\\nd\\n=\\n=\\n+\\n+\\n \\n‚Ä¢ Balanced accuracy is defined as the average of sensitivity and specificity, \\nso Balanced accuracy \\nSensitivity\\nSpecificity\\n2\\n+\\n=\\n.  \\n‚Ä¢ \\n1F -score  is the harmonic mean of recall and precision, and so can be \\ndefined as follows: \\n1\\n(Precision)\\n(Recall)\\nF -score\\n2 Precision\\nRecall\\n\\uf0b4\\n=\\n+\\n. \\n2.6   TERMINAL QUESTIONS  \\n1.      Build an algorithm to predict the gender of a child using the childHeight \\nvariable as a feature of the GaltonFamilies dataset in the HistData \\npackage of R by removing 200 rows randomly of female children from \\nthis dataset. Find the overall accuracy of the algorithm. \\n2.      Obtain female and male children's overall accuracy individually and \\ncomment on the results obtained by comparing these results with the \\nresults of Sec. 2.3 of the similar model, where we removed 300 random \\nrows of female children instead of 200 rows.  \\n2.7   SOLUTIONS/ANSWERS   \\nSelf-Assessment Questions (SAQs) \\n1.      It is a false statement because the training dataset is a random subset of \\nthe original dataset is ok, but it contains 70 to 80% instances of the \\noriginal dataset, not 20 to 30% instances.\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 18}, page_content='Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n53 \\n2.  \\nA screenshot of one sample of a line of code of R with output where the \\npipe operator from the tidyverse package is used is given as follows. \\n \\n \\n \\nWorking of pipe operator is like this:  \\n‚Ä¢ Whatever we have before the first pipe operator it becomes the first \\nargument of the function just written after the first pipe operator. For \\nexample, here iris is written before the pipe operator, so it becomes \\nthe first argument of the function subset() which is written just after \\nthe first pipe operator.  \\n‚Ä¢ Whatever is written before the second pipe operator it will be \\nevaluated and its output will be the first argument of the second pipe \\noperator R. Here first R will subset the dataset iris and select only \\nthose rows of the iris dataset where the variable Sepal.Length is \\ngreater than 5. This subset of iris dataset will be the first argument of \\nthe function head() which is written just after the second pipe operator \\nin this line of code. Therefore final output will be the first 4 rows of the \\nsubseted iris dataset. \\n3.      We have explained the meaning of all codes in Example 1, so here we \\nare just running the codes and getting the required output. The \\nscreenshot of the code with output is shown as follows.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 19}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n54 \\n \\n \\n \\nNote that this time model incorrectly classifies one case of Setosa, while \\nall non-Setosa cases are correctly classified. So, the specificity of the \\nmodel is 100% while the sensitivity of the algorithm is 23/24 = 95.83%. \\nWhat can we say about the reduction of sensitivity from 100% to 95.83% \\ncompared to Example 1? One possible answer is algorithm got less data \\nfor training compared to Example 1. In Example 1 training dataset has \\n105 instances, while this time we have only 75 instances in the training \\ndataset. So, we can say that the more the dataset for training, the more \\nlearning takes place. \\nTerminal Questions  \\n1.      We have already explained all steps used in the process of building such \\nan algorithm in Sec. 2.3. So, we are just running the final R codes on R \\nconsole. Screenshot of R codes and their output is shown as follows.'),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 20}, page_content=\"Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n55 \\n \\n \\n \\n \\n2. \\nFemale and male children's overall accuracy individually can be \\nobtained by running the following code.\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': '2025-12-01T11:18:35+05:30', 'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'total_pages': 22, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-01T11:18:46+05:30', 'trapped': '', 'modDate': \"D:20251201111846+05'30'\", 'creationDate': \"D:20251201111835+05'30'\", 'page': 21}, page_content='Data Types, \\nEvaluation Metrics \\nand Cross-Validation \\nfor Machine Learning \\nAlgorithms \\n56 \\n \\nNote that this time also overall accuracy of male children is more than \\nfemale children but they do not have as much huge difference as they \\nhave in Sec. 2.3 where we removed 300 rows of the female children \\ninstead of 200. It means if there is more gap between prevalence of \\nfemale and male children then their overall accuracy will also has more \\ngap.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a00263",
   "metadata": {},
   "source": [
    "### Equation Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84629f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_equations(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize common math symbols and LaTeX expressions\n",
    "    to improve embedding quality.\n",
    "    \"\"\"\n",
    "\n",
    "    # Greek letters\n",
    "    replacements = {\n",
    "        r\"\\\\theta\": \"theta\",\n",
    "        r\"\\\\alpha\": \"alpha\",\n",
    "        r\"\\\\beta\": \"beta\",\n",
    "        r\"\\\\gamma\": \"gamma\",\n",
    "        r\"\\\\lambda\": \"lambda\",\n",
    "\n",
    "        r\"\\^T\": \" transpose \",\n",
    "        r\"\\^2\": \" squared \",\n",
    "        r\"\\^3\": \" cubed \",\n",
    "\n",
    "        r\"=\": \" equals \",\n",
    "        r\"\\+\": \" plus \",\n",
    "        r\"-\": \" minus \",\n",
    "        r\"\\*\": \" times \",\n",
    "        r\"/\": \" divided by \",\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b2c7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics Machine learning is a subset of artificial intelligence that enables syste,s to learn and improve from experience without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves. Types of Machine Learning: 1. Supervised Learning: Learning with labeled data 2. Unsupervised Learning: Finding patterns in unlabeled data 3. Reinforcement Learning: Learning through rewards and penalties Applications include image recognition, speech processing, and recommendation systems'),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction Python is a high minus level, interpreted programming language known for its simplicity and readability. Created by Guido van Rossum and first released in 1991, Pyhton has become one of the most popular programming languages in the world. Key Features: minus Easy to learn and use minus Extensive standard library minus Cross minus platform campatibility minus Strong community support Python is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_documents = dir_loader.load()\n",
    "\n",
    "for doc in pdf_documents:\n",
    "    doc.page_content = preprocess_equations(doc.page_content)\n",
    "\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a66216",
   "metadata": {},
   "source": [
    "### Fixed-size chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc586fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def chunk_documents(documents, chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks for better RAG retrieval.\n",
    "    \"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    chunked_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunked_docs)} chunks\")\n",
    "\n",
    "    if chunked_docs:\n",
    "        print(f\"\\n Example Chunk:\")\n",
    "        print(f\"Content: {chunked_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {chunked_docs[0].metadata}\")\n",
    "\n",
    "    return chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24e4b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 4 chunks\n",
      "\n",
      " Example Chunk:\n",
      "Content: Machine Learning Basics Machine learning is a subset of artificial intelligence that enables syste,s to learn and improve from experience without being explicitly programmed. It focuses on developing ...\n",
      "Metadata: {'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics Machine learning is a subset of artificial intelligence that enables syste,s to learn and improve from experience without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves. Types of Machine Learning: 1. Supervised Learning: Learning with labeled data 2. Unsupervised Learning: Finding patterns in unlabeled data 3'),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='. Unsupervised Learning: Finding patterns in unlabeled data 3. Reinforcement Learning: Learning through rewards and penalties Applications include image recognition, speech processing, and recommendation systems'),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction Python is a high minus level, interpreted programming language known for its simplicity and readability. Created by Guido van Rossum and first released in 1991, Pyhton has become one of the most popular programming languages in the world'),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='. Key Features: minus Easy to learn and use minus Extensive standard library minus Cross minus platform campatibility minus Strong community support Python is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = chunk_documents(pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826f5b6",
   "metadata": {},
   "source": [
    "### Sentence Based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01ce372b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SHIVA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def sentence_based_chunking(documents, max_chunk_size=800):\n",
    "    \"\"\"\n",
    "    Chunk documents by preserving sentence boundaries.\n",
    "    Sentences are grouped until max_chunk_size is reached.\n",
    "    \"\"\"\n",
    "    chunked_docs = []\n",
    "\n",
    "    for doc in documents:\n",
    "        sentences = sent_tokenize(doc.page_content)\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "                current_chunk += \" \" + sentence\n",
    "            else:\n",
    "                chunked_docs.append(\n",
    "                    Document(\n",
    "                        page_content=current_chunk.strip(),\n",
    "                        metadata=doc.metadata\n",
    "                    )\n",
    "                )\n",
    "                current_chunk = sentence\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunked_docs.append(\n",
    "                Document(\n",
    "                    page_content=current_chunk.strip(),\n",
    "                    metadata=doc.metadata\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(f\"Sentence-based chunking created {len(chunked_docs)} chunks\")\n",
    "    return chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1654bf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-based chunking created 2 chunks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics Machine learning is a subset of artificial intelligence that enables syste,s to learn and improve from experience without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves. Types of Machine Learning: 1. Supervised Learning: Learning with labeled data 2. Unsupervised Learning: Finding patterns in unlabeled data 3. Reinforcement Learning: Learning through rewards and penalties Applications include image recognition, speech processing, and recommendation systems'),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction Python is a high minus level, interpreted programming language known for its simplicity and readability. Created by Guido van Rossum and first released in 1991, Pyhton has become one of the most popular programming languages in the world. Key Features: minus Easy to learn and use minus Extensive standard library minus Cross minus platform campatibility minus Strong community support Python is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_chunks = sentence_based_chunking(pdf_documents, max_chunk_size=800)\n",
    "sentence_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07875212",
   "metadata": {},
   "source": [
    "### Embedding and vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cc88f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05955834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 719.94it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x225b24c10d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Genrated emebeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3232fe51",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9f80cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initilized. Collection: pdf_documents\n",
      "Existing documents in collection: 5532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x225b2455790>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "    \n",
    "    def _initialize_store(self):\n",
    "        try:\n",
    "            #create ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\" : \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initilized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "        \n",
    "    def add_documents(self, documents: List[Any], embeddings:np.array):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of docments must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        #data for chromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            #unique Id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorStore_ = VectorStore()\n",
    "vectorStore_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfd07daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 4 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (4, 384)\n",
      "Adding 4 documents to vector store...\n",
      "Successfully added 4 documents to vector store\n",
      "Total documents in collection: 5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "### Generate the embedding\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "### Store in vector\n",
    "vectorStore_.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadd80c",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32fa246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "\n",
    "        #genrate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "\n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "\n",
    "                        print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "                    \n",
    "            else:\n",
    "                print(\"No docments found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "                \n",
    "rag_retriever = RAGRetriever(vectorStore_, embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9630a677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x225c1d43350>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "249ccf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Machine Learning'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 93.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Retrieved 4 documents (after filtering)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_3f0a412a_15',\n",
       "  'content': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a computer program to optimize the parameters of the model using the training data or \\npast experience. The model may be predictive to make predictions in the future, or descriptive to gain',\n",
       "  'metadata': {'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'format': 'PDF 1.4',\n",
       "   'modDate': '',\n",
       "   'moddate': '',\n",
       "   'creationdate': '',\n",
       "   'creationDate': '',\n",
       "   'content_length': 487,\n",
       "   'page': 5,\n",
       "   'total_pages': 120,\n",
       "   'title': '',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'trapped': '',\n",
       "   'doc_index': 15,\n",
       "   'keywords': '',\n",
       "   'creator': '',\n",
       "   'author': '',\n",
       "   'producer': '',\n",
       "   'subject': ''},\n",
       "  'similarity_score': 0.6231977343559265,\n",
       "  'distance': 0.3768022656440735,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_f39a4f46_15',\n",
       "  'content': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a computer program to optimize the parameters of the model using the training data or \\npast experience. The model may be predictive to make predictions in the future, or descriptive to gain',\n",
       "  'metadata': {'title': '',\n",
       "   'moddate': '',\n",
       "   'modDate': '',\n",
       "   'creationdate': '',\n",
       "   'page': 5,\n",
       "   'trapped': '',\n",
       "   'total_pages': 120,\n",
       "   'producer': '',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'creator': '',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'subject': '',\n",
       "   'content_length': 487,\n",
       "   'creationDate': '',\n",
       "   'keywords': '',\n",
       "   'author': '',\n",
       "   'doc_index': 15,\n",
       "   'format': 'PDF 1.4'},\n",
       "  'similarity_score': 0.6231977343559265,\n",
       "  'distance': 0.3768022656440735,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_05f955b2_15',\n",
       "  'content': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a computer program to optimize the parameters of the model using the training data or \\npast experience. The model may be predictive to make predictions in the future, or descriptive to gain',\n",
       "  'metadata': {'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'total_pages': 120,\n",
       "   'author': '',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'trapped': '',\n",
       "   'creator': '',\n",
       "   'page': 5,\n",
       "   'content_length': 487,\n",
       "   'modDate': '',\n",
       "   'subject': '',\n",
       "   'producer': '',\n",
       "   'doc_index': 15,\n",
       "   'title': '',\n",
       "   'moddate': '',\n",
       "   'creationDate': '',\n",
       "   'creationdate': '',\n",
       "   'keywords': '',\n",
       "   'format': 'PDF 1.4'},\n",
       "  'similarity_score': 0.6231977343559265,\n",
       "  'distance': 0.3768022656440735,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_d17b77ed_15',\n",
       "  'content': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a computer program to optimize the parameters of the model using the training data or \\npast experience. The model may be predictive to make predictions in the future, or descriptive to gain',\n",
       "  'metadata': {'subject': '',\n",
       "   'author': '',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'trapped': '',\n",
       "   'creationdate': '',\n",
       "   'format': 'PDF 1.4',\n",
       "   'modDate': '',\n",
       "   'moddate': '',\n",
       "   'title': '',\n",
       "   'page': 5,\n",
       "   'producer': '',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'total_pages': 120,\n",
       "   'creator': '',\n",
       "   'content_length': 487,\n",
       "   'keywords': '',\n",
       "   'doc_index': 15,\n",
       "   'creationDate': ''},\n",
       "  'similarity_score': 0.6231977343559265,\n",
       "  'distance': 0.3768022656440735,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_ccf03693_16',\n",
       "  'content': 'knowledge from data, or both. \\nArthur Samuel, an early American leader in the field of computer gaming and artificial intelligence, \\ncoined the term ‚ÄúMachine Learning‚Äù in 1959 while at IBM. He defined machine learning as ‚Äúthe field of \\nstudy that gives computers the ability to learn without being explicitly programmed.‚Äù However, there is \\nno universally accepted definition for machine learning. Different authors define the term differently. \\n \\nDefinition of learning \\nDefinition',\n",
       "  'metadata': {'creationdate': '',\n",
       "   'moddate': '',\n",
       "   'creator': '',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'trapped': '',\n",
       "   'creationDate': '',\n",
       "   'keywords': '',\n",
       "   'subject': '',\n",
       "   'format': 'PDF 1.4',\n",
       "   'page': 5,\n",
       "   'total_pages': 120,\n",
       "   'producer': '',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'modDate': '',\n",
       "   'content_length': 482,\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf',\n",
       "   'doc_index': 16},\n",
       "  'similarity_score': 0.5525288581848145,\n",
       "  'distance': 0.44747114181518555,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bd5ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Multi Layer Artificial Neural Networks'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 63.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Retrieved 4 documents (after filtering)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_5806b333_1013',\n",
       "  'content': 'efforts (Werbos 1974, Parker 1982, and Rumelhart, Hinton and Williams 1986) \\nprovides a systematic means for training multi-layer networks, thereby overcoming \\nlimitations presented by Minsky. \\n1.3.0 Characteristics of ANN \\nArtificial neural networks are biologically inspired; that is, they are composed of \\nelements that perform in a manner that is analogous to the most elementary functions of the \\nbiological neuron. The important characteristics of artificial neural networks are learning',\n",
       "  'metadata': {'subject': '',\n",
       "   'creator': 'Microsoft¬Æ Word for Office 365',\n",
       "   'author': 'Harish  Balaga',\n",
       "   'content_length': 493,\n",
       "   'title': 'Introduction to ANN',\n",
       "   'creationdate': '2019-07-02T13:53:30+05:30',\n",
       "   'format': 'PDF 1.7',\n",
       "   'keywords': '',\n",
       "   'total_pages': 36,\n",
       "   'page': 2,\n",
       "   'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'creationDate': \"D:20190702135330+05'30'\",\n",
       "   'producer': 'Microsoft¬Æ Word for Office 365',\n",
       "   'modDate': \"D:20190702135330+05'30'\",\n",
       "   'moddate': '2019-07-02T13:53:30+05:30',\n",
       "   'doc_index': 1013,\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'trapped': ''},\n",
       "  'similarity_score': 0.42835140228271484,\n",
       "  'distance': 0.5716485977172852,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_ca64dc49_1013',\n",
       "  'content': 'efforts (Werbos 1974, Parker 1982, and Rumelhart, Hinton and Williams 1986) \\nprovides a systematic means for training multi-layer networks, thereby overcoming \\nlimitations presented by Minsky. \\n1.3.0 Characteristics of ANN \\nArtificial neural networks are biologically inspired; that is, they are composed of \\nelements that perform in a manner that is analogous to the most elementary functions of the \\nbiological neuron. The important characteristics of artificial neural networks are learning',\n",
       "  'metadata': {'creationDate': \"D:20190702135330+05'30'\",\n",
       "   'page': 2,\n",
       "   'total_pages': 36,\n",
       "   'title': 'Introduction to ANN',\n",
       "   'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft¬Æ Word for Office 365',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'creationdate': '2019-07-02T13:53:30+05:30',\n",
       "   'subject': '',\n",
       "   'producer': 'Microsoft¬Æ Word for Office 365',\n",
       "   'content_length': 493,\n",
       "   'format': 'PDF 1.7',\n",
       "   'author': 'Harish  Balaga',\n",
       "   'modDate': \"D:20190702135330+05'30'\",\n",
       "   'doc_index': 1013,\n",
       "   'moddate': '2019-07-02T13:53:30+05:30',\n",
       "   'trapped': ''},\n",
       "  'similarity_score': 0.42835140228271484,\n",
       "  'distance': 0.5716485977172852,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_ee9e596c_1013',\n",
       "  'content': 'efforts (Werbos 1974, Parker 1982, and Rumelhart, Hinton and Williams 1986) \\nprovides a systematic means for training multi-layer networks, thereby overcoming \\nlimitations presented by Minsky. \\n1.3.0 Characteristics of ANN \\nArtificial neural networks are biologically inspired; that is, they are composed of \\nelements that perform in a manner that is analogous to the most elementary functions of the \\nbiological neuron. The important characteristics of artificial neural networks are learning',\n",
       "  'metadata': {'moddate': '2019-07-02T13:53:30+05:30',\n",
       "   'title': 'Introduction to ANN',\n",
       "   'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'modDate': \"D:20190702135330+05'30'\",\n",
       "   'format': 'PDF 1.7',\n",
       "   'creationdate': '2019-07-02T13:53:30+05:30',\n",
       "   'page': 2,\n",
       "   'content_length': 493,\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft¬Æ Word for Office 365',\n",
       "   'creationDate': \"D:20190702135330+05'30'\",\n",
       "   'total_pages': 36,\n",
       "   'author': 'Harish  Balaga',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'producer': 'Microsoft¬Æ Word for Office 365',\n",
       "   'trapped': '',\n",
       "   'doc_index': 1013,\n",
       "   'subject': ''},\n",
       "  'similarity_score': 0.42835140228271484,\n",
       "  'distance': 0.5716485977172852,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_7dada659_1013',\n",
       "  'content': 'efforts (Werbos 1974, Parker 1982, and Rumelhart, Hinton and Williams 1986) \\nprovides a systematic means for training multi-layer networks, thereby overcoming \\nlimitations presented by Minsky. \\n1.3.0 Characteristics of ANN \\nArtificial neural networks are biologically inspired; that is, they are composed of \\nelements that perform in a manner that is analogous to the most elementary functions of the \\nbiological neuron. The important characteristics of artificial neural networks are learning',\n",
       "  'metadata': {'doc_index': 1013,\n",
       "   'author': 'Harish  Balaga',\n",
       "   'page': 2,\n",
       "   'creationDate': \"D:20190702135330+05'30'\",\n",
       "   'modDate': \"D:20190702135330+05'30'\",\n",
       "   'format': 'PDF 1.7',\n",
       "   'producer': 'Microsoft¬Æ Word for Office 365',\n",
       "   'keywords': '',\n",
       "   'creationdate': '2019-07-02T13:53:30+05:30',\n",
       "   'total_pages': 36,\n",
       "   'title': 'Introduction to ANN',\n",
       "   'moddate': '2019-07-02T13:53:30+05:30',\n",
       "   'trapped': '',\n",
       "   'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'content_length': 493,\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'subject': '',\n",
       "   'creator': 'Microsoft¬Æ Word for Office 365'},\n",
       "  'similarity_score': 0.42835140228271484,\n",
       "  'distance': 0.5716485977172852,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_e08f30c0_1082',\n",
       "  'content': 'function of each neuron in hidden layers, the multi layer neural networks able to solve many \\nof the complex problems, such as, nonlinear function approximation, learning generalization, \\nnonlinear classification etc. \\n \\nA multi layer neural network consists of input layer, output layer and hidden layers. \\nThe number of nodes in input layer depends on the number of inputs and the number of nodes \\nin the output layer depends upon the number of outputs. The designer selects the number of',\n",
       "  'metadata': {'modDate': \"D:20190702135330+05'30'\",\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'content_length': 490,\n",
       "   'title': 'Introduction to ANN',\n",
       "   'creator': 'Microsoft¬Æ Word for Office 365',\n",
       "   'keywords': '',\n",
       "   'page': 16,\n",
       "   'subject': '',\n",
       "   'trapped': '',\n",
       "   'producer': 'Microsoft¬Æ Word for Office 365',\n",
       "   'creationdate': '2019-07-02T13:53:30+05:30',\n",
       "   'moddate': '2019-07-02T13:53:30+05:30',\n",
       "   'creationDate': \"D:20190702135330+05'30'\",\n",
       "   'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf',\n",
       "   'total_pages': 36,\n",
       "   'doc_index': 1082,\n",
       "   'format': 'PDF 1.7',\n",
       "   'author': 'Harish  Balaga'},\n",
       "  'similarity_score': 0.33844852447509766,\n",
       "  'distance': 0.6615514755249023,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Multi Layer Artificial Neural Networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d81c32",
   "metadata": {},
   "source": [
    "### RAG pipeline with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-8b-instant\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "#RAG function\n",
    "\n",
    "def rag_simple(query, retriever, llm, top_k=3):\n",
    "    \n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "\n",
    "    if not context:\n",
    "        return \"No Relevant context found to answer the question.\"\n",
    "    \n",
    "    ## generate ans\n",
    "    prompt = f\"\"\"\n",
    "        You are an academic Machine Learning assistant.\n",
    "\n",
    "        Use only the provided context to answer the question.\n",
    "\n",
    "        Guidelines:\n",
    "        - Answer clearly and concisely.\n",
    "        - Do not add information outside the context.\n",
    "        - If a mathematical formula appears, rewrite it in clean readable format.\n",
    "        - Explain technical terms briefly if necessary.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    \n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758aa64",
   "metadata": {},
   "source": [
    "#### Test Simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33380bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is The simple linear regression model?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 82.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Simple Linear Regression model is a statistical model that shows a linear or sloped straight line relationship between a dependent variable (continuous/real value) and a single independent variable (can be continuous or categorical value).\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"What is The simple linear regression model?\", rag_retriever, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unkown')),\n",
    "        'page': doc['metadata'].get('page', 'unkown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300]+ '...'\n",
    "    } for doc in results]\n",
    "\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "\n",
    "    # Genrate ans\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are a machine learning academic assistant.\n",
    "\n",
    "        Use the retrieved context to answer clearly.\n",
    "\n",
    "        If mathematical equations appear:\n",
    "        - Rewrite them in clean readable format.\n",
    "        - Explain each symbol.\n",
    "        - Do not copy broken PDF formatting.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "        Question:\n",
    "        {query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"    \n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "\n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1230f71",
   "metadata": {},
   "source": [
    "#### Test Advanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527f110",
   "metadata": {},
   "source": [
    "##### 1st Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "239caeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Machine Learning?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: **What is Machine Learning?**\n",
      "\n",
      "Machine learning is a subfield of artificial intelligence (AI) that involves programming computers to optimize a performance criterion using example data or past experience.\n",
      "\n",
      "**Key Components:**\n",
      "\n",
      "1. **Model**: A mathematical representation of a system or a relationship between variables.\n",
      "2. **Parameters**: Adjustable values within the model that need to be optimized.\n",
      "3. **Training Data**: A set of examples used to train the model and optimize its parameters.\n",
      "4. **Performance Criterion**: A measure of how well the model performs, such as accuracy or loss.\n",
      "\n",
      "**Machine Learning Process:**\n",
      "\n",
      "1. **Model Definition**: Define a model with adjustable parameters.\n",
      "2. **Training**: Execute a computer program to optimize the parameters of the model using the training data.\n",
      "3. **Model Evaluation**: Evaluate the performance of the trained model using a performance criterion.\n",
      "\n",
      "**Types of Machine Learning Models:**\n",
      "\n",
      "1. **Predictive Models**: Designed to make predictions in the future based on past data.\n",
      "2. **Descriptive Models**: Designed to gain insights or understanding of a system or relationship.\n",
      "\n",
      "In mathematical terms, the machine learning process can be represented as:\n",
      "\n",
      "**Model Optimization**\n",
      "\n",
      "Minimize the loss function (L) with respect to the model parameters (Œ∏):\n",
      "\n",
      "L(Œ∏) = (y - f(x; Œ∏))^2\n",
      "\n",
      "where:\n",
      "\n",
      "* L(Œ∏) is the loss function, which measures the difference between the predicted output (f(x; Œ∏)) and the actual output (y).\n",
      "* Œ∏ represents the model parameters, which need to be optimized.\n",
      "* x is the input data.\n",
      "* y is the actual output.\n",
      "\n",
      "The goal of machine learning is to find the optimal values of Œ∏ that minimize the loss function L(Œ∏).\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'page': 5, 'score': 0.6533342599868774, 'preview': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a ...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'page': 5, 'score': 0.6533342599868774, 'preview': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a ...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'page': 5, 'score': 0.6533342599868774, 'preview': '1 \\n \\nUNIT I  \\nIntroduction to Machine Learning \\n1. Introduction \\n \\n1.1 What Is Machine Learning?  \\nMachine learning is programming computers to optimize a performance criterion using example \\ndata or past experience. We have a model defined up to some parameters, and learning is the \\nexecution of a ...'}]\n",
      "Confidence: 0.6533342599868774\n",
      "Context Preview: 1 \n",
      " \n",
      "UNIT I  \n",
      "Introduction to Machine Learning \n",
      "1. Introduction \n",
      " \n",
      "1.1 What Is Machine Learning?  \n",
      "Machine learning is programming computers to optimize a performance criterion using example \n",
      "data or past experience. We have a model defined up to some parameters, and learning is the \n",
      "execution of a \n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"What is Machine Learning?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3c6e8",
   "metadata": {},
   "source": [
    "##### 2nd Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d05ac36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Version Spaces?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: **Version Spaces: A Concept in Machine Learning**\n",
      "\n",
      "Version spaces are a fundamental concept in machine learning, particularly in the field of inductive inference. They were introduced by Mitchell in 1982 as a way to represent the set of possible hypotheses that are consistent with a given set of training examples.\n",
      "\n",
      "**Definition:**\n",
      "\n",
      "The version space, denoted as V(H, D), is the subset of hypotheses from the hypothesis space H that are consistent with the training examples in D.\n",
      "\n",
      "**Mathematical Representation:**\n",
      "\n",
      "Let H be the hypothesis space, D be the set of training examples, and V(H, D) be the version space. Then:\n",
      "\n",
      "V(H, D) = {h ‚àà H | h(x) = c(x) ‚àÄ x ‚àà D}\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* h ‚àà H: This means that h is a hypothesis in the hypothesis space H.\n",
      "* h(x) = c(x): This means that the hypothesis h correctly classifies the example x, where c(x) is the correct classification of x.\n",
      "* ‚àÄ x ‚àà D: This means that the hypothesis h must correctly classify all examples in the training set D.\n",
      "\n",
      "**Key Difference:**\n",
      "\n",
      "The key difference between the definitions of \"satisfies\" and \"consistent\" is that:\n",
      "\n",
      "* An example x satisfies a hypothesis h if h(x) = 1, regardless of whether x is a positive or negative example of the target concept.\n",
      "* An example x is consistent with a hypothesis h if h(x) = c(x), where c(x) is the correct classification of x.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose we have a hypothesis space H that consists of two hypotheses: h1 and h2. The training set D contains two examples: x1 and x2. The correct classifications of x1 and x2 are c(x1) = 1 and c(x2) = 0, respectively.\n",
      "\n",
      "If h1(x1) = 1 and h1(x2) = 0, then h1 is consistent with the training set D, and h1 ‚àà V(H, D).\n",
      "\n",
      "If h2(x1) = 0 and h2(x2) = 1, then h2 is not consistent with the training set D, and h2 ‚àâ V(H, D).\n",
      "\n",
      "Therefore, the version space V(H, D) contains only the hypothesis h1, which is consistent with the training set D.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'page': 20, 'score': 0.11193448305130005, 'preview': 'Note difference between definitions of consistent and satisfies  \\n\\uf0b7 \\nAn example x is said to satisfy hypothesis h when h(x) = 1, regardless of whether x is a positive \\nor negative example of the target concept.  \\n\\uf0b7 \\nAn example x is said to consistent with hypothesis h iff h(x) = c(x)  \\n \\nDefinition:...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'page': 20, 'score': 0.11193448305130005, 'preview': 'Note difference between definitions of consistent and satisfies  \\n\\uf0b7 \\nAn example x is said to satisfy hypothesis h when h(x) = 1, regardless of whether x is a positive \\nor negative example of the target concept.  \\n\\uf0b7 \\nAn example x is said to consistent with hypothesis h iff h(x) = c(x)  \\n \\nDefinition:...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 1 - Intro to ML.pdf', 'page': 20, 'score': 0.11193448305130005, 'preview': 'Note difference between definitions of consistent and satisfies  \\n\\uf0b7 \\nAn example x is said to satisfy hypothesis h when h(x) = 1, regardless of whether x is a positive \\nor negative example of the target concept.  \\n\\uf0b7 \\nAn example x is said to consistent with hypothesis h iff h(x) = c(x)  \\n \\nDefinition:...'}]\n",
      "Confidence: 0.11193448305130005\n",
      "Context Preview: Note difference between definitions of consistent and satisfies  \n",
      "ÔÇ∑ \n",
      "An example x is said to satisfy hypothesis h when h(x) = 1, regardless of whether x is a positive \n",
      "or negative example of the target concept.  \n",
      "ÔÇ∑ \n",
      "An example x is said to consistent with hypothesis h iff h(x) = c(x)  \n",
      " \n",
      "Definition:\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"What is Version Spaces?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f6b2a",
   "metadata": {},
   "source": [
    "##### 3rd Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ed563e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Explain Least squares estimation?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 44.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Least Squares Estimation is a popular method of estimation in statistics and machine learning. It is used to estimate the parameters of a linear regression model by minimizing the sum of squares of the residuals.\n",
      "\n",
      "**Simple Linear Regression Model**\n",
      "\n",
      "The simple linear regression model is given by:\n",
      "\n",
      "y_i = Œ≤_0 + Œ≤_1x_i + Œµ_i\n",
      "\n",
      "where:\n",
      "\n",
      "* y_i is the dependent variable (response variable)\n",
      "* x_i is the independent variable (predictor variable)\n",
      "* Œ≤_0 is the intercept or constant term\n",
      "* Œ≤_1 is the slope coefficient\n",
      "* Œµ_i is the error term or residual\n",
      "\n",
      "**Least Squares Estimation**\n",
      "\n",
      "The principle of least squares estimates the parameters Œ≤_0 and Œ≤_1 by minimizing the sum of squares of the residuals. The sum of squares of the residuals is given by:\n",
      "\n",
      "S = ‚àë[y_i - (Œ≤_0 + Œ≤_1x_i)]^2\n",
      "\n",
      "where the sum is taken over all n observations.\n",
      "\n",
      "**Minimizing the Sum of Squares**\n",
      "\n",
      "To minimize the sum of squares, we take the partial derivatives of S with respect to Œ≤_0 and Œ≤_1, and set them equal to zero:\n",
      "\n",
      "‚àÇS/‚àÇŒ≤_0 = -2‚àë[y_i - (Œ≤_0 + Œ≤_1x_i)] = 0\n",
      "‚àÇS/‚àÇŒ≤_1 = -2‚àëx_i[y_i - (Œ≤_0 + Œ≤_1x_i)] = 0\n",
      "\n",
      "Solving these equations, we get:\n",
      "\n",
      "Œ≤_1 = ‚àë[x_iy_i - x_i^2] / ‚àëx_i^2\n",
      "Œ≤_0 = ‚àëy_i - Œ≤_1‚àëx_i\n",
      "\n",
      "These are the least squares estimates of the parameters Œ≤_0 and Œ≤_1.\n",
      "\n",
      "**Interpretation**\n",
      "\n",
      "The least squares estimates are the values of Œ≤_0 and Œ≤_1 that minimize the sum of squares of the residuals. The residual is the difference between the observed value of y_i and the predicted value of y_i based on the linear regression model. The least squares estimates are used to make predictions and to understand the relationship between the independent variable x_i and the dependent variable y_i.\n",
      "\n",
      "In summary, least squares estimation is a method of estimation that uses the principle of minimizing the sum of squares of the residuals to estimate the parameters of a linear regression model.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'page': 1, 'score': 0.3314582109451294, 'preview': 'methods of least squares and maximum likelihood are the popular methods of estimation. \\n \\nLeast squares estimation \\nSuppose a sample of  n   sets of paired observations ( ,\\n)  (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n is available. These observations \\nare assumed to satisfy the simple linear regression model, and...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'page': 1, 'score': 0.3314582109451294, 'preview': 'methods of least squares and maximum likelihood are the popular methods of estimation. \\n \\nLeast squares estimation \\nSuppose a sample of  n   sets of paired observations ( ,\\n)  (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n is available. These observations \\nare assumed to satisfy the simple linear regression model, and...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 2 - Simple Linear Regression.pdf', 'page': 1, 'score': 0.3314582109451294, 'preview': 'methods of least squares and maximum likelihood are the popular methods of estimation. \\n \\nLeast squares estimation \\nSuppose a sample of  n   sets of paired observations ( ,\\n)  (\\n1,2,..., )\\ni\\ni\\nx y\\ni\\nn\\n\\uf03d\\n is available. These observations \\nare assumed to satisfy the simple linear regression model, and...'}]\n",
      "Confidence: 0.3314582109451294\n",
      "Context Preview: methods of least squares and maximum likelihood are the popular methods of estimation. \n",
      " \n",
      "Least squares estimation \n",
      "Suppose a sample of  n   sets of paired observations ( ,\n",
      ")  (\n",
      "1,2,..., )\n",
      "i\n",
      "i\n",
      "x y\n",
      "i\n",
      "n\n",
      "ÔÄΩ\n",
      " is available. These observations \n",
      "are assumed to satisfy the simple linear regression model, and\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"Explain Least squares estimation?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48b2b5",
   "metadata": {},
   "source": [
    "##### 4th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "665fa148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Logistic Regression?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 48.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided context, Logistic Regression is the case where the response is binomial, with 'n' equal to the number of data-points with the given 'x' (often but not always 1), and 'p' is given by the following equation:\n",
      "\n",
      "p = 1 / (1 + e^(-z))\n",
      "\n",
      "Here's a clean and readable format of the equation:\n",
      "\n",
      "p = 1 / (1 + e^(-z))\n",
      "\n",
      "Explanation of symbols:\n",
      "\n",
      "- p: The probability of the response variable\n",
      "- e: The base of the natural logarithm (approximately 2.718)\n",
      "- z: The linear predictor, which is a linear combination of the input features 'x' and the model parameters\n",
      "\n",
      "In Logistic Regression, the relationship between the parameters and the linear predictor is changed using a link function, which is a mathematical function that maps the linear predictor to the probability of the response variable. This is done for computational reasons, as it allows for the use of optimization algorithms to find the model parameters.\n",
      "\n",
      "In essence, Logistic Regression is a type of regression analysis that is used to model binary outcomes, where the response variable can take on only two possible values (e.g., 0 or 1, yes or no, etc.).\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'page': 9, 'score': 0.35998380184173584, 'preview': 'is the case where response is Gaussian, with mean equal to the linear predictor, and\\nconstant variance. Logistic regression is the case where the response is binomial, with\\nn equal to the number of data-points with the given x (often but not always 1), and p\\nis given by Equation 12.5. Changing the r...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'page': 9, 'score': 0.35998380184173584, 'preview': 'is the case where response is Gaussian, with mean equal to the linear predictor, and\\nconstant variance. Logistic regression is the case where the response is binomial, with\\nn equal to the number of data-points with the given x (often but not always 1), and p\\nis given by Equation 12.5. Changing the r...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 3 - Logistic Regression.pdf', 'page': 9, 'score': 0.35998380184173584, 'preview': 'is the case where response is Gaussian, with mean equal to the linear predictor, and\\nconstant variance. Logistic regression is the case where the response is binomial, with\\nn equal to the number of data-points with the given x (often but not always 1), and p\\nis given by Equation 12.5. Changing the r...'}]\n",
      "Confidence: 0.35998380184173584\n",
      "Context Preview: is the case where response is Gaussian, with mean equal to the linear predictor, and\n",
      "constant variance. Logistic regression is the case where the response is binomial, with\n",
      "n equal to the number of data-points with the given x (often but not always 1), and p\n",
      "is given by Equation 12.5. Changing the r\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"What is Logistic Regression?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd702fb",
   "metadata": {},
   "source": [
    "##### 5th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a19bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Explain Decision Tree Learning Algorithm'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 33.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Decision Tree Learning Algorithm\n",
      "================================\n",
      "\n",
      "Decision Tree Learning is a supervised learning algorithm used for both classification and regression tasks. It's a simple yet powerful algorithm that works by recursively partitioning the data into smaller subsets based on the input features.\n",
      "\n",
      "**Decision Tree Structure**\n",
      "\n",
      "A decision tree consists of:\n",
      "\n",
      "1. **Root Node**: The topmost node in the tree, which represents the entire dataset.\n",
      "2. **Internal Nodes**: These nodes represent a feature or attribute of the data. Each internal node performs a Boolean test on the input feature.\n",
      "3. **Leaf Nodes**: These nodes represent the predicted class or target value.\n",
      "4. **Edges**: These are the connections between nodes, labeled with the values of the input feature.\n",
      "\n",
      "**Decision Tree Learning Algorithm**\n",
      "\n",
      "The decision tree learning algorithm can be summarized as follows:\n",
      "\n",
      "1. **Choose a Root Node**: Select a feature or attribute to be the root node of the tree.\n",
      "2. **Split the Data**: Partition the data into subsets based on the root node feature. This is done by applying a Boolean test to the data.\n",
      "3. **Recursively Split**: Repeat steps 1 and 2 for each subset of data, until a stopping criterion is met (e.g., all instances in a subset belong to the same class).\n",
      "4. **Create Leaf Nodes**: When a stopping criterion is met, create a leaf node with the predicted class or target value.\n",
      "5. **Prune the Tree**: Remove branches that do not contribute to the accuracy of the tree.\n",
      "\n",
      "**Decision Tree Induction**\n",
      "\n",
      "Decision tree induction is the process of constructing a decision tree from a dataset. The goal is to create a tree that accurately classifies new, unseen data.\n",
      "\n",
      "**Decision Tree Induction Algorithm**\n",
      "\n",
      "The decision tree induction algorithm can be summarized as follows:\n",
      "\n",
      "1. **Choose a Root Node**: Select a feature or attribute to be the root node of the tree.\n",
      "2. **Calculate the Gain**: Calculate the gain of each feature in the dataset. The gain is a measure of how well the feature splits the data.\n",
      "3. **Select the Best Feature**: Select the feature with the highest gain as the root node.\n",
      "4. **Split the Data**: Partition the data into subsets based on the root node feature.\n",
      "5. **Recursively Split**: Repeat steps 2-4 for each subset of data, until a stopping criterion is met.\n",
      "\n",
      "**Decision Tree Evaluation**\n",
      "\n",
      "Decision tree evaluation involves assessing the performance of a decision tree on a test dataset. Common evaluation metrics include accuracy, precision, recall, and F1 score.\n",
      "\n",
      "**Decision Tree Advantages**\n",
      "\n",
      "Decision trees have several advantages, including:\n",
      "\n",
      "* **Interpretability**: Decision trees are easy to interpret, as the tree structure provides a clear understanding of how the model makes predictions.\n",
      "* **Handling Missing Values**: Decision trees can handle missing values by ignoring the feature or using a default value.\n",
      "* **Handling Non-Normal Data**: Decision trees can handle non-normal data by using a non-parametric approach.\n",
      "\n",
      "**Decision Tree Disadvantages**\n",
      "\n",
      "Decision trees have several disadvantages, including:\n",
      "\n",
      "* **Overfitting**: Decision trees can overfit the training data, resulting in poor performance on test data.\n",
      "* **Handling High-Dimensional Data**: Decision trees can struggle with high-dimensional data, as the number of features can lead to overfitting.\n",
      "\n",
      "In conclusion, decision tree learning is a powerful algorithm for both classification and regression tasks. Its simplicity and interpretability make it a popular choice for many applications. However, it can suffer from overfitting and handling high-dimensional data.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'page': 6, 'score': 0.4512757658958435, 'preview': 'CS 486/686\\nLecture 7\\n3\\nDeÔ¨Ånition and Classifying an Example\\n3.1\\nWhat is a decision tree?\\nA decision tree is a simple model for supervised classiÔ¨Åcation. It is used for classifying a\\nsingle discrete target feature.\\nEach internal node performs a Boolean test on an input feature (in general, a test may...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'page': 6, 'score': 0.4512757658958435, 'preview': 'CS 486/686\\nLecture 7\\n3\\nDeÔ¨Ånition and Classifying an Example\\n3.1\\nWhat is a decision tree?\\nA decision tree is a simple model for supervised classiÔ¨Åcation. It is used for classifying a\\nsingle discrete target feature.\\nEach internal node performs a Boolean test on an input feature (in general, a test may...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 4 - Decision Tree.pdf', 'page': 6, 'score': 0.4512757658958435, 'preview': 'CS 486/686\\nLecture 7\\n3\\nDeÔ¨Ånition and Classifying an Example\\n3.1\\nWhat is a decision tree?\\nA decision tree is a simple model for supervised classiÔ¨Åcation. It is used for classifying a\\nsingle discrete target feature.\\nEach internal node performs a Boolean test on an input feature (in general, a test may...'}]\n",
      "Confidence: 0.4512757658958435\n",
      "Context Preview: CS 486/686\n",
      "Lecture 7\n",
      "3\n",
      "DeÔ¨Ånition and Classifying an Example\n",
      "3.1\n",
      "What is a decision tree?\n",
      "A decision tree is a simple model for supervised classiÔ¨Åcation. It is used for classifying a\n",
      "single discrete target feature.\n",
      "Each internal node performs a Boolean test on an input feature (in general, a test may\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"Explain Decision Tree Learning Algorithm\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a80cb",
   "metadata": {},
   "source": [
    "##### 6th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a02922e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Multi Layer Artificial Neural Networks?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 46.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: **Multi Layer Artificial Neural Networks (MLANN)**\n",
      "\n",
      "A Multi Layer Artificial Neural Network (MLANN) is a type of neural network that consists of multiple layers of interconnected nodes or neurons. These layers are:\n",
      "\n",
      "1. **Input Layer**: The first layer that receives the input data.\n",
      "2. **Hidden Layers**: One or more layers between the input and output layers that perform complex computations.\n",
      "3. **Output Layer**: The final layer that produces the output.\n",
      "\n",
      "**Function of Each Neuron in Hidden Layers**\n",
      "\n",
      "The neurons in the hidden layers are responsible for:\n",
      "\n",
      "* **Nonlinear Function Approximation**: The ability to approximate complex relationships between inputs and outputs using nonlinear functions.\n",
      "* **Learning Generalization**: The ability to learn from a limited set of examples and apply that knowledge to new, unseen data.\n",
      "* **Nonlinear Classification**: The ability to classify data into different categories using nonlinear boundaries.\n",
      "\n",
      "**Architecture of a Multi Layer Neural Network**\n",
      "\n",
      "A typical MLANN architecture consists of:\n",
      "\n",
      "* **Input Layer**: `x = [x1, x2, ..., xn]` (number of nodes = number of inputs)\n",
      "* **Hidden Layers**: `h = [h1, h2, ..., hm]` (number of nodes = selected by designer)\n",
      "* **Output Layer**: `y = [y1, y2, ..., ym]` (number of nodes = number of outputs)\n",
      "\n",
      "**Mathematical Representation**\n",
      "\n",
      "The output of a neuron in the hidden layer can be represented as:\n",
      "\n",
      "`h = œÉ(Wx + b)`\n",
      "\n",
      "where:\n",
      "\n",
      "* `œÉ` is the activation function (e.g. sigmoid, ReLU)\n",
      "* `W` is the weight matrix\n",
      "* `x` is the input vector\n",
      "* `b` is the bias vector\n",
      "\n",
      "The output of the output layer can be represented as:\n",
      "\n",
      "`y = œÉ(W'h + b')`\n",
      "\n",
      "where:\n",
      "\n",
      "* `W'` is the weight matrix from the hidden layer to the output layer\n",
      "* `b'` is the bias vector for the output layer\n",
      "\n",
      "**Explanation of Symbols**\n",
      "\n",
      "* `œÉ`: Activation function (e.g. sigmoid, ReLU)\n",
      "* `W`: Weight matrix\n",
      "* `x`: Input vector\n",
      "* `b`: Bias vector\n",
      "* `h`: Output of the hidden layer\n",
      "* `y`: Output of the output layer\n",
      "* `W'`: Weight matrix from the hidden layer to the output layer\n",
      "* `b'`: Bias vector for the output layer\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'page': 16, 'score': 0.4305758476257324, 'preview': 'function of each neuron in hidden layers, the multi layer neural networks able to solve many \\nof the complex problems, such as, nonlinear function approximation, learning generalization, \\nnonlinear classification etc. \\n \\nA multi layer neural network consists of input layer, output layer and hidden l...'}, {'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'page': 16, 'score': 0.4305758476257324, 'preview': 'function of each neuron in hidden layers, the multi layer neural networks able to solve many \\nof the complex problems, such as, nonlinear function approximation, learning generalization, \\nnonlinear classification etc. \\n \\nA multi layer neural network consists of input layer, output layer and hidden l...'}, {'source': '..\\\\data\\\\pdf\\\\chapter 5 -Neural Networks.pdf', 'page': 16, 'score': 0.4305758476257324, 'preview': 'function of each neuron in hidden layers, the multi layer neural networks able to solve many \\nof the complex problems, such as, nonlinear function approximation, learning generalization, \\nnonlinear classification etc. \\n \\nA multi layer neural network consists of input layer, output layer and hidden l...'}]\n",
      "Confidence: 0.4305758476257324\n",
      "Context Preview: function of each neuron in hidden layers, the multi layer neural networks able to solve many \n",
      "of the complex problems, such as, nonlinear function approximation, learning generalization, \n",
      "nonlinear classification etc. \n",
      " \n",
      "A multi layer neural network consists of input layer, output layer and hidden l\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"What is Multi Layer Artificial Neural Networks?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bd3df",
   "metadata": {},
   "source": [
    "##### 7th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46c70912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is L1 regularization (LASSO)'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 39.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: L1 regularization, also known as LASSO (Least Absolute Shrinkage and Selection Operator), is a type of regularization technique used in linear regression and other machine learning models. It is a method for reducing overfitting by adding a penalty term to the loss function.\n",
      "\n",
      "The L1 regularization equation is:\n",
      "\n",
      "ÀÜw = arg min\n",
      "w (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•1\n",
      "\n",
      "where:\n",
      "\n",
      "- ÀÜw is the estimated weight vector\n",
      "- w is the weight vector\n",
      "- Y is the target variable\n",
      "- X is the design matrix\n",
      "- Œª is the regularization parameter (Œª ‚â• 0)\n",
      "- ‚à•w‚à•1 is the L1 norm of the weight vector, defined as:\n",
      "\n",
      "‚à•w‚à•1 = PD\n",
      "j = 1|wj|\n",
      "\n",
      "In simpler terms, the L1 norm is the sum of the absolute values of the weights.\n",
      "\n",
      "The L1 regularization term (Œª‚à•w‚à•1) encourages the model to set some of the weights to zero, effectively selecting the most important features and reducing overfitting.\n",
      "\n",
      "LASSO has two main implications:\n",
      "\n",
      "1. **No closed-form solution**: Unlike L2 regularization, LASSO does not have a closed-form solution. Instead, it requires the use of quadratic programming or other optimization techniques to find the optimal weights.\n",
      "2. **LASSO as MAP learning with Laplacian prior**: LASSO can be viewed as a Maximum a Posteriori (MAP) learning method with a Laplacian prior distribution over the weights. The prior distribution is given by:\n",
      "\n",
      "P(wj) = 1\n",
      "2be‚àí\n",
      "|wj|\n",
      "b\n",
      "\n",
      "where b is the scale parameter.\n",
      "\n",
      "In summary, L1 regularization (LASSO) is a powerful technique for reducing overfitting and selecting important features in linear regression and other machine learning models.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'page': 11, 'score': 0.30302995443344116, 'preview': 'L1 regularization (LASSO)\\nÀÜw = arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•1\\nwhere Œª ‚â•0 and ‚à•w‚à•1 = PD\\nj = 1|wj|\\nLooks like a small tweak, but makes a big diÔ¨Äerence!\\n1) No more closed-form solution\\n‚Äì use quadratic programming\\nminw(Y ‚àíXw)T(Y ‚àíXw) s.t. ‚à•w‚à•1 ‚â§s\\n‚Äì convex problem, polytime (but expensive) solution\\n2)...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'page': 11, 'score': 0.30302995443344116, 'preview': 'L1 regularization (LASSO)\\nÀÜw = arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•1\\nwhere Œª ‚â•0 and ‚à•w‚à•1 = PD\\nj = 1|wj|\\nLooks like a small tweak, but makes a big diÔ¨Äerence!\\n1) No more closed-form solution\\n‚Äì use quadratic programming\\nminw(Y ‚àíXw)T(Y ‚àíXw) s.t. ‚à•w‚à•1 ‚â§s\\n‚Äì convex problem, polytime (but expensive) solution\\n2)...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 6 - Overfitting & Regularization.pdf', 'page': 11, 'score': 0.30302995443344116, 'preview': 'L1 regularization (LASSO)\\nÀÜw = arg min\\nw (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•1\\nwhere Œª ‚â•0 and ‚à•w‚à•1 = PD\\nj = 1|wj|\\nLooks like a small tweak, but makes a big diÔ¨Äerence!\\n1) No more closed-form solution\\n‚Äì use quadratic programming\\nminw(Y ‚àíXw)T(Y ‚àíXw) s.t. ‚à•w‚à•1 ‚â§s\\n‚Äì convex problem, polytime (but expensive) solution\\n2)...'}]\n",
      "Confidence: 0.30302995443344116\n",
      "Context Preview: L1 regularization (LASSO)\n",
      "ÀÜw = arg min\n",
      "w (Y ‚àíXw)T(Y ‚àíXw) + Œª‚à•w‚à•1\n",
      "where Œª ‚â•0 and ‚à•w‚à•1 = PD\n",
      "j = 1|wj|\n",
      "Looks like a small tweak, but makes a big diÔ¨Äerence!\n",
      "1) No more closed-form solution\n",
      "‚Äì use quadratic programming\n",
      "minw(Y ‚àíXw)T(Y ‚àíXw) s.t. ‚à•w‚à•1 ‚â§s\n",
      "‚Äì convex problem, polytime (but expensive) solution\n",
      "2)\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"what is L1 regularization (LASSO)\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6bc462",
   "metadata": {},
   "source": [
    "##### 8th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b3c394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Bias-Variance Decomposition of the 0-1 Loss'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 52.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The Bias-Variance Decomposition of the 0-1 Loss, as formulated by Kong & Dietterich (1995), is given by:\n",
      "\n",
      "**Bias-Variance Decomposition of 0-1 Loss:**\n",
      "\n",
      "Let's denote the true label as y, the predicted label as \\hat{y}, and the probability of the predicted label as p(\\hat{y}).\n",
      "\n",
      "The 0-1 loss function is defined as:\n",
      "\n",
      "L(y, \\hat{y}) = \\begin{cases}\n",
      "0, & \\text{if } y = \\hat{y} \\\\\n",
      "1, & \\text{if } y \\neq \\hat{y}\n",
      "\\end{cases}\n",
      "\n",
      "The expected 0-1 loss is given by:\n",
      "\n",
      "E[L(y, \\hat{y})] = E[1 - 2y\\hat{y}]\n",
      "\n",
      "Using the law of iterated expectations, we can rewrite this as:\n",
      "\n",
      "E[L(y, \\hat{y})] = E[E[L(y, \\hat{y}) | \\hat{y}]]\n",
      "\n",
      "Now, we can expand the inner expectation:\n",
      "\n",
      "E[L(y, \\hat{y}) | \\hat{y}] = E[1 - 2y\\hat{y} | \\hat{y}]\n",
      "\n",
      "Using the fact that E[y | \\hat{y}] = \\hat{y}, we get:\n",
      "\n",
      "E[L(y, \\hat{y}) | \\hat{y}] = 1 - 2\\hat{y}^2\n",
      "\n",
      "Now, we can take the outer expectation:\n",
      "\n",
      "E[L(y, \\hat{y})] = E[1 - 2\\hat{y}^2]\n",
      "\n",
      "Using the fact that E[\\hat{y}^2] = Var(\\hat{y}) + (E[\\hat{y}])^2, we get:\n",
      "\n",
      "E[L(y, \\hat{y})] = 1 - 2(E[\\hat{y}])^2 - 2Var(\\hat{y})\n",
      "\n",
      "This is the Bias-Variance Decomposition of the 0-1 Loss.\n",
      "\n",
      "**Explanation of Symbols:**\n",
      "\n",
      "* L(y, \\hat{y}) is the 0-1 loss function, which is 0 if the predicted label is correct and 1 if it is incorrect.\n",
      "* E[L(y, \\hat{y})] is the expected 0-1 loss.\n",
      "* E[...] is the expected value of a random variable.\n",
      "* Var(\\hat{y}) is the variance of the predicted label.\n",
      "* E[\\hat{y}] is the expected value of the predicted label.\n",
      "* \\hat{y} is the predicted label.\n",
      "* y is the true label.\n",
      "\n",
      "**Interpretation:**\n",
      "\n",
      "The Bias-Variance Decomposition of the 0-1 Loss shows that the expected 0-1 loss can be decomposed into three terms:\n",
      "\n",
      "* The first term, 1 - 2(E[\\hat{y}])^2, represents the bias of the model. This term measures how far the model's predictions are from the true labels.\n",
      "* The second term, -2Var(\\hat{y}), represents the variance of the model. This term measures how much the model's predictions vary from the expected value.\n",
      "\n",
      "The Bias-Variance Decomposition of the 0-1 Loss provides a way to analyze the performance of a model in terms of its bias and variance.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'page': 7, 'score': 0.7009924054145813, 'preview': 'bias-variance decompositions related to zero-one loss (Kong & Dietterich, 1995; Breiman,\\n1996b; Kohavi & Wolpert, 1996; Tibshirani, 1996; Friedman, 1997). However, each of these\\ndecompositions has signiÔ¨Åcant shortcomings.‚Äù4. In fact, the paper this quote was taken from\\nmay oÔ¨Äer the most intuitive an...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'page': 7, 'score': 0.7009924054145813, 'preview': 'bias-variance decompositions related to zero-one loss (Kong & Dietterich, 1995; Breiman,\\n1996b; Kohavi & Wolpert, 1996; Tibshirani, 1996; Friedman, 1997). However, each of these\\ndecompositions has signiÔ¨Åcant shortcomings.‚Äù4. In fact, the paper this quote was taken from\\nmay oÔ¨Äer the most intuitive an...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 7 - Bias Variance.pdf', 'page': 7, 'score': 0.7009924054145813, 'preview': 'bias-variance decompositions related to zero-one loss (Kong & Dietterich, 1995; Breiman,\\n1996b; Kohavi & Wolpert, 1996; Tibshirani, 1996; Friedman, 1997). However, each of these\\ndecompositions has signiÔ¨Åcant shortcomings.‚Äù4. In fact, the paper this quote was taken from\\nmay oÔ¨Äer the most intuitive an...'}]\n",
      "Confidence: 0.7009924054145813\n",
      "Context Preview: bias-variance decompositions related to zero-one loss (Kong & Dietterich, 1995; Breiman,\n",
      "1996b; Kohavi & Wolpert, 1996; Tibshirani, 1996; Friedman, 1997). However, each of these\n",
      "decompositions has signiÔ¨Åcant shortcomings.‚Äù4. In fact, the paper this quote was taken from\n",
      "may oÔ¨Äer the most intuitive an\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"What is Bias-Variance Decomposition of the 0-1 Loss\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2415e9b",
   "metadata": {},
   "source": [
    "##### 9th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24ed0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Explain Gradient Descent'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 34.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: **What is Gradient Descent?**\n",
      "\n",
      "Gradient Descent is a fundamental optimization algorithm used in machine learning to minimize the loss function of a model. It's a popular technique for finding the optimal parameters of a model by iteratively adjusting them based on the gradient of the loss function.\n",
      "\n",
      "**How Gradient Descent Works**\n",
      "\n",
      "The goal of Gradient Descent is to find the minimum value of the loss function, which measures the difference between the model's predictions and the actual values. The algorithm works as follows:\n",
      "\n",
      "1. **Initialization**: Initialize the model's parameters (weights and biases) randomly.\n",
      "2. **Forward Pass**: Compute the model's predictions using the current parameters.\n",
      "3. **Compute Loss**: Calculate the loss function using the predictions and actual values.\n",
      "4. **Compute Gradient**: Calculate the gradient of the loss function with respect to each parameter.\n",
      "5. **Update Parameters**: Update each parameter by subtracting a fraction of the gradient, scaled by the learning rate.\n",
      "\n",
      "**Mathematical Representation**\n",
      "\n",
      "Let's denote the loss function as `L`, the model's parameters as `w` (weights) and `b` (biases), the learning rate as `Œ±`, and the number of iterations as `t`. The update rule for each parameter `w_i` is:\n",
      "\n",
      "`w_i(t+1) = w_i(t) - Œ± * ‚àÇL/‚àÇw_i`\n",
      "\n",
      "where `‚àÇL/‚àÇw_i` is the partial derivative of the loss function with respect to `w_i`.\n",
      "\n",
      "**Explanation of Symbols**\n",
      "\n",
      "* `L`: Loss function (e.g., mean squared error, cross-entropy)\n",
      "* `w`: Model's weights (parameters)\n",
      "* `b`: Model's biases (parameters)\n",
      "* `Œ±`: Learning rate (step size)\n",
      "* `t`: Iteration number\n",
      "* `‚àÇL/‚àÇw_i`: Partial derivative of the loss function with respect to `w_i`\n",
      "\n",
      "**Types of Gradient Descent**\n",
      "\n",
      "There are two main types of Gradient Descent:\n",
      "\n",
      "1. **Batch Gradient Descent**: Updates the parameters using the entire training dataset at each iteration.\n",
      "2. **Stochastic Gradient Descent**: Updates the parameters using a single training example at each iteration.\n",
      "\n",
      "**Advantages and Disadvantages**\n",
      "\n",
      "Advantages:\n",
      "\n",
      "* Simple to implement\n",
      "* Fast convergence\n",
      "* Can handle large datasets\n",
      "\n",
      "Disadvantages:\n",
      "\n",
      "* May get stuck in local minima\n",
      "* Requires careful selection of learning rate and batch size\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "Gradient Descent is a fundamental algorithm in machine learning that helps optimize model parameters to minimize the loss function. Its simplicity and effectiveness make it a popular choice for many machine learning applications.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'page': 7, 'score': 0.6323383450508118, 'preview': 'Part I\\nWHAT IS GRADIENT DESCENT?\\n7 / 39...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'page': 7, 'score': 0.6323383450508118, 'preview': 'Part I\\nWHAT IS GRADIENT DESCENT?\\n7 / 39...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 8 - Gradient Descent.pdf', 'page': 7, 'score': 0.6323383450508118, 'preview': 'Part I\\nWHAT IS GRADIENT DESCENT?\\n7 / 39...'}]\n",
      "Confidence: 0.6323383450508118\n",
      "Context Preview: Part I\n",
      "WHAT IS GRADIENT DESCENT?\n",
      "7 / 39\n",
      "\n",
      "Part I\n",
      "WHAT IS GRADIENT DESCENT?\n",
      "7 / 39\n",
      "\n",
      "Part I\n",
      "WHAT IS GRADIENT DESCENT?\n",
      "7 / 39\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"Explain Gradient Descent\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0dd21d",
   "metadata": {},
   "source": [
    "##### 10th Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87afc7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Explain Evaluation Metrics? '\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 61.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrated emebeddings with shape: (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Evaluation Metrics for Machine Learning Algorithms\n",
      "=====================================================\n",
      "\n",
      "As a data scientist, it's essential to understand various evaluation metrics to assess the performance of machine learning algorithms. These metrics help identify issues caused by an imbalance in the prevalence of categories.\n",
      "\n",
      "### Confusion Matrix\n",
      "\n",
      "A confusion matrix is a table used to evaluate the performance of a classification model. It displays the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN).\n",
      "\n",
      "|  | Predicted Positive | Predicted Negative |\n",
      "| --- | --- | --- |\n",
      "| **Actual Positive** | TP | FN |\n",
      "| **Actual Negative** | FP | TN |\n",
      "\n",
      "### Sensitivity (Recall)\n",
      "\n",
      "Sensitivity, also known as recall, measures the proportion of actual positive instances that are correctly predicted by the model.\n",
      "\n",
      "**Sensitivity (Recall) = TP / (TP + FN)**\n",
      "\n",
      "* TP: True Positives (correctly predicted positive instances)\n",
      "* FN: False Negatives (missed positive instances)\n",
      "\n",
      "Sensitivity is particularly useful when the cost of false negatives is high, such as in medical diagnosis.\n",
      "\n",
      "### Specificity\n",
      "\n",
      "Specificity measures the proportion of actual negative instances that are correctly predicted by the model.\n",
      "\n",
      "**Specificity = TN / (TN + FP)**\n",
      "\n",
      "* TN: True Negatives (correctly predicted negative instances)\n",
      "* FP: False Positives (incorrectly predicted positive instances)\n",
      "\n",
      "Specificity is useful when the cost of false positives is high, such as in medical diagnosis.\n",
      "\n",
      "### Precision\n",
      "\n",
      "Precision measures the proportion of correctly predicted positive instances among all predicted positive instances.\n",
      "\n",
      "**Precision = TP / (TP + FP)**\n",
      "\n",
      "* TP: True Positives (correctly predicted positive instances)\n",
      "* FP: False Positives (incorrectly predicted positive instances)\n",
      "\n",
      "Precision is useful when the cost of false positives is high.\n",
      "\n",
      "### F1-Score\n",
      "\n",
      "The F1-score is the harmonic mean of precision and recall.\n",
      "\n",
      "**F1-Score = 2 \\* (Precision \\* Recall) / (Precision + Recall)**\n",
      "\n",
      "* Precision: TP / (TP + FP)\n",
      "* Recall: TP / (TP + FN)\n",
      "\n",
      "The F1-score provides a balanced measure of precision and recall.\n",
      "\n",
      "### Accuracy\n",
      "\n",
      "Accuracy measures the proportion of correctly predicted instances among all instances.\n",
      "\n",
      "**Accuracy = (TP + TN) / (TP + TN + FP + FN)**\n",
      "\n",
      "* TP: True Positives (correctly predicted positive instances)\n",
      "* TN: True Negatives (correctly predicted negative instances)\n",
      "* FP: False Positives (incorrectly predicted positive instances)\n",
      "* FN: False Negatives (missed positive instances)\n",
      "\n",
      "Accuracy is a simple measure, but it can be misleading when the classes are imbalanced.\n",
      "\n",
      "### Receiver Operating Characteristic (ROC) Curve\n",
      "\n",
      "The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1 - specificity) at different thresholds.\n",
      "\n",
      "**True Positive Rate = TP / (TP + FN)**\n",
      "**False Positive Rate = FP / (FP + TN)**\n",
      "\n",
      "The ROC curve helps evaluate the model's ability to distinguish between classes.\n",
      "\n",
      "### Area Under the ROC Curve (AUC)\n",
      "\n",
      "The AUC measures the area under the ROC curve.\n",
      "\n",
      "**AUC = ‚à´[0,1] (True Positive Rate) d(False Positive Rate)**\n",
      "\n",
      "The AUC provides a single value to evaluate the model's performance.\n",
      "\n",
      "These evaluation metrics help data scientists assess the performance of machine learning algorithms and identify areas for improvement.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'page': 10, 'score': 0.16548210382461548, 'preview': 'Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n45 \\nyou an exposure to this important learning that you should have as a data \\nscientist. \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.34) \\nAs promised in (2.30), in this section, other than the confusion matrix, we will \\nalso learn some other evaluation metrics which ca...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'page': 10, 'score': 0.16548210382461548, 'preview': 'Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n45 \\nyou an exposure to this important learning that you should have as a data \\nscientist. \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.34) \\nAs promised in (2.30), in this section, other than the confusion matrix, we will \\nalso learn some other evaluation metrics which ca...'}, {'source': '..\\\\data\\\\pdf\\\\Chapter 9 - Evaluation Metrics.pdf', 'page': 10, 'score': 0.16548210382461548, 'preview': 'Evaluation Metrics \\nfor Machine Learning \\nAlgorithms \\n45 \\nyou an exposure to this important learning that you should have as a data \\nscientist. \\n \\n \\n \\n \\n \\n \\n \\n‚Ä¶ (2.34) \\nAs promised in (2.30), in this section, other than the confusion matrix, we will \\nalso learn some other evaluation metrics which ca...'}]\n",
      "Confidence: 0.16548210382461548\n",
      "Context Preview: Evaluation Metrics \n",
      "for Machine Learning \n",
      "Algorithms \n",
      "45 \n",
      "you an exposure to this important learning that you should have as a data \n",
      "scientist. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "‚Ä¶ (2.34) \n",
      "As promised in (2.30), in this section, other than the confusion matrix, we will \n",
      "also learn some other evaluation metrics which ca\n"
     ]
    }
   ],
   "source": [
    "result = rag_advanced(\"Explain Evaluation Metrics? \", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Based Study Assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
